{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8TQtMFiNNyw"
      },
      "source": [
        "# 0. Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5teCJMv-Rq31",
        "outputId": "a7440d37-e000-44a6-c743-ff137e44ecc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.11.7)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.14.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.2)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.73.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.16.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.0.2)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.24.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.26.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-sdk>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9->chromadb) (0.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers>=0.13.2->chromadb) (0.33.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (1.1.5)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.4.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading chromadb-1.0.15-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.22.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.2/71.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=327b856063e70c1063ed1b2c27d1fb1613c1c1d055bbfc4a4a9b074cb5ba33ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, python-dotenv, pybase64, overrides, opentelemetry-proto, mmh3, humanfriendly, httptools, bcrypt, backoff, watchfiles, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-semantic-conventions, onnxruntime, kubernetes, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed backoff-2.2.1 bcrypt-4.3.0 chromadb-1.0.15 coloredlogs-15.0.1 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-33.1.0 mmh3-5.1.0 onnxruntime-1.22.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 overrides-7.7.0 posthog-5.4.0 pybase64-1.4.1 pypika-0.48.9 python-dotenv-1.1.1 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnh5f8-IXd7w"
      },
      "source": [
        "# 1. Cree la base de donnees"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pFJey1wYQ6SZ"
      },
      "outputs": [],
      "source": [
        "import chromadb\n",
        "\n",
        "def init_db():\n",
        "    \"\"\"Initialisation de la base de données ChromaDB\"\"\"\n",
        "    return chromadb.PersistentClient(path=\"/content/chromadb\")\n",
        "\n",
        "db = init_db()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_slW1788Xmh9"
      },
      "source": [
        "# 2. Cree les Collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yY1GFL4QRhNE"
      },
      "outputs": [],
      "source": [
        "roles = [\"Simple\", \"Dev\", \"Admin\"]\n",
        "collections = {role: db.get_or_create_collection(name=f\"qa_{role}\") for role in roles}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeALzm1ER5d2",
        "outputId": "769033d4-a980-443b-f74a-d3594c56b8a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Simple': Collection(name=qa_Simple),\n",
              " 'Dev': Collection(name=qa_Dev),\n",
              " 'Admin': Collection(name=qa_Admin)}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYmRLMDFR_zf",
        "outputId": "4d8ee1c1-bba7-4404-fa4b-35d011eeb621"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['qa_Dev', 'qa_Simple', 'qa_Admin']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "db.list_collections()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cWQCCC0USQvI"
      },
      "outputs": [],
      "source": [
        "def Num_Data():\n",
        "  for coll in collections:\n",
        "      print('Num ', coll,' : ', collections[coll].count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZhk57sLTN9V",
        "outputId": "f803faad-18ad-4b2d-ab90-97897171ed0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num  Simple  :  0\n",
            "Num  Dev  :  0\n",
            "Num  Admin  :  0\n"
          ]
        }
      ],
      "source": [
        "Num_Data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSnjKwmRXvAD"
      },
      "source": [
        "# 3. Add/ Ask questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Mo-ktryJRMpa"
      },
      "outputs": [],
      "source": [
        "def add_document(role: str, question: str, answer: str):\n",
        "    \"\"\"Ajoute une question-réponse dans la collection associée au rôle spécifié\"\"\"\n",
        "    if role not in collections:\n",
        "        print(\"Rôle invalide!\")\n",
        "        return\n",
        "\n",
        "    collection = collections[role]\n",
        "    collection.add(\n",
        "        documents=[question],\n",
        "        metadatas=[{\"answer\": answer}],\n",
        "        ids=[f\"{role}_{question}\"]  # Identifiant unique basé sur le rôle\n",
        "    )\n",
        "    print(f\"Ajouté avec succès dans la collection {role}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "22pGB_A9ljLr"
      },
      "outputs": [],
      "source": [
        "seuil = 0.1\n",
        "message_question_existante_autre_role = \"Cette question associée à un autre rôle.\"\n",
        "message_hors_contexte = \"Cette question ne correspond à aucun des rôles définis.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mo8T-9JMqx49"
      },
      "outputs": [],
      "source": [
        "def ask_autre_role(role: str, question: str):\n",
        "    for rol in collections:\n",
        "        if rol != role:\n",
        "            collection = collections[rol]\n",
        "            results = collection.query(query_texts=[question], n_results=1)\n",
        "\n",
        "            if results and results.get(\"documents\"):\n",
        "                distance = results[\"distances\"][0][0] if results[\"distances\"] else None\n",
        "                if distance is not None and distance <= seuil:\n",
        "                    return True\n",
        "    return False  # Ajoute un return par défaut pour éviter des erreurs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ebd-TntLTjFc"
      },
      "outputs": [],
      "source": [
        "def ask_question(role: str, question: str):\n",
        "    \"\"\"Recherche la réponse en fonction du rôle donné\"\"\"\n",
        "    if role not in collections:\n",
        "        return \"Rôle invalide!\"\n",
        "\n",
        "    collection = collections[role]\n",
        "    results = collection.query(query_texts=[question], n_results=1)\n",
        "\n",
        "    if results and results.get(\"documents\"):\n",
        "        distance = results[\"distances\"][0][0] if results[\"distances\"] else None\n",
        "\n",
        "        if distance <= seuil:\n",
        "          answer = results[\"metadatas\"][0][0][\"answer\"] if results[\"metadatas\"] else \"Réponse non disponible\"\n",
        "          #return f\"Réponse: {answer}, Pertinence (distance): {distance:.4f}\"\n",
        "          return answer\n",
        "\n",
        "        else :\n",
        "          temp = ask_autre_role(role, question)\n",
        "          if temp:\n",
        "            return message_question_existante_autre_role\n",
        "          else:\n",
        "            return message_hors_contexte\n",
        "          #return \"Seuil elvee !\"\n",
        "\n",
        "        #return f\"Réponse: {answer}, Pertinence (distance): {distance:.4f}\"\n",
        "\n",
        "    return \"Aucune réponse trouvée\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "yW653yRPTmI2"
      },
      "outputs": [],
      "source": [
        "# # Exemple d'utilisation\n",
        "# add_document(\"Simple\", \"Quel est le capital du Maroc?\", \"Rabat\")\n",
        "# add_document(\"Dev\", \"Qu'est-ce que Python?\", \"Un langage de programmation interprété.\")\n",
        "# add_document(\"Admin\", \"Comment redémarrer un serveur Linux?\", \"Utiliser la commande 'sudo reboot'.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "zRBY3Bc_UVQs"
      },
      "outputs": [],
      "source": [
        "# print(ask_question(\"Simple\", \"Quel est le capital du Maroc?\"))  # Devrait retourner Rabat\n",
        "# print(ask_question(\"Dev\", \"Qu'est-ce que Python?\"))  # Devrait retourner la réponse associée\n",
        "# print(ask_question(\"Admin\", \"Comment redémarrer un serveur Linux?\"))  # Réponse Admin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "dZUsxLG2jVUz"
      },
      "outputs": [],
      "source": [
        "# ask_question('Dev', \"Qui est le Groupe OMF ?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNraZT_58jj5"
      },
      "source": [
        "# 4. Creation du contexte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kmGPvOjLMQm1"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "# If these fail, please check you're running from an 'activated' environment with (llms) in the command prompt\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import json\n",
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFgQzSODNOlE",
        "outputId": "e6263c66-50f7-486d-957f-4e1d3abb9781"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API key looks good so far\n"
          ]
        }
      ],
      "source": [
        "# Initialize and constants\n",
        "\n",
        "api_key = \"##\"\n",
        "\n",
        "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
        "    print(\"API key looks good so far\")\n",
        "else:\n",
        "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
        "\n",
        "MODEL = 'gpt-4o-mini'\n",
        "openai = OpenAI(api_key=api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbouOzonMRoh"
      },
      "outputs": [],
      "source": [
        "# A class to represent a Webpage\n",
        "\n",
        "# Some websites need you to use proper headers when fetching them:\n",
        "headers = {\n",
        " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "class Website:\n",
        "    \"\"\"\n",
        "    A utility class to represent a Website that we have scraped, now with links\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, url):\n",
        "        self.url = url\n",
        "        response = requests.get(url, headers=headers)\n",
        "        self.body = response.content\n",
        "        soup = BeautifulSoup(self.body, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        if soup.body:\n",
        "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "                irrelevant.decompose()\n",
        "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
        "        else:\n",
        "            self.text = \"\"\n",
        "        links = [link.get('href') for link in soup.find_all('a')]\n",
        "        self.links = [link for link in links if link]\n",
        "\n",
        "    def get_contents(self):\n",
        "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFvadHZWMpCp",
        "outputId": "fae3e3f5-ee7d-46d1-dc97-b4137a71198f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['#',\n",
              " 'https://www.groupe-omf.com/',\n",
              " 'https://www.facebook.com/groupeomf',\n",
              " 'https://www.twitter.com/groupeomf',\n",
              " 'https://www.instagram.com/groupe_omf',\n",
              " 'https://www.linkedin.com/company/groupe-omf',\n",
              " 'https://www.groupe-omf.com/contact/',\n",
              " '#',\n",
              " 'https://www.groupe-omf.com/',\n",
              " '#',\n",
              " '#',\n",
              " 'https://www.groupe-omf.com/',\n",
              " 'https://www.groupe-omf.com/groupe-omf/',\n",
              " 'https://www.groupe-omf.com/mot-du-president/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/politique-qhse/',\n",
              " 'https://www.groupe-omf.com/clients/',\n",
              " '/services',\n",
              " 'https://www.groupe-omf.com/creation-de-societe/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/gestion-deleguee-de-la-paie/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/portage-salarial/',\n",
              " 'https://www.groupe-omf.com/delocalisation/',\n",
              " 'https://www.groupe-omf.com/formation-professionnelle-continue/',\n",
              " 'https://www.groupe-omf.com/ingenierie-de-formation/',\n",
              " 'https://www.groupe-omf.com/subvention/',\n",
              " '/media-technologie',\n",
              " 'https://www.groupe-omf.com/audit-diagnostics/',\n",
              " 'https://www.groupe-omf.com/transformation-numerique/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-digitale/',\n",
              " 'https://www.groupe-omf.com/digital/',\n",
              " 'https://www.groupe-omf.com/community-management/',\n",
              " 'https://www.groupe-omf.com/content-marketing/',\n",
              " 'https://www.groupe-omf.com/relations-publiques-presse/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/smart-crm/',\n",
              " 'https://www.groupe-omf.com/smart-gep/',\n",
              " 'https://www.groupe-omf.com/smart-project/',\n",
              " 'https://www.groupe-omf.com/contact/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/contact/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/',\n",
              " 'https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/',\n",
              " 'https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/',\n",
              " 'https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/',\n",
              " 'https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/',\n",
              " 'https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/',\n",
              " 'https://www.groupe-omf.com/blog/',\n",
              " 'career',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " '/cdn-cgi/l/email-protection',\n",
              " 'https://twitter.com/bold_themes',\n",
              " '#',\n",
              " 'about',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " '/cdn-cgi/l/email-protection',\n",
              " 'https://twitter.com/bold_themes',\n",
              " '#',\n",
              " 'about',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " '/cdn-cgi/l/email-protection',\n",
              " 'https://twitter.com/bold_themes',\n",
              " '#',\n",
              " 'about',\n",
              " 'https://www.groupe-omf.com/mot-du-president/',\n",
              " '#',\n",
              " '#',\n",
              " '#',\n",
              " 'https://www.groupe-omf.com/groupe-omf/',\n",
              " 'https://www.groupe-omf.com/mot-du-president/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/politique-qhse/',\n",
              " 'https://www.groupe-omf.com/clients/',\n",
              " 'https://www.groupe-omf.com/creation-de-societe/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/gestion-deleguee-de-la-paie/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/audit-diagnostics/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-digitale/',\n",
              " 'https://www.groupe-omf.com/transformation-numerique/',\n",
              " 'https://www.facebook.com/groupeomf',\n",
              " 'https://www.twitter.com/groupeomf',\n",
              " 'https://www.instagram.com/groupe_omf',\n",
              " 'https://www.linkedin.com/company/groupe-omf',\n",
              " '#',\n",
              " '#']"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ed = Website(\"https://www.groupe-omf.com/\")\n",
        "ed.links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-82C_FPMpF2"
      },
      "outputs": [],
      "source": [
        "link_system_prompt = \"You are provided with a list of links found on a webpage. \\\n",
        "You are able to decide which of the links would be most relevant to include in a brochure about the company, \\\n",
        "such as links to an About page, or a Company page, or Careers/Jobs pages.\\n\"\n",
        "link_system_prompt += \"You should respond in JSON as in this example:\"\n",
        "link_system_prompt += \"\"\"\n",
        "{\n",
        "    \"links\": [\n",
        "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
        "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
        "    ]\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln44WRwAMpIC",
        "outputId": "de087999-440b-4c25-fc00-efb4a4b1fd5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are provided with a list of links found on a webpage. You are able to decide which of the links would be most relevant to include in a brochure about the company, such as links to an About page, or a Company page, or Careers/Jobs pages.\n",
            "You should respond in JSON as in this example:\n",
            "{\n",
            "    \"links\": [\n",
            "        {\"type\": \"about page\", \"url\": \"https://full.url/goes/here/about\"},\n",
            "        {\"type\": \"careers page\": \"url\": \"https://another.full.url/careers\"}\n",
            "    ]\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(link_system_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5Vhza3PMpKH"
      },
      "outputs": [],
      "source": [
        "def get_links_user_prompt(website):\n",
        "    user_prompt = f\"Here is the list of links on the website of {website.url} - \"\n",
        "    user_prompt += \"please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. \\\n",
        "Do not include Terms of Service, Privacy, email links.\\n\"\n",
        "    user_prompt += \"Links (some might be relative links):\\n\"\n",
        "    user_prompt += \"\\n\".join(website.links)\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjlocjWXNBvl",
        "outputId": "18994b38-95a3-487b-9614-c2bcc377ba35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here is the list of links on the website of https://www.groupe-omf.com/ - please decide which of these are relevant web links for a brochure about the company, respond with the full https URL in JSON format. Do not include Terms of Service, Privacy, email links.\n",
            "Links (some might be relative links):\n",
            "#\n",
            "https://www.groupe-omf.com/\n",
            "https://www.facebook.com/groupeomf\n",
            "https://www.twitter.com/groupeomf\n",
            "https://www.instagram.com/groupe_omf\n",
            "https://www.linkedin.com/company/groupe-omf\n",
            "https://www.groupe-omf.com/contact/\n",
            "#\n",
            "https://www.groupe-omf.com/\n",
            "#\n",
            "#\n",
            "https://www.groupe-omf.com/\n",
            "https://www.groupe-omf.com/groupe-omf/\n",
            "https://www.groupe-omf.com/mot-du-president/\n",
            "https://www.groupe-omf.com/missions-valeurs/\n",
            "https://www.groupe-omf.com/politique-qhse/\n",
            "https://www.groupe-omf.com/clients/\n",
            "/services\n",
            "https://www.groupe-omf.com/creation-de-societe/\n",
            "https://www.groupe-omf.com/tenue-de-comptabilite/\n",
            "https://www.groupe-omf.com/gestion-deleguee-de-la-paie/\n",
            "https://www.groupe-omf.com/assistance-iso/\n",
            "https://www.groupe-omf.com/expertise-rh/\n",
            "https://www.groupe-omf.com/optimisation-fiscale/\n",
            "https://www.groupe-omf.com/portage-salarial/\n",
            "https://www.groupe-omf.com/delocalisation/\n",
            "https://www.groupe-omf.com/formation-professionnelle-continue/\n",
            "https://www.groupe-omf.com/ingenierie-de-formation/\n",
            "https://www.groupe-omf.com/subvention/\n",
            "/media-technologie\n",
            "https://www.groupe-omf.com/audit-diagnostics/\n",
            "https://www.groupe-omf.com/transformation-numerique/\n",
            "https://www.groupe-omf.com/strategie-de-communication/\n",
            "https://www.groupe-omf.com/strategie-digitale/\n",
            "https://www.groupe-omf.com/digital/\n",
            "https://www.groupe-omf.com/community-management/\n",
            "https://www.groupe-omf.com/content-marketing/\n",
            "https://www.groupe-omf.com/relations-publiques-presse/\n",
            "https://www.groupe-omf.com/smart4apps-labs/\n",
            "https://www.groupe-omf.com/smart-crm/\n",
            "https://www.groupe-omf.com/smart-gep/\n",
            "https://www.groupe-omf.com/smart-project/\n",
            "https://www.groupe-omf.com/contact/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/media-technologie/\n",
            "https://www.groupe-omf.com/contact/\n",
            "https://www.groupe-omf.com/services/\n",
            "https://www.groupe-omf.com/tenue-de-comptabilite/\n",
            "https://www.groupe-omf.com/tenue-de-comptabilite/\n",
            "https://www.groupe-omf.com/tenue-de-comptabilite/\n",
            "https://www.groupe-omf.com/assistance-iso/\n",
            "https://www.groupe-omf.com/assistance-iso/\n",
            "https://www.groupe-omf.com/assistance-iso/\n",
            "https://www.groupe-omf.com/optimisation-fiscale/\n",
            "https://www.groupe-omf.com/optimisation-fiscale/\n",
            "https://www.groupe-omf.com/optimisation-fiscale/\n",
            "https://www.groupe-omf.com/expertise-rh/\n",
            "https://www.groupe-omf.com/expertise-rh/\n",
            "https://www.groupe-omf.com/expertise-rh/\n",
            "https://www.groupe-omf.com/strategie-de-communication/\n",
            "https://www.groupe-omf.com/strategie-de-communication/\n",
            "https://www.groupe-omf.com/strategie-de-communication/\n",
            "https://www.groupe-omf.com/smart4apps-labs/\n",
            "https://www.groupe-omf.com/smart4apps-labs/\n",
            "https://www.groupe-omf.com/smart4apps-labs/\n",
            "https://www.groupe-omf.com/missions-valeurs/\n",
            "https://www.groupe-omf.com/missions-valeurs/\n",
            "https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/\n",
            "https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/\n",
            "https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/\n",
            "https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/\n",
            "https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/\n",
            "https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/\n",
            "https://www.groupe-omf.com/blog/\n",
            "career\n",
            "https://www.groupe-omf.com/?page_id=1606\n",
            "https://www.groupe-omf.com/?page_id=1606\n",
            "/cdn-cgi/l/email-protection\n",
            "https://twitter.com/bold_themes\n",
            "#\n",
            "about\n",
            "https://www.groupe-omf.com/?page_id=1606\n",
            "https://www.groupe-omf.com/?page_id=1606\n",
            "/cdn-cgi/l/email-protection\n",
            "https://twitter.com/bold_themes\n",
            "#\n",
            "about\n",
            "https://www.groupe-omf.com/?page_id=1606\n",
            "https://www.groupe-omf.com/?page_id=1606\n",
            "/cdn-cgi/l/email-protection\n",
            "https://twitter.com/bold_themes\n",
            "#\n",
            "about\n",
            "https://www.groupe-omf.com/mot-du-president/\n",
            "#\n",
            "#\n",
            "#\n",
            "https://www.groupe-omf.com/groupe-omf/\n",
            "https://www.groupe-omf.com/mot-du-president/\n",
            "https://www.groupe-omf.com/missions-valeurs/\n",
            "https://www.groupe-omf.com/politique-qhse/\n",
            "https://www.groupe-omf.com/clients/\n",
            "https://www.groupe-omf.com/creation-de-societe/\n",
            "https://www.groupe-omf.com/tenue-de-comptabilite/\n",
            "https://www.groupe-omf.com/gestion-deleguee-de-la-paie/\n",
            "https://www.groupe-omf.com/assistance-iso/\n",
            "https://www.groupe-omf.com/expertise-rh/\n",
            "https://www.groupe-omf.com/audit-diagnostics/\n",
            "https://www.groupe-omf.com/strategie-de-communication/\n",
            "https://www.groupe-omf.com/strategie-digitale/\n",
            "https://www.groupe-omf.com/transformation-numerique/\n",
            "https://www.facebook.com/groupeomf\n",
            "https://www.twitter.com/groupeomf\n",
            "https://www.instagram.com/groupe_omf\n",
            "https://www.linkedin.com/company/groupe-omf\n",
            "#\n",
            "#\n"
          ]
        }
      ],
      "source": [
        "print(get_links_user_prompt(ed))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDYtBLooNBya"
      },
      "outputs": [],
      "source": [
        "def get_links(url):\n",
        "    website = Website(url)\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": link_system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_links_user_prompt(website)}\n",
        "      ],\n",
        "        response_format={\"type\": \"json_object\"}\n",
        "    )\n",
        "    result = response.choices[0].message.content\n",
        "    return json.loads(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOJQyTQbMzmF",
        "outputId": "e5bef1c4-3999-4bbc-d648-237759ec3e82"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['#',\n",
              " 'https://www.groupe-omf.com/',\n",
              " 'https://www.facebook.com/groupeomf',\n",
              " 'https://www.twitter.com/groupeomf',\n",
              " 'https://www.instagram.com/groupe_omf',\n",
              " 'https://www.linkedin.com/company/groupe-omf',\n",
              " 'https://www.groupe-omf.com/contact/',\n",
              " '#',\n",
              " 'https://www.groupe-omf.com/',\n",
              " '#',\n",
              " '#',\n",
              " 'https://www.groupe-omf.com/',\n",
              " 'https://www.groupe-omf.com/groupe-omf/',\n",
              " 'https://www.groupe-omf.com/mot-du-president/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/politique-qhse/',\n",
              " 'https://www.groupe-omf.com/clients/',\n",
              " '/services',\n",
              " 'https://www.groupe-omf.com/creation-de-societe/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/gestion-deleguee-de-la-paie/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/portage-salarial/',\n",
              " 'https://www.groupe-omf.com/delocalisation/',\n",
              " 'https://www.groupe-omf.com/formation-professionnelle-continue/',\n",
              " 'https://www.groupe-omf.com/ingenierie-de-formation/',\n",
              " 'https://www.groupe-omf.com/subvention/',\n",
              " '/media-technologie',\n",
              " 'https://www.groupe-omf.com/audit-diagnostics/',\n",
              " 'https://www.groupe-omf.com/transformation-numerique/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-digitale/',\n",
              " 'https://www.groupe-omf.com/digital/',\n",
              " 'https://www.groupe-omf.com/community-management/',\n",
              " 'https://www.groupe-omf.com/content-marketing/',\n",
              " 'https://www.groupe-omf.com/relations-publiques-presse/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/smart-crm/',\n",
              " 'https://www.groupe-omf.com/smart-gep/',\n",
              " 'https://www.groupe-omf.com/smart-project/',\n",
              " 'https://www.groupe-omf.com/contact/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/media-technologie/',\n",
              " 'https://www.groupe-omf.com/contact/',\n",
              " 'https://www.groupe-omf.com/services/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/optimisation-fiscale/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/smart4apps-labs/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/',\n",
              " 'https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/',\n",
              " 'https://www.groupe-omf.com/linteroperabilite-entraine-une-croissance-radicale/',\n",
              " 'https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/',\n",
              " 'https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/',\n",
              " 'https://www.groupe-omf.com/applications-et-avantages-de-lia-dans-la-finance/',\n",
              " 'https://www.groupe-omf.com/blog/',\n",
              " 'career',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " '/cdn-cgi/l/email-protection',\n",
              " 'https://twitter.com/bold_themes',\n",
              " '#',\n",
              " 'about',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " '/cdn-cgi/l/email-protection',\n",
              " 'https://twitter.com/bold_themes',\n",
              " '#',\n",
              " 'about',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " 'https://www.groupe-omf.com/?page_id=1606',\n",
              " '/cdn-cgi/l/email-protection',\n",
              " 'https://twitter.com/bold_themes',\n",
              " '#',\n",
              " 'about',\n",
              " 'https://www.groupe-omf.com/mot-du-president/',\n",
              " '#',\n",
              " '#',\n",
              " '#',\n",
              " 'https://www.groupe-omf.com/groupe-omf/',\n",
              " 'https://www.groupe-omf.com/mot-du-president/',\n",
              " 'https://www.groupe-omf.com/missions-valeurs/',\n",
              " 'https://www.groupe-omf.com/politique-qhse/',\n",
              " 'https://www.groupe-omf.com/clients/',\n",
              " 'https://www.groupe-omf.com/creation-de-societe/',\n",
              " 'https://www.groupe-omf.com/tenue-de-comptabilite/',\n",
              " 'https://www.groupe-omf.com/gestion-deleguee-de-la-paie/',\n",
              " 'https://www.groupe-omf.com/assistance-iso/',\n",
              " 'https://www.groupe-omf.com/expertise-rh/',\n",
              " 'https://www.groupe-omf.com/audit-diagnostics/',\n",
              " 'https://www.groupe-omf.com/strategie-de-communication/',\n",
              " 'https://www.groupe-omf.com/strategie-digitale/',\n",
              " 'https://www.groupe-omf.com/transformation-numerique/',\n",
              " 'https://www.facebook.com/groupeomf',\n",
              " 'https://www.twitter.com/groupeomf',\n",
              " 'https://www.instagram.com/groupe_omf',\n",
              " 'https://www.linkedin.com/company/groupe-omf',\n",
              " '#',\n",
              " '#']"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Anthropic has made their site harder to scrape, so I'm using HuggingFace..\n",
        "\n",
        "huggingface = Website(\"https://www.groupe-omf.com/\")\n",
        "huggingface.links"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BSBRiAdMzo-",
        "outputId": "272b0638-0574-4305-88d0-90497603d7ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'links': [{'type': 'about page',\n",
              "   'url': 'https://www.groupe-omf.com/groupe-omf/'},\n",
              "  {'type': 'about page',\n",
              "   'url': 'https://www.groupe-omf.com/mot-du-president/'},\n",
              "  {'type': 'about page',\n",
              "   'url': 'https://www.groupe-omf.com/missions-valeurs/'},\n",
              "  {'type': 'careers page', 'url': 'https://www.groupe-omf.com/?page_id=1606'},\n",
              "  {'type': 'contact page', 'url': 'https://www.groupe-omf.com/contact/'}]}"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_links(\"https://www.groupe-omf.com/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-oa8QquOaSK"
      },
      "source": [
        "## Second step: make the brochure!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKUnJXU7ObhM"
      },
      "outputs": [],
      "source": [
        "def get_all_details(url):\n",
        "    result = \"Landing page:\\n\"\n",
        "    result += Website(url).get_contents()\n",
        "    links = get_links(url) ### API\n",
        "    #print(\"Found links:\", links)\n",
        "    for link in links[\"links\"]:\n",
        "        result += f\"\\n\\n{link['type']}\\n\"\n",
        "        result += Website(link[\"url\"]).get_contents()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a83C0k6sOc2Y"
      },
      "outputs": [],
      "source": [
        "print(get_all_details(\"https://www.groupe-omf.com/\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdh8eea-Ok6_"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
        "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
        "Include details of company culture, customers and careers/jobs if you have the information.\"\n",
        "\n",
        "# Or uncomment the lines below for a more humorous brochure - this demonstrates how easy it is to incorporate 'tone':\n",
        "\n",
        "# system_prompt = \"You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
        "# and creates a short humorous, entertaining, jokey brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
        "# Include details of company culture, customers and careers/jobs if you have the information.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imXuhYuXOpAe"
      },
      "outputs": [],
      "source": [
        "def get_brochure_user_prompt(company_name, url):\n",
        "    user_prompt = f\"You are looking at a company called: {company_name}\\n\"\n",
        "    user_prompt += f\"Here are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\n\"\n",
        "    user_prompt += get_all_details(url)\n",
        "    user_prompt = user_prompt[:5_000] # Truncate if more than 5,000 characters\n",
        "    return user_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NE2EC0aYOpkb",
        "outputId": "b4a52ba8-e1ee-42e7-813d-db5f8dc1d1cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You are looking at a company called: HuggingFace\\nHere are the contents of its landing page and other relevant pages; use this information to build a short brochure of the company in markdown.\\nLanding page:\\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nblack-forest-labs/FLUX.1-Kontext-dev\\nUpdated\\n8 days ago\\n•\\n155k\\n•\\n1.33k\\ntencent/Hunyuan-A13B-Instruct\\nUpdated\\n4 days ago\\n•\\n13.7k\\n•\\n712\\ngoogle/gemma-3n-E4B-it\\nUpdated\\n2 days ago\\n•\\n197k\\n•\\n458\\nTHUDM/GLM-4.1V-9B-Thinking\\nUpdated\\n2 days ago\\n•\\n7.03k\\n•\\n210\\nkyutai/tts-1.6b-en_fr\\nUpdated\\n2 days ago\\n•\\n7.19k\\n•\\n173\\nBrowse 1M+ models\\nSpaces\\nRunning\\n9.27k\\n9.27k\\nDeepSite v2\\n🐳\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\nMCP\\n567\\n567\\nFLUX.1 Kontext\\n⚡\\nKontext image editing on FLUX[dev]\\nRunning\\n1.04k\\n1.04k\\nSparc3D\\n🏃\\nNext-Gen High-Resolution 3D Model Generation\\nRunning\\non\\nZero\\n126\\n126\\nOvis U1 3B\\n🎨\\nDemo for multimodal understanding and generation\\nRunning\\non\\nZero\\n628\\n628\\nHunyuan3D-2.1\\n👻\\nImage-to-3D Generation\\nBrowse 400k+ applications\\nDatasets\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n•\\n22.9k\\n•\\n8.16k\\nHuggingFaceFW/fineweb-2\\nUpdated\\n9 days ago\\n•\\n38.3k\\n•\\n564\\nfacebook/seamless-interaction\\nUpdated\\n8 days ago\\n•\\n1\\n•\\n80\\nFreedomIntelligence/ShareGPT-4o-Image\\nUpdated\\n5 days ago\\n•\\n75\\n•\\n68\\nblack-forest-labs/kontext-bench\\nUpdated\\n10 days ago\\n•\\n34\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n•\\n766 models\\n•\\n3.52k followers\\nAI at Meta\\nEnterprise\\ncompany\\n•\\n2.17k models\\n•\\n6.7k followers\\nAmazon\\ncompany\\n•\\n20 models\\n•\\n3.27k followers\\nGoogle\\nEnterprise\\ncompany\\n•\\n1.01k models\\n•\\n18.8k followers\\nIntel\\ncompany\\n•\\n207 models\\n•\\n2.7k followers\\nMicrosoft\\ncompany\\n•\\n396 models\\n•\\n13.3k followers\\nGrammarly\\nTeam\\ncompany\\n•\\n10 models\\n•\\n166 followers\\nWriter\\nEnterprise\\ncompany\\n•\\n21 models\\n•\\n309 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n146,487\\nState-of-the-art ML for PyTorch, TensorFlow, JAX\\nDiffusers\\n29,647\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,340\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,735\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n9,868\\nFast tokenizers optimized for research & production\\nTRL\\n14,457\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n13,987\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n20,934\\nSmol library to build great agents in Python\\nPEFT\\n18,946\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,339\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,289\\nServe language models with TGI optimized toolkit\\nAccelerate\\n8,900\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord\\n\\n\\n\\nhome page\\nWebpage Title:\\nHugging Face – The AI community building the future.\\nWebpage Contents:\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nblack-forest-labs/FLUX.1-Kontext-dev\\nUpdated\\n8 days ago\\n•\\n155k\\n•\\n1.33k\\ntencent/Hunyuan-A13B-Instruct\\nUpdated\\n4 days ago\\n•\\n13.7k\\n•\\n712\\ngoogle/gemma-3n-E4B-it\\nUpdated\\n2 days ago\\n•\\n197k\\n•\\n458\\nTHUDM/GLM-4.1V-9B-Thinking\\nUpdated\\n2 days ago\\n•\\n7.03k\\n•\\n210\\nkyutai/tts-1.6b-en_fr\\nUpdated\\n2 days ago\\n•\\n7.19k\\n•\\n173\\nBrowse 1M+ models\\nSpaces\\nRunning\\n9.27k\\n9.27k\\nDeepSite v2\\n🐳\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\nMCP\\n567\\n567\\nFLUX.1 Kontext\\n⚡\\nKontext image ed'"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_brochure_user_prompt(\"HuggingFace\", \"https://huggingface.co\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TivXPEAlOwmJ"
      },
      "outputs": [],
      "source": [
        "def create_brochure(company_name, url):\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": get_brochure_user_prompt(company_name, url)}\n",
        "          ],\n",
        "    )\n",
        "    result = response.choices[0].message.content\n",
        "    display(Markdown(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkfFry8KOy-v"
      },
      "outputs": [],
      "source": [
        "Brochure = create_brochure(\"Groupe OMF\", \"https://www.groupe-omf.com/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq1ZLX2TRLsR"
      },
      "source": [
        "# 5. Generation du donnees en fonction du context de l'entreprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R29jgyyYRScl"
      },
      "outputs": [],
      "source": [
        "# Brochure de référence\n",
        "brochure = \"\"\"\n",
        "Brochure de l'entreprise: Groupe OMF\n",
        "Qui sommes-nous ?\n",
        "Groupe OMF est une entreprise marocaine dynamique, engagée à accompagner les chefs d'entreprise dans leurs défis quotidiens. Forts de plus de 20 ans d'expérience, nous nous positionnons comme le partenaire de référence pour les entreprises cherchant des solutions personnalisées et de qualité dans divers domaines, allant de la gestion à la communication, en passant par la technologie.\n",
        "\n",
        "Nos services\n",
        "Nous proposons une large gamme de services, notamment :\n",
        "\n",
        "Gestion: Aide à la planification, organisation et contrôle des ressources.\n",
        "Optimisation: Amélioration de l'utilisation des ressources pour des résultats optimaux.\n",
        "Formation: Développement des compétences des salariés pour renforcer la performance.\n",
        "Conseil: Expertise pour des décisions stratégiques et organisationnelles.\n",
        "Communication: Stratégies pour la diffusion efficace des messages d'entreprise.\n",
        "Technologie: Outils et méthodes pour la gestion de l'information numérique.\n",
        "Politique QHSE\n",
        "Chez Groupe OMF, nous attachons une grande importance à la qualité, à l'hygiène, à la sécurité et à l'environnement. Nos engagements en matière de QHSE assurent un service de haute qualité et respectueux des normes.\n",
        "\n",
        "Valeurs et culture d'entreprise\n",
        "Nous croyons fermement en :\n",
        "\n",
        "Respect: Chaque membre de notre équipe et chaque client méritent d'être respectés.\n",
        "Exemplarité: Un comportement éthique et professionnel dans toutes nos interactions.\n",
        "Innovation: Une quête constante pour s'adapter aux évolutions du marché.\n",
        "Esprit d'équipe: Collaboration pour atteindre des objectifs communs.\n",
        "Pour nos clients\n",
        "Nous sommes dédiés à fournir des solutions adaptées aux besoins spécifiques de nos clients, en mettant l'accent sur la satisfaction client et l'innovation continue. Nos clients proviennent de divers secteurs et tirent parti de notre expertise pour atteindre leurs ambitions.\n",
        "\n",
        "Carrières chez Groupe OMF\n",
        "Nous recherchons des talents motivés et passionnés à rejoindre notre équipe. Notre processus de recrutement est rigoureux et vise à identifier des candidats qui partagent nos valeurs. Nous offrons des opportunités de développement professionnel grâce à des formations continues et un environnement de travail collaboratif.\n",
        "\n",
        "Contactez-nous\n",
        "Adresse:\n",
        "Residence Abdelmoumen, Bd Raphael,\n",
        "Casablanca 20102, Maroc\n",
        "\n",
        "Téléphone:\n",
        "+212 522 27 35 38\n",
        "\n",
        "Email: Nous Contacter\n",
        "\n",
        "Visitez notre site web pour plus d’informations sur nos services et opportunités de carrière.\n",
        "\n",
        "Groupe OMF – Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nn4hzMSzRmbV"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"Tu es un expert en création de questionnaires d'entreprise. Tu dois retourner les résultats sous forme de liste Python de tuples [(question, réponse), ...].\"\n",
        "\n",
        "# Générateur de Questions/Réponses\n",
        "def generate_qa(profile, type_question, brochure_text, nb=20):\n",
        "    instruction = \"\"\n",
        "    if type_question == \"personnalisées\":\n",
        "        instruction = (\n",
        "            f\"Génère {nb} paires Question/Réponse pour un utilisateur de type '{profile}' concernant l'entreprise ci-dessous. \"\n",
        "            \"Les réponses doivent être précises et compréhensibles selon le niveau de l'utilisateur.\"\n",
        "        )\n",
        "    elif type_question == \"communes\":\n",
        "        instruction = (\n",
        "            f\"Génère {nb} questions communes sur l'entreprise ci-dessous. \"\n",
        "            \"Pour chaque question, donne 3 réponses : une pour 'Simple', une pour 'Dev', et une pour 'Admin'.\"\n",
        "        )\n",
        "    elif type_question == \"hors_contexte\":\n",
        "        instruction = (\n",
        "            f\"Génère {nb} paires Question/Réponse absurdes ou hors contexte, mais dans un format professionnel et amusant.\"\n",
        "        )\n",
        "\n",
        "    prompt = f\"{instruction}\\nVoici la brochure de l'entreprise :\\n{brochure_text}\"\n",
        "\n",
        "    response = openai.chat.completions.create(\n",
        "        model=MODEL,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMkzh0nASBGt"
      },
      "source": [
        "## Questions / Reponses personnalisées"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1KNxbNbRqL0"
      },
      "outputs": [],
      "source": [
        "# ⚙️ Exécution\n",
        "questions_simple = generate_qa(\"Simple\", \"personnalisées\", brochure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIqto-oASOz2",
        "outputId": "e4ed094f-d2c6-4ebf-bc46-d1f591e046ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "questions_reponses = [\n",
            "    (\"Qui est le Groupe OMF ?\", \"Le Groupe OMF est une entreprise marocaine dynamique qui accompagne les chefs d'entreprise depuis plus de 20 ans.\"),\n",
            "    (\"Quels services propose le Groupe OMF ?\", \"Le Groupe OMF propose des services en gestion, optimisation, formation, conseil, communication et technologie.\"),\n",
            "    (\"Quelle est l'expertise du Groupe OMF ?\", \"Le Groupe OMF offre une expertise pour aider à la prise de décisions stratégiques et organisationnelles.\"),\n",
            "    (\"Comment le Groupe OMF assure-t-il la qualité de ses services ?\", \"Le Groupe OMF respecte une politique QHSE qui met l'accent sur la qualité, l'hygiène, la sécurité et l'environnement.\"),\n",
            "    (\"Quelles sont les valeurs du Groupe OMF ?\", \"Les valeurs du Groupe OMF incluent le respect, l'exemplarité, l'innovation et l'esprit d'équipe.\"),\n",
            "    (\"Où est situé le Groupe OMF ?\", \"Le Groupe OMF est situé à Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.\"),\n",
            "    (\"Quel est le numéro de téléphone du Groupe OMF ?\", \"Le numéro de téléphone du Groupe OMF est +212 522 27 35 38.\"),\n",
            "    (\"Comment peut-on contacter le Groupe OMF par email ?\", \"Pour contacter le Groupe OMF par email, il faut se référer à leur site web pour plus d'informations.\"),\n",
            "    (\"Quels types de clients le Groupe OMF sert-il ?\", \"Le Groupe OMF sert des clients provenant de divers secteurs, en s'adaptant à leurs besoins spécifiques.\"),\n",
            "    (\"Pourquoi le Groupe OMF est-il un bon partenaire pour les entreprises ?\", \"Le Groupe OMF est perçu comme un partenaire de référence grâce à son expérience et ses solutions personnalisées.\"),\n",
            "    (\"Que signifie le terme QHSE ?\", \"QHSE signifie Qualité, Hygiène, Sécurité et Environnement.\"),\n",
            "    (\"Quelle approche le Groupe OMF utilise-t-il pour la formation ?\", \"Le Groupe OMF propose des formations pour développer les compétences des salariés et améliorer la performance.\"),\n",
            "    (\"Comment le Groupe OMF aide-t-il à l'optimisation des ressources ?\", \"Le Groupe OMF travaille à améliorer l'utilisation des ressources pour des résultats optimaux.\"),\n",
            "    (\"Quelles sont les possibilités de carrières au Groupe OMF ?\", \"Le Groupe OMF recherche des talents motivés et offre des opportunités de développement professionnel.\"),\n",
            "    (\"Quelle est l'importance de l'esprit d'équipe pour le Groupe OMF ?\", \"L'esprit d'équipe est essentiel pour collaborer et atteindre des objectifs communs au sein de l'entreprise.\"),\n",
            "    (\"Comment le Groupe OMF reste-t-il innovant ?\", \"Le Groupe OMF a une quête constante pour s'adapter aux évolutions du marché et proposer des solutions innovantes.\"),\n",
            "    (\"Quelle est l'importance de la satisfaction client pour le Groupe OMF ?\", \"Le Groupe OMF met un accent particulier sur la satisfaction client dans toutes ses activités et services.\"),\n",
            "    (\"Quels outils le Groupe OMF utilise pour la gestion de l'information numérique ?\", \"Le Groupe OMF utilise divers outils et méthodes technologiques pour la gestion de l'information numérique.\"),\n",
            "    (\"Comment se passe le processus de recrutement au Groupe OMF ?\", \"Le processus de recrutement est rigoureux et cherche à identifier des candidats qui partagent les valeurs de l'entreprise.\"),\n",
            "    (\"Où peut-on trouver plus d'informations sur les services du Groupe OMF ?\", \"Plus d'informations sur les services et les opportunités de carrière peuvent être trouvées sur leur site web.\")\n",
            "]\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "print(questions_simple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "varPpG_kSLkJ"
      },
      "outputs": [],
      "source": [
        "# 20 Questions spécifiques par Simple\n",
        "questions_dev = generate_qa(\"Dev\", \"personnalisées\", brochure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LKp-HDzbyte"
      },
      "outputs": [],
      "source": [
        "questions_dev = \"\"\"\n",
        "Voici une liste de 20 paires de questions et réponses adaptées à un utilisateur de type 'Dev' concernant le Groupe OMF :\n",
        "\n",
        "```python\n",
        "questions_reponses  = [\n",
        "    (\"Quelle est la mission principale du Groupe OMF ?\", \"Accompagner les chefs d'entreprise dans leurs défis quotidiens avec des solutions personnalisées.\"),\n",
        "    (\"Depuis combien d'années le Groupe OMF est-il actif ?\", \"Plus de 20 ans d'expérience.\"),\n",
        "    (\"Quels types de services propose le Groupe OMF ?\", \"Gestion, optimisation, formation, conseil, communication, et technologie.\"),\n",
        "    (\"Comment le Groupe OMF aide-t-il à la gestion des ressources ?\", \"Il fournit de l'aide à la planification, l'organisation et le contrôle des ressources.\"),\n",
        "    (\"Qu'entend-on par optimisation au sein du Groupe OMF ?\", \"Amélioration de l'utilisation des ressources pour des résultats optimaux.\"),\n",
        "    (\"Le Groupe OMF propose-t-il des formations ?\", \"Oui, pour développer les compétences des salariés et renforcer la performance.\"),\n",
        "    (\"Quel type de conseil est offert par le Groupe OMF ?\", \"Conseil stratégique et organisationnel basé sur l'expertise.\"),\n",
        "    (\"Comment le Groupe OMF aborde-t-il la communication ?\", \"En proposant des stratégies pour la diffusion efficace des messages d'entreprise.\"),\n",
        "    (\"Quels outils technologiques fournit le Groupe OMF ?\", \"Des outils et méthodes pour la gestion de l'information numérique.\"),\n",
        "    (\"Qu'est-ce que la politique QHSE au sein du Groupe OMF ?\", \"Un engagement envers la qualité, l'hygiène, la sécurité et l'environnement.\"),\n",
        "    (\"Quelles valeurs sont prônées par le Groupe OMF ?\", \"Respect, exemplarité, innovation, esprit d'équipe.\"),\n",
        "    (\"Comment le Groupe OMF garantit-il la satisfaction client ?\", \"En fournissant des solutions adaptées aux besoins spécifiques des clients.\"),\n",
        "    (\"Dans quels secteurs les clients du Groupe OMF opèrent-ils ?\", \"Divers secteurs, profitant de notre expertise pour atteindre leurs ambitions.\"),\n",
        "    (\"Quel type de candidats le Groupe OMF recherche-t-il pour ses carrières ?\", \"Des talents motivés et passionnés partageant les valeurs de l'entreprise.\"),\n",
        "    (\"Comment se déroule le processus de recrutement chez Groupe OMF ?\", \"Rigorieux, visant à identifier des candidats alignés avec nos valeurs.\"),\n",
        "    (\"Le Groupe OMF offre-t-il des opportunités de développement professionnel ?\", \"Oui, grâce à des formations continues et un environnement collaboratif.\"),\n",
        "    (\"Quelle est l'adresse du Groupe OMF ?\", \"Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.\"),\n",
        "    (\"Quel est le numéro de téléphone du Groupe OMF ?\", \"+212 522 27 35 38.\"),\n",
        "    (\"Comment peut-on contacter le Groupe OMF par email ?\", \"En utilisant le lien 'Nous Contacter' sur leur site.\"),\n",
        "    (\"Quel est l'objectif global du Groupe OMF ?\", \"Aider les entreprises à prendre des mesures décisives et à obtenir des résultats durables.\"),\n",
        "]\n",
        "```\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uosQb-4ySWdJ",
        "outputId": "944258a8-bc8e-4cdb-d221-771e364779e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Voici une liste de 20 paires de questions et réponses adaptées à un utilisateur de type 'Dev' concernant le Groupe OMF :\n",
            "\n",
            "```python\n",
            "questions_reponses  = [\n",
            "    (\"Quelle est la mission principale du Groupe OMF ?\", \"Accompagner les chefs d'entreprise dans leurs défis quotidiens avec des solutions personnalisées.\"),\n",
            "    (\"Depuis combien d'années le Groupe OMF est-il actif ?\", \"Plus de 20 ans d'expérience.\"),\n",
            "    (\"Quels types de services propose le Groupe OMF ?\", \"Gestion, optimisation, formation, conseil, communication, et technologie.\"),\n",
            "    (\"Comment le Groupe OMF aide-t-il à la gestion des ressources ?\", \"Il fournit de l'aide à la planification, l'organisation et le contrôle des ressources.\"),\n",
            "    (\"Qu'entend-on par optimisation au sein du Groupe OMF ?\", \"Amélioration de l'utilisation des ressources pour des résultats optimaux.\"),\n",
            "    (\"Le Groupe OMF propose-t-il des formations ?\", \"Oui, pour développer les compétences des salariés et renforcer la performance.\"),\n",
            "    (\"Quel type de conseil est offert par le Groupe OMF ?\", \"Conseil stratégique et organisationnel basé sur l'expertise.\"),\n",
            "    (\"Comment le Groupe OMF aborde-t-il la communication ?\", \"En proposant des stratégies pour la diffusion efficace des messages d'entreprise.\"),\n",
            "    (\"Quels outils technologiques fournit le Groupe OMF ?\", \"Des outils et méthodes pour la gestion de l'information numérique.\"),\n",
            "    (\"Qu'est-ce que la politique QHSE au sein du Groupe OMF ?\", \"Un engagement envers la qualité, l'hygiène, la sécurité et l'environnement.\"),\n",
            "    (\"Quelles valeurs sont prônées par le Groupe OMF ?\", \"Respect, exemplarité, innovation, esprit d'équipe.\"),\n",
            "    (\"Comment le Groupe OMF garantit-il la satisfaction client ?\", \"En fournissant des solutions adaptées aux besoins spécifiques des clients.\"),\n",
            "    (\"Dans quels secteurs les clients du Groupe OMF opèrent-ils ?\", \"Divers secteurs, profitant de notre expertise pour atteindre leurs ambitions.\"),\n",
            "    (\"Quel type de candidats le Groupe OMF recherche-t-il pour ses carrières ?\", \"Des talents motivés et passionnés partageant les valeurs de l'entreprise.\"),\n",
            "    (\"Comment se déroule le processus de recrutement chez Groupe OMF ?\", \"Rigorieux, visant à identifier des candidats alignés avec nos valeurs.\"),\n",
            "    (\"Le Groupe OMF offre-t-il des opportunités de développement professionnel ?\", \"Oui, grâce à des formations continues et un environnement collaboratif.\"),\n",
            "    (\"Quelle est l'adresse du Groupe OMF ?\", \"Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.\"),\n",
            "    (\"Quel est le numéro de téléphone du Groupe OMF ?\", \"+212 522 27 35 38.\"),\n",
            "    (\"Comment peut-on contacter le Groupe OMF par email ?\", \"En utilisant le lien 'Nous Contacter' sur leur site.\"),\n",
            "    (\"Quel est l'objectif global du Groupe OMF ?\", \"Aider les entreprises à prendre des mesures décisives et à obtenir des résultats durables.\"),\n",
            "]\n",
            "```\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(questions_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc6cpSYcSWsh"
      },
      "outputs": [],
      "source": [
        "questions_admin = generate_qa(\"Admin\", \"personnalisées\", brochure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Pw57GIUM5G"
      },
      "outputs": [],
      "source": [
        "print(questions_admin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UebV12oEUgJo"
      },
      "source": [
        "## Questions / Reponses Communes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebd_Fg2hUNA9"
      },
      "outputs": [],
      "source": [
        "# 20 Questions communes avec réponses multiples\n",
        "questions_communes = generate_qa(\"Tous\", \"communes\", brochure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziBV7CNkUnsm"
      },
      "outputs": [],
      "source": [
        "print(questions_communes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9tge6r7U42F"
      },
      "source": [
        "## Questions / Reponses Absurdes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9UIeoBzUn02"
      },
      "outputs": [],
      "source": [
        "questions_absurdes = generate_qa(\"Tous\", \"hors_contexte\", brochure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgWceaOnU_Yj"
      },
      "outputs": [],
      "source": [
        "print(questions_absurdes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtJXvSThZd30"
      },
      "outputs": [],
      "source": [
        "questions_absurdes = \"\"\"\n",
        "Voici une liste de 20 paires de questions/réponses absurdes ou hors contexte que vous pourriez utiliser de manière professionnelle et amusante :\n",
        "\n",
        "```python\n",
        "absurd_questions_answers = [\n",
        "    (\"Si une licorne pouvait conseiller sur la gestion des ressources, que dirait-elle ?\", \"Toujours garder une réserve de paille, c'est essentiel pour la motivation.\"),\n",
        "    (\"Quelle stratégie de communication utiliser pour vendre des glaces dans le désert ?\", \"Un mélange de sable et de crème chantilly pourrait faire des merveilles.\"),\n",
        "    (\"Comment optimiser les performances d'un hamster en roue ?\", \"Installer des panneaux solaires et un café à volonté.\"),\n",
        "    (\"Que signifie QHSE pour les robots dansant ?\", \"Qualité, Hyperbole, Sécurité Électrisante.\"),\n",
        "    (\"Pourquoi les chats sont-ils de très mauvais conseillers en carrière ?\", \"Ils préfèrent dormir sur vos décisions plutôt que de les soutenir.\"),\n",
        "    (\"Si l'innovation était un fruit, lequel serait-il ?\", \"Une mangue qui chante des chansons d'été.\"),\n",
        "    (\"Quelle est la meilleure façon de gérer une réunion avec des extraterrestres ?\", \"Prévoir un buffet intergalactique et des diapositives sur les tendances terriennes.\"),\n",
        "    (\"Comment évaluer la performance d'une équipe de pingouins ?\", \"Compter le nombre de glissades réussies sur la banquise.\"),\n",
        "    (\"Quel est l'impact des couleurs des cravates sur le moral d'un cactus ?\", \"Une cravate rouge booste la photosynthèse, paraît-il.\"),\n",
        "    (\"Comment réduire le stress d'un cactus au travail ?\", \"Offrir des séances de méditation sous un soleil radieux.\"),\n",
        "    (\"Quel est le secret de la réussite d'un poisson d'entreprise ?\", \"Un bon réseau aquatique et un sens inné des courants.\"),\n",
        "    (\"Si les ordinateurs pouvaient avoir des émotions, que diraient-ils en réunion ?\", \"J'ai besoin d'un reboot émotionnel avant de continuer.\"),\n",
        "    (\"Pourquoi la pâtisserie est-elle essentielle pour la gestion du temps ?\", \"Les macarons bipolaires sont une excellente façon de rythmer la journée.\"),\n",
        "    (\"Si nos valeurs d'entreprise étaient des super-héros, qui seraient-ils ?\", \"Le Respect aurait un costume vert, l’Innovation porterait un masque futuriste.\"),\n",
        "    (\"Quel serait le rôle d'un perroquet dans notre équipe de formation ?\", \"Remplacer le PowerPoint par des imitations de vos feedbacks.\"),\n",
        "    (\"Que feriez-vous si un message de l'espace arrivait par erreur ?\", \"Le traiter comme une opportunité de communication innovante.\"),\n",
        "    (\"Quel est le plus grand défi dans le domaine de la technologie ?\", \"Convaincre un toaster de connaître ses limites.\"),\n",
        "    (\"Comment gérer un projet avec des gnomes de jardin ?\", \"Règle n°1 : ne jamais leur tourner le dos pendant la phase de planification.\"),\n",
        "    (\"Quel est l'intérêt d'une réunion avec des nuages ?\", \"Développer des stratégies pour une couverture pluvieuse de qualité.\"),\n",
        "    (\"Si les perroquets pouvaient postuler, quel serait leur atout le plus convaincant ?\", \"Une parole en or pour chaque proposition.\")\n",
        "]\n",
        "```\n",
        "\n",
        "Ces paires de questions et réponses ajoutent une touche humoristique tout en conservant un format pouvant être utilisé dans un contexte professionnel.\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ah0eF1W2fF"
      },
      "source": [
        "# 6. Creation de la DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Nb_D5eAYFii"
      },
      "source": [
        "## Nettoyer les listes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QotZ7v-jW7yy"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import ast\n",
        "\n",
        "def extract_python_list(response_text):\n",
        "    \"\"\"\n",
        "    Extrait et convertit une liste Python présente dans un texte brut.\n",
        "    :param response_text: Chaîne contenant la liste au format texte\n",
        "    :return: La liste Python extraite, ou None si extraction échoue\n",
        "    \"\"\"\n",
        "    # Chercher le bloc ```python ... ```\n",
        "    pattern = r\"```python\\s*(.*?)```\"\n",
        "    match = re.search(pattern, response_text, re.DOTALL)\n",
        "\n",
        "    if not match:\n",
        "        print(\"⚠️ Bloc Python non trouvé.\")\n",
        "        return None\n",
        "\n",
        "    code_block = match.group(1)\n",
        "\n",
        "    # Chercher la partie contenant la liste\n",
        "    list_pattern = r\"=\\s*(\\[[\\s\\S]*\\])\"\n",
        "    list_match = re.search(list_pattern, code_block)\n",
        "\n",
        "    if not list_match:\n",
        "        print(\"⚠️ Liste non trouvée dans le bloc de code.\")\n",
        "        return None\n",
        "\n",
        "    list_str = list_match.group(1)\n",
        "\n",
        "    try:\n",
        "        extracted_list = ast.literal_eval(list_str)\n",
        "        return extracted_list\n",
        "    except Exception as e:\n",
        "        print(f\"Erreur lors du parsing de la liste : {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThbfjH_OYZ1T"
      },
      "outputs": [],
      "source": [
        "questions_simple_Clean = extract_python_list(questions_simple)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy77d6j1Yq8W"
      },
      "outputs": [],
      "source": [
        "len(questions_simple_Clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvkZzt3oYmVo"
      },
      "outputs": [],
      "source": [
        "questions_dev_Clean = extract_python_list(questions_dev)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPVpiRmqb9Wj"
      },
      "outputs": [],
      "source": [
        "len(questions_dev_Clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpsbabbkYmrP"
      },
      "outputs": [],
      "source": [
        "questions_admin_Clean = extract_python_list(questions_admin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gx6QnpMRY6LO"
      },
      "outputs": [],
      "source": [
        "len(questions_admin_Clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zj8WYFbzYotN"
      },
      "outputs": [],
      "source": [
        "questions_communes_Clean = extract_python_list(questions_communes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbLJM3MAZthM"
      },
      "outputs": [],
      "source": [
        "len(questions_communes_Clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6bTx2pZYo9B"
      },
      "outputs": [],
      "source": [
        "questions_absurdes_Clean = extract_python_list(questions_absurdes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O9lzuA7MW-mb"
      },
      "outputs": [],
      "source": [
        "len(questions_absurdes_Clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhcO3JA3ay6q"
      },
      "source": [
        "## Cree l'objet Pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJV0JPOBa3sO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Initialisation liste finale\n",
        "data = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OM-AjGSa30g"
      },
      "outputs": [],
      "source": [
        "# Simple\n",
        "for q, r in questions_simple_Clean:\n",
        "    data.append({\"Question\": q, \"Réponse\": r, \"Profil\": \"Simple\"})\n",
        "\n",
        "# Dev\n",
        "for q, r in questions_dev_Clean:\n",
        "    data.append({\"Question\": q, \"Réponse\": r, \"Profil\": \"Dev\"})\n",
        "\n",
        "# Admin\n",
        "for q, r in questions_admin_Clean:\n",
        "    data.append({\"Question\": q, \"Réponse\": r, \"Profil\": \"Admin\"})\n",
        "\n",
        "# Communes : une ligne par réponse et profil\n",
        "for q, r_simple, r_dev, r_admin in questions_communes_Clean:\n",
        "    data.append({\"Question\": q, \"Réponse\": r_simple, \"Profil\": \"Commun_Simple\"})\n",
        "    data.append({\"Question\": q, \"Réponse\": r_dev, \"Profil\": \"Commun_Dev\"})\n",
        "    data.append({\"Question\": q, \"Réponse\": r_admin, \"Profil\": \"Commun_Admin\"})\n",
        "\n",
        "# Absurdes\n",
        "for q, r in questions_absurdes_Clean:\n",
        "    data.append({\"Question\": q, \"Réponse\": r, \"Profil\": \"Absurde\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqkwAbBia_RL"
      },
      "outputs": [],
      "source": [
        "# Création du DataFrame final\n",
        "df_total = pd.DataFrame(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbG1ZLPBc3oy"
      },
      "outputs": [],
      "source": [
        "df_total.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JopL5PG3cjVp"
      },
      "outputs": [],
      "source": [
        "# Aperçu\n",
        "df_total.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFe6UQD8crRE"
      },
      "outputs": [],
      "source": [
        "df_total['Profil'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQeLyfdscjmw"
      },
      "outputs": [],
      "source": [
        "# Optionnel : Sauvegarde\n",
        "df_total.to_csv(\"Questions_Reponses_Global_Contextialiser.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8t4TAHPIWOlp"
      },
      "source": [
        "# 7. Insertion des donnees dans ChromaDb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "gLIpO1PBeHyt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "dataset = pd.read_csv(\"Questions_Reponses_Global_Contextialiser.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcKsn8BGeTTG",
        "outputId": "402f8c92-823f-40d3-d4df-d8148e3511bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(141, 3)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWYBdaIEeYoX",
        "outputId": "7523c10b-788a-4477-ead9-421bbf40c27a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Question', 'Réponse', 'Profil'], dtype='object')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01J6g8_HgW1g",
        "outputId": "06c8d297-1bff-42b8-d5aa-db7f485a21c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Simple', 'Dev', 'Admin', 'Commun_Simple', 'Commun_Dev',\n",
              "       'Commun_Admin', 'Absurde'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Profil'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtqqQ-_9frg_",
        "outputId": "db4f6939-6248-4753-b340-db7d40c1f748"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(95,)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Question'].unique().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tswzcZe3gMwN",
        "outputId": "f0e34521-56cd-4576-de20-b71ba694e45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "****** Questions/Réponses uniques pour le profil : Simple ******\n",
            "Question : Qui est le Groupe OMF ?\n",
            "Réponse : Le Groupe OMF est une entreprise marocaine qui aide les chefs d'entreprise à relever leurs défis quotidiens.\n",
            "\n",
            "Question : Depuis combien d'années le Groupe OMF est-il actif ?\n",
            "Réponse : Nous avons plus de 20 ans d'expérience dans notre domaine.\n",
            "\n",
            "Question : Quels types de services propose le Groupe OMF ?\n",
            "Réponse : Nous proposons des services en gestion, optimisation, formation, conseil, communication et technologie.\n",
            "\n",
            "Question : Que signifie le service de gestion chez Groupe OMF ?\n",
            "Réponse : Le service de gestion aide à la planification, organisation et contrôle des ressources d'une entreprise.\n",
            "\n",
            "Question : Quel est l'objectif de l'optimisation proposée par le Groupe OMF ?\n",
            "Réponse : L'optimisation vise à améliorer l'utilisation des ressources pour des résultats optimaux.\n",
            "\n",
            "Question : Pourquoi la formation est-elle importante pour le Groupe OMF ?\n",
            "Réponse : La formation développe les compétences des salariés, renforçant ainsi la performance de l'entreprise.\n",
            "\n",
            "Question : Quel type de conseils offre le Groupe OMF ?\n",
            "Réponse : Nous offrons des conseils experts pour prendre des décisions stratégiques et organisationnelles.\n",
            "\n",
            "Question : Comment le Groupe OMF aborde-t-il la communication ?\n",
            "Réponse : Nous mettons en place des stratégies pour diffuser efficacement les messages d'entreprise.\n",
            "\n",
            "Question : Quel rôle joue la technologie chez Groupe OMF ?\n",
            "Réponse : Nous fournissons des outils et méthodes pour gérer efficacement l'information numérique.\n",
            "\n",
            "Question : Quelle est la politique QHSE du Groupe OMF ?\n",
            "Réponse : Notre politique QHSE garantit un service de haute qualité, conforme aux normes de qualité, d'hygiène, de sécurité et d'environnement.\n",
            "\n",
            "Question : Quelles sont les valeurs clés du Groupe OMF ?\n",
            "Réponse : Les valeurs clés incluent le respect, l'exemplarité, l'innovation et l'esprit d'équipe.\n",
            "\n",
            "Question : Comment le Groupe OMF assure-t-il la satisfaction client ?\n",
            "Réponse : Nous fournissons des solutions adaptées aux besoins spécifiques de nos clients et nous nous engageons dans une innovation continue.\n",
            "\n",
            "Question : Quels secteurs d'activité bénéficient des services du Groupe OMF ?\n",
            "Réponse : Nos clients proviennent de divers secteurs, tous tirent parti de notre expertise.\n",
            "\n",
            "Question : Comment puis-je postuler pour une carrière chez Groupe OMF ?\n",
            "Réponse : Nous recherchons des talents motivés et passionnés, et notre processus de recrutement est rigoureux.\n",
            "\n",
            "Question : Quelles opportunités de formation le Groupe OMF offre-t-il ?\n",
            "Réponse : Nous offrons des opportunités de développement professionnel avec des formations continues.\n",
            "\n",
            "Question : Où se situe le Groupe OMF ?\n",
            "Réponse : L'adresse est : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.\n",
            "\n",
            "Question : Quel est le numéro de téléphone du Groupe OMF ?\n",
            "Réponse : Vous pouvez nous contacter au +212 522 27 35 38.\n",
            "\n",
            "Question : Comment puis-je contacter le Groupe OMF par email ?\n",
            "Réponse : Pour nous contacter par email, veuillez visiter notre site web et utiliser le formulaire de contact.\n",
            "\n",
            "Question : Que faire si je veux plus d'informations sur les services ?\n",
            "Réponse : Vous pouvez visiter notre site web pour plus d'informations sur nos services et opportunités de carrière.\n",
            "\n",
            "Question : Quel est le message de fin du Groupe OMF ?\n",
            "Réponse : Groupe OMF – Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.\n",
            "\n",
            "\n",
            "****** Questions/Réponses uniques pour le profil : Dev ******\n",
            "Question : Quelle est la mission principale du Groupe OMF ?\n",
            "Réponse : Accompagner les chefs d'entreprise dans leurs défis quotidiens avec des solutions personnalisées.\n",
            "\n",
            "Question : Depuis combien d'années le Groupe OMF est-il actif ?\n",
            "Réponse : Plus de 20 ans d'expérience.\n",
            "\n",
            "Question : Quels types de services propose le Groupe OMF ?\n",
            "Réponse : Gestion, optimisation, formation, conseil, communication, et technologie.\n",
            "\n",
            "Question : Comment le Groupe OMF aide-t-il à la gestion des ressources ?\n",
            "Réponse : Il fournit de l'aide à la planification, l'organisation et le contrôle des ressources.\n",
            "\n",
            "Question : Qu'entend-on par optimisation au sein du Groupe OMF ?\n",
            "Réponse : Amélioration de l'utilisation des ressources pour des résultats optimaux.\n",
            "\n",
            "Question : Le Groupe OMF propose-t-il des formations ?\n",
            "Réponse : Oui, pour développer les compétences des salariés et renforcer la performance.\n",
            "\n",
            "Question : Quel type de conseil est offert par le Groupe OMF ?\n",
            "Réponse : Conseil stratégique et organisationnel basé sur l'expertise.\n",
            "\n",
            "Question : Comment le Groupe OMF aborde-t-il la communication ?\n",
            "Réponse : En proposant des stratégies pour la diffusion efficace des messages d'entreprise.\n",
            "\n",
            "Question : Quels outils technologiques fournit le Groupe OMF ?\n",
            "Réponse : Des outils et méthodes pour la gestion de l'information numérique.\n",
            "\n",
            "Question : Qu'est-ce que la politique QHSE au sein du Groupe OMF ?\n",
            "Réponse : Un engagement envers la qualité, l'hygiène, la sécurité et l'environnement.\n",
            "\n",
            "Question : Quelles valeurs sont prônées par le Groupe OMF ?\n",
            "Réponse : Respect, exemplarité, innovation, esprit d'équipe.\n",
            "\n",
            "Question : Comment le Groupe OMF garantit-il la satisfaction client ?\n",
            "Réponse : En fournissant des solutions adaptées aux besoins spécifiques des clients.\n",
            "\n",
            "Question : Dans quels secteurs les clients du Groupe OMF opèrent-ils ?\n",
            "Réponse : Divers secteurs, profitant de notre expertise pour atteindre leurs ambitions.\n",
            "\n",
            "Question : Quel type de candidats le Groupe OMF recherche-t-il pour ses carrières ?\n",
            "Réponse : Des talents motivés et passionnés partageant les valeurs de l'entreprise.\n",
            "\n",
            "Question : Comment se déroule le processus de recrutement chez Groupe OMF ?\n",
            "Réponse : Rigorieux, visant à identifier des candidats alignés avec nos valeurs.\n",
            "\n",
            "Question : Le Groupe OMF offre-t-il des opportunités de développement professionnel ?\n",
            "Réponse : Oui, grâce à des formations continues et un environnement collaboratif.\n",
            "\n",
            "Question : Quelle est l'adresse du Groupe OMF ?\n",
            "Réponse : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.\n",
            "\n",
            "Question : Quel est le numéro de téléphone du Groupe OMF ?\n",
            "Réponse : +212 522 27 35 38.\n",
            "\n",
            "Question : Comment peut-on contacter le Groupe OMF par email ?\n",
            "Réponse : En utilisant le lien 'Nous Contacter' sur leur site.\n",
            "\n",
            "Question : Quel est l'objectif global du Groupe OMF ?\n",
            "Réponse : Aider les entreprises à prendre des mesures décisives et à obtenir des résultats durables.\n",
            "\n",
            "\n",
            "****** Questions/Réponses uniques pour le profil : Admin ******\n",
            "Question : Quel est le but principal du Groupe OMF ?\n",
            "Réponse : Accompagner les chefs d'entreprise dans leurs défis quotidiens.\n",
            "\n",
            "Question : Depuis combien de temps le Groupe OMF est-il en activité ?\n",
            "Réponse : Plus de 20 ans.\n",
            "\n",
            "Question : Quels types de services propose le Groupe OMF ?\n",
            "Réponse : Gestion, optimisation, formation, conseil, communication et technologie.\n",
            "\n",
            "Question : Comment le Groupe OMF aide-t-il à la gestion des ressources ?\n",
            "Réponse : En offrant des services d'aide à la planification, l'organisation et le contrôle des ressources.\n",
            "\n",
            "Question : Quelle est l'approche du Groupe OMF en matière d'optimisation ?\n",
            "Réponse : Amélioration de l'utilisation des ressources pour obtenir des résultats optimaux.\n",
            "\n",
            "Question : Quel type de formation offre le Groupe OMF ?\n",
            "Réponse : Des formations visant à développer les compétences des salariés pour renforcer leur performance.\n",
            "\n",
            "Question : Quelle expertise le Groupe OMF fournit-il en matière de conseil ?\n",
            "Réponse : Des conseils stratégiques et organisationnels pour aider à la prise de décision.\n",
            "\n",
            "Question : Comment le Groupe OMF aborde-t-il la communication d'entreprise ?\n",
            "Réponse : En élaborant des stratégies pour assurer la diffusion efficace des messages.\n",
            "\n",
            "Question : Quels outils technologiques propose le Groupe OMF ?\n",
            "Réponse : Des outils et méthodes pour la gestion de l'information numérique.\n",
            "\n",
            "Question : Quelles sont les valeurs fondamentales du Groupe OMF ?\n",
            "Réponse : Respect, exemplarité, innovation et esprit d'équipe.\n",
            "\n",
            "Question : Comment le Groupe OMF assure-t-il la qualité et la sécurité ?\n",
            "Réponse : Grâce à une politique QHSE qui garantit un service de haute qualité.\n",
            "\n",
            "Question : En quoi consiste l'engagement QHSE du Groupe OMF ?\n",
            "Réponse : Assurer des services respectueux des normes de qualité, d'hygiène, de sécurité et d'environnement.\n",
            "\n",
            "Question : Comment le Groupe OMF répond-il aux besoins spécifiques de ses clients ?\n",
            "Réponse : En fournissant des solutions adaptées, mettant l'accent sur la satisfaction client.\n",
            "\n",
            "Question : Quels secteurs desservent les clients du Groupe OMF ?\n",
            "Réponse : Divers secteurs avec des solutions adaptées à chacun.\n",
            "\n",
            "Question : Comment le Groupe OMF s'assure-t-il de la satisfaction client ?\n",
            "Réponse : Par une innovation continue et l'adaptation aux besoins des clients.\n",
            "\n",
            "Question : Quelles opportunités de carrière sont offertes par le Groupe OMF ?\n",
            "Réponse : Des postes pour des talents motivés et passionnés, ainsi que des formations continues.\n",
            "\n",
            "Question : Quel est le processus de recrutement du Groupe OMF ?\n",
            "Réponse : Un processus rigoureux visant à identifier des candidats partageant les valeurs de l'entreprise.\n",
            "\n",
            "Question : Quels sont les principaux avantages de travailler au Groupe OMF ?\n",
            "Réponse : Développement professionnel, environnement collaboratif et possibilités de formation.\n",
            "\n",
            "Question : Comment puis-je contacter le Groupe OMF ?\n",
            "Réponse : Par téléphone au +212 522 27 35 38 ou par email via leur site web.\n",
            "\n",
            "Question : Où se situe le siège du Groupe OMF ?\n",
            "Réponse : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.\n",
            "\n",
            "Question : Quel est le slogan du Groupe OMF ?\n",
            "Réponse : Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.\n",
            "\n",
            "\n",
            "****** Questions/Réponses uniques pour le profil : Commun_Simple ******\n",
            "Question : Quelle est l'année de création de Groupe OMF ?\n",
            "Réponse : 2003\n",
            "\n",
            "Question : Quels types de services propose Groupe OMF ?\n",
            "Réponse : Gestion, optimisation et formation\n",
            "\n",
            "Question : Quelle est la principale valeur de l'entreprise ?\n",
            "Réponse : Respect\n",
            "\n",
            "Question : Comment Groupe OMF s'engage-t-elle en matière de QHSE ?\n",
            "Réponse : En suivant des normes strictes\n",
            "\n",
            "Question : Où est situé le siège de Groupe OMF ?\n",
            "Réponse : À Casablanca\n",
            "\n",
            "Question : Quels secteurs d'activité desservent-ils ?\n",
            "Réponse : Divers secteurs\n",
            "\n",
            "Question : Comment les clients peuvent-ils contacter Groupe OMF ?\n",
            "Réponse : Par téléphone ou par email\n",
            "\n",
            "Question : Quel est le principal objectif de l'entreprise ?\n",
            "Réponse : Aider les entreprises à résoudre des problèmes\n",
            "\n",
            "Question : Qu'est-ce qui caractérise l'esprit d'équipe chez Groupe OMF ?\n",
            "Réponse : Collaboration\n",
            "\n",
            "Question : Quel type de formation propose Groupe OMF ?\n",
            "Réponse : Développement des compétences\n",
            "\n",
            "Question : Quel est le processus de recrutement de Groupe OMF ?\n",
            "Réponse : Rigoureux\n",
            "\n",
            "Question : Quel est l'un des principaux services offerts ?\n",
            "Réponse : Optimisation des ressources\n",
            "\n",
            "Question : Quelles technologies sont mises en œuvre par Groupe OMF ?\n",
            "Réponse : Outils de gestion informatique\n",
            "\n",
            "Question : Quel rôle joue l'innovation chez Groupe OMF ?\n",
            "Réponse : S'adapter au marché\n",
            "\n",
            "Question : Quel aspect des services de Groupe OMF est le plus valorisé par les clients ?\n",
            "Réponse : Satisfaction client\n",
            "\n",
            "Question : Quel est le numéro de téléphone de Groupe OMF ?\n",
            "Réponse : +212 522 27 35 38\n",
            "\n",
            "Question : Comment décrit-on l'importance des valeurs chez Groupe OMF ?\n",
            "Réponse : Essentielles\n",
            "\n",
            "Question : Quel type d'engagement est présent dans la politique QHSE ?\n",
            "Réponse : Respect des normes\n",
            "\n",
            "Question : Que permet la formation continue pour les employés ?\n",
            "Réponse : Développement personnel\n",
            "\n",
            "Question : Qu'est-ce qui rend Groupe OMF unique ?\n",
            "Réponse : Son approche personnalisée\n",
            "\n",
            "\n",
            "****** Questions/Réponses uniques pour le profil : Commun_Dev ******\n",
            "Question : Quelle est l'année de création de Groupe OMF ?\n",
            "Réponse : 2003\n",
            "\n",
            "Question : Quels types de services propose Groupe OMF ?\n",
            "Réponse : Gestion, optimisation, formation, technologie, communication\n",
            "\n",
            "Question : Quelle est la principale valeur de l'entreprise ?\n",
            "Réponse : Respect\n",
            "\n",
            "Question : Comment Groupe OMF s'engage-t-elle en matière de QHSE ?\n",
            "Réponse : En adoptant des normes QHSE rigoureuses\n",
            "\n",
            "Question : Où est situé le siège de Groupe OMF ?\n",
            "Réponse : À Casablanca\n",
            "\n",
            "Question : Quels secteurs d'activité desservent-ils ?\n",
            "Réponse : Divers secteurs avec des solutions adaptées\n",
            "\n",
            "Question : Comment les clients peuvent-ils contacter Groupe OMF ?\n",
            "Réponse : Par téléphone ou par email pour une réponse rapide\n",
            "\n",
            "Question : Quel est le principal objectif de l'entreprise ?\n",
            "Réponse : Aider les entreprises à prendre des mesures décisives\n",
            "\n",
            "Question : Qu'est-ce qui caractérise l'esprit d'équipe chez Groupe OMF ?\n",
            "Réponse : Collaboration pour atteindre des objectifs communs\n",
            "\n",
            "Question : Quel type de formation propose Groupe OMF ?\n",
            "Réponse : Formations sur des compétences variées\n",
            "\n",
            "Question : Quel est le processus de recrutement de Groupe OMF ?\n",
            "Réponse : Rigoureux, pour trouver les meilleurs talents\n",
            "\n",
            "Question : Quel est l'un des principaux services offerts ?\n",
            "Réponse : Optimisation et amélioration des processus\n",
            "\n",
            "Question : Quelles technologies sont mises en œuvre par Groupe OMF ?\n",
            "Réponse : Technologies pour la gestion de l'information\n",
            "\n",
            "Question : Quel rôle joue l'innovation chez Groupe OMF ?\n",
            "Réponse : Une quête constante pour innover\n",
            "\n",
            "Question : Quel aspect des services de Groupe OMF est le plus valorisé par les clients ?\n",
            "Réponse : Solutions personnalisées pour chaque client\n",
            "\n",
            "Question : Quel est le numéro de téléphone de Groupe OMF ?\n",
            "Réponse : +212 522 27 35 38\n",
            "\n",
            "Question : Comment décrit-on l'importance des valeurs chez Groupe OMF ?\n",
            "Réponse : Essentielles pour la culture d'entreprise\n",
            "\n",
            "Question : Quel type d'engagement est présent dans la politique QHSE ?\n",
            "Réponse : Engagement envers la qualité et la sécurité\n",
            "\n",
            "Question : Que permet la formation continue pour les employés ?\n",
            "Réponse : Développement professionnel\n",
            "\n",
            "Question : Qu'est-ce qui rend Groupe OMF unique ?\n",
            "Réponse : Une expérience de 20 ans\n",
            "\n",
            "\n",
            "****** Questions/Réponses uniques pour le profil : Commun_Admin ******\n",
            "Question : Quelle est l'année de création de Groupe OMF ?\n",
            "Réponse : 2003\n",
            "\n",
            "Question : Quels types de services propose Groupe OMF ?\n",
            "Réponse : Gestion, optimisation, formation, conseil, technologie, communication\n",
            "\n",
            "Question : Quelle est la principale valeur de l'entreprise ?\n",
            "Réponse : Respect\n",
            "\n",
            "Question : Comment Groupe OMF s'engage-t-elle en matière de QHSE ?\n",
            "Réponse : En respectant des engagements QHSE qui garantissent la qualité\n",
            "\n",
            "Question : Où est situé le siège de Groupe OMF ?\n",
            "Réponse : Résidence Abdelmoumen, Casablanca 20102\n",
            "\n",
            "Question : Quels secteurs d'activité desservent-ils ?\n",
            "Réponse : Divers secteurs incluant ceux nécessitant une gestion complexe\n",
            "\n",
            "Question : Comment les clients peuvent-ils contacter Groupe OMF ?\n",
            "Réponse : Par téléphone, email ou site web pour toutes demandes\n",
            "\n",
            "Question : Quel est le principal objectif de l'entreprise ?\n",
            "Réponse : Aider les entreprises en leur fournissant des solutions sur mesure\n",
            "\n",
            "Question : Qu'est-ce qui caractérise l'esprit d'équipe chez Groupe OMF ?\n",
            "Réponse : Collaboration et soutien mutuel dans les projets\n",
            "\n",
            "Question : Quel type de formation propose Groupe OMF ?\n",
            "Réponse : Formations adaptées aux besoins du marché et des entreprises\n",
            "\n",
            "Question : Quel est le processus de recrutement de Groupe OMF ?\n",
            "Réponse : Rigoureux avec un accent sur les valeurs et la culture d'entreprise\n",
            "\n",
            "Question : Quel est l'un des principaux services offerts ?\n",
            "Réponse : Optimisation pour améliorer l'efficacité organisationnelle\n",
            "\n",
            "Question : Quelles technologies sont mises en œuvre par Groupe OMF ?\n",
            "Réponse : Solutions numériques pour la gestion et l'organisation\n",
            "\n",
            "Question : Quel rôle joue l'innovation chez Groupe OMF ?\n",
            "Réponse : Un élément clé de la stratégie d'entreprise\n",
            "\n",
            "Question : Quel aspect des services de Groupe OMF est le plus valorisé par les clients ?\n",
            "Réponse : Adaptabilité aux besoins spécifiques des clients\n",
            "\n",
            "Question : Quel est le numéro de téléphone de Groupe OMF ?\n",
            "Réponse : +212 522 27 35 38 pour contacter notre équipe\n",
            "\n",
            "Question : Comment décrit-on l'importance des valeurs chez Groupe OMF ?\n",
            "Réponse : Essentielles pour maintenir un bon environnement de travail\n",
            "\n",
            "Question : Quel type d'engagement est présent dans la politique QHSE ?\n",
            "Réponse : Engagement à respecter les normes QHSE\n",
            "\n",
            "Question : Que permet la formation continue pour les employés ?\n",
            "Réponse : Opportunités de croissance et d'avancement\n",
            "\n",
            "Question : Qu'est-ce qui rend Groupe OMF unique ?\n",
            "Réponse : Une forte dynamique d’innovation et d'adaptation aux besoins du marché\n",
            "\n",
            "\n",
            "****** Questions/Réponses uniques pour le profil : Absurde ******\n",
            "Question : Si une licorne pouvait conseiller sur la gestion des ressources, que dirait-elle ?\n",
            "Réponse : Toujours garder une réserve de paille, c'est essentiel pour la motivation.\n",
            "\n",
            "Question : Quelle stratégie de communication utiliser pour vendre des glaces dans le désert ?\n",
            "Réponse : Un mélange de sable et de crème chantilly pourrait faire des merveilles.\n",
            "\n",
            "Question : Comment optimiser les performances d'un hamster en roue ?\n",
            "Réponse : Installer des panneaux solaires et un café à volonté.\n",
            "\n",
            "Question : Que signifie QHSE pour les robots dansant ?\n",
            "Réponse : Qualité, Hyperbole, Sécurité Électrisante.\n",
            "\n",
            "Question : Pourquoi les chats sont-ils de très mauvais conseillers en carrière ?\n",
            "Réponse : Ils préfèrent dormir sur vos décisions plutôt que de les soutenir.\n",
            "\n",
            "Question : Si l'innovation était un fruit, lequel serait-il ?\n",
            "Réponse : Une mangue qui chante des chansons d'été.\n",
            "\n",
            "Question : Quelle est la meilleure façon de gérer une réunion avec des extraterrestres ?\n",
            "Réponse : Prévoir un buffet intergalactique et des diapositives sur les tendances terriennes.\n",
            "\n",
            "Question : Comment évaluer la performance d'une équipe de pingouins ?\n",
            "Réponse : Compter le nombre de glissades réussies sur la banquise.\n",
            "\n",
            "Question : Quel est l'impact des couleurs des cravates sur le moral d'un cactus ?\n",
            "Réponse : Une cravate rouge booste la photosynthèse, paraît-il.\n",
            "\n",
            "Question : Comment réduire le stress d'un cactus au travail ?\n",
            "Réponse : Offrir des séances de méditation sous un soleil radieux.\n",
            "\n",
            "Question : Quel est le secret de la réussite d'un poisson d'entreprise ?\n",
            "Réponse : Un bon réseau aquatique et un sens inné des courants.\n",
            "\n",
            "Question : Si les ordinateurs pouvaient avoir des émotions, que diraient-ils en réunion ?\n",
            "Réponse : J'ai besoin d'un reboot émotionnel avant de continuer.\n",
            "\n",
            "Question : Pourquoi la pâtisserie est-elle essentielle pour la gestion du temps ?\n",
            "Réponse : Les macarons bipolaires sont une excellente façon de rythmer la journée.\n",
            "\n",
            "Question : Si nos valeurs d'entreprise étaient des super-héros, qui seraient-ils ?\n",
            "Réponse : Le Respect aurait un costume vert, l’Innovation porterait un masque futuriste.\n",
            "\n",
            "Question : Quel serait le rôle d'un perroquet dans notre équipe de formation ?\n",
            "Réponse : Remplacer le PowerPoint par des imitations de vos feedbacks.\n",
            "\n",
            "Question : Que feriez-vous si un message de l'espace arrivait par erreur ?\n",
            "Réponse : Le traiter comme une opportunité de communication innovante.\n",
            "\n",
            "Question : Quel est le plus grand défi dans le domaine de la technologie ?\n",
            "Réponse : Convaincre un toaster de connaître ses limites.\n",
            "\n",
            "Question : Comment gérer un projet avec des gnomes de jardin ?\n",
            "Réponse : Règle n°1 : ne jamais leur tourner le dos pendant la phase de planification.\n",
            "\n",
            "Question : Quel est l'intérêt d'une réunion avec des nuages ?\n",
            "Réponse : Développer des stratégies pour une couverture pluvieuse de qualité.\n",
            "\n",
            "Question : Si les perroquets pouvaient postuler, quel serait leur atout le plus convaincant ?\n",
            "Réponse : Une parole en or pour chaque proposition.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for profil in dataset['Profil'].unique():\n",
        "    print(f\"\\n****** Questions/Réponses uniques pour le profil : {profil} ******\")\n",
        "\n",
        "    # On récupère les paires uniques (question, réponse) par profil\n",
        "    df_profil = dataset[dataset['Profil'] == profil][['Question', 'Réponse']].drop_duplicates()\n",
        "\n",
        "    for _, row in df_profil.iterrows():\n",
        "        print(f\"Question : {row['Question']}\\nRéponse : {row['Réponse']}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "ad-nIVkafrvF",
        "outputId": "fc98ab2b-ac45-47ef-d44b-a9ba9c976c15"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Quels types de services propose le Groupe OMF ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\\u00e9ponse\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Nous proposons des services en gestion, optimisation, formation, conseil, communication et technologie.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profil\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c000c8d1-a49b-4553-a09c-b9f22e4d4d2f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Réponse</th>\n",
              "      <th>Profil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Quels types de services propose le Groupe OMF ?</td>\n",
              "      <td>Nous proposons des services en gestion, optimi...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Quels types de services propose le Groupe OMF ?</td>\n",
              "      <td>Gestion, optimisation, formation, conseil, com...</td>\n",
              "      <td>Dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Quels types de services propose le Groupe OMF ?</td>\n",
              "      <td>Gestion, optimisation, formation, conseil, com...</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c000c8d1-a49b-4553-a09c-b9f22e4d4d2f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c000c8d1-a49b-4553-a09c-b9f22e4d4d2f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c000c8d1-a49b-4553-a09c-b9f22e4d4d2f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-88395f0c-78a8-417c-95ff-c50fa68b23eb\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-88395f0c-78a8-417c-95ff-c50fa68b23eb')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-88395f0c-78a8-417c-95ff-c50fa68b23eb button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                           Question  \\\n",
              "2   Quels types de services propose le Groupe OMF ?   \n",
              "22  Quels types de services propose le Groupe OMF ?   \n",
              "42  Quels types de services propose le Groupe OMF ?   \n",
              "\n",
              "                                              Réponse  Profil  \n",
              "2   Nous proposons des services en gestion, optimi...  Simple  \n",
              "22  Gestion, optimisation, formation, conseil, com...     Dev  \n",
              "42  Gestion, optimisation, formation, conseil, com...   Admin  "
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.loc[dataset['Question'] == \"Quels types de services propose le Groupe OMF ?\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9rA6YWhWWCO"
      },
      "source": [
        "## 7.1 Simple utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "jvnMZd2mWR_7"
      },
      "outputs": [],
      "source": [
        "#add_document(\"Simple\", \"Quelle est la capitale de la France ?\", \"Paris\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CMTIyU1ekRv",
        "outputId": "78010dff-5ebc-4824-fa67-fa0b3dd7f28d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n"
          ]
        }
      ],
      "source": [
        "for question, reponse in dataset.loc[dataset['Profil'] == 'Simple', ['Question', 'Réponse']].values:\n",
        "    add_document(\"Simple\", question, reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywkQfUNuXPbL",
        "outputId": "3ce0c8df-eda7-4ecc-990a-dbe21c5dccae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections['Simple'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqf-7LRGWaTN"
      },
      "source": [
        "## 7.2 Dev utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VHrIM9eaWec2"
      },
      "outputs": [],
      "source": [
        "# add_document(\"Dev\", \"Qu'est-ce qu'une API ?\", \"Interface de programmation permettant aux applications de communiquer entre elles.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2Z9i2KhgSBn",
        "outputId": "5e8eeaed-c935-4f5c-e04f-7d61460230c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n"
          ]
        }
      ],
      "source": [
        "for question, reponse in dataset.loc[dataset['Profil'] == 'Dev', ['Question', 'Réponse']].values:\n",
        "    add_document(\"Dev\", question, reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPlImQPBXTrz",
        "outputId": "137e28be-aa71-4d1b-b297-1d51a6cc762f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "20"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections['Dev'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwaOPcNtWjOC"
      },
      "source": [
        "## 7.3 Admin utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nH0peW43Wmob"
      },
      "outputs": [],
      "source": [
        "# add_document(\"Admin\", \"Comment installer Apache sur un serveur Linux ?\", \"Utiliser la commande 'sudo apt install apache2' sur une machine Ubuntu.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np4vLI_pgxBx",
        "outputId": "19c5384f-fd05-4677-b3e7-fb4e232d4c8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n"
          ]
        }
      ],
      "source": [
        "for question, reponse in dataset.loc[dataset['Profil'] == 'Admin', ['Question', 'Réponse']].values:\n",
        "    add_document(\"Admin\", question, reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsCz4T0TXVxB",
        "outputId": "273e0a49-05ad-4584-8327-16f37d1d1e2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections['Admin'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpEZWR82XBxS"
      },
      "source": [
        "## 7.4 Question communes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "OdjgI5jQXXJJ"
      },
      "outputs": [],
      "source": [
        "# # Question 1\n",
        "# add_document(\"Simple\", \"Qu'est-ce que le cloud ?\", \"Un espace de stockage en ligne pour conserver des fichiers accessibles partout.\")\n",
        "# add_document(\"Dev\", \"Qu'est-ce que le cloud ?\", \"Une infrastructure qui permet d'héberger et d'exécuter des applications à distance.\")\n",
        "# add_document(\"Admin\", \"Qu'est-ce que le cloud ?\", \"Un ensemble de serveurs distants offrant des services de stockage, de calcul et de réseau.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEs8VnOWSTk7",
        "outputId": "e52a946b-a59f-41e2-cc71-3cf72fa9c17b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n",
            "Ajouté avec succès dans la collection Simple\n"
          ]
        }
      ],
      "source": [
        "for question, reponse in dataset.loc[dataset['Profil'] == 'Commun_Simple', ['Question', 'Réponse']].values:\n",
        "    add_document(\"Simple\", question, reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYK987aciItA",
        "outputId": "bf57aa33-660d-47c2-de41-d6927116d4f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections['Simple'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0ZICCHJh4vV",
        "outputId": "735e0930-e818-4b63-b959-3cc56f7dfae8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n",
            "Ajouté avec succès dans la collection Dev\n"
          ]
        }
      ],
      "source": [
        "for question, reponse in dataset.loc[dataset['Profil'] == 'Commun_Dev', ['Question', 'Réponse']].values:\n",
        "    add_document(\"Dev\", question, reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4ZhgMgOiKyH",
        "outputId": "83bd01a0-be4d-4d98-83e3-0b1752f8e6c7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections['Dev'].count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQq7gTMxiAya",
        "outputId": "a020bfff-1207-4a44-9759-e64e653eb1ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n",
            "Ajouté avec succès dans la collection Admin\n"
          ]
        }
      ],
      "source": [
        "for question, reponse in dataset.loc[dataset['Profil'] == 'Commun_Admin', ['Question', 'Réponse']].values:\n",
        "    add_document(\"Admin\", question, reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgmINPAOiOU0",
        "outputId": "e70cc9be-e1d0-436f-93b7-86512877201a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "41"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "collections['Admin'].count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CqY_BcEiDaV"
      },
      "source": [
        "# 6. Test Retriver Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBYXTtOTsrkM",
        "outputId": "cf7ce258-6ba2-4689-9a38-0158cb508107"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Question', 'Réponse', 'Profil'], dtype='object')"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwADX0kWsvnt",
        "outputId": "fe7ba845-24bb-4151-b55d-3821e7e0ace4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Simple', 'Dev', 'Admin', 'Commun_Simple', 'Commun_Dev',\n",
              "       'Commun_Admin', 'Absurde'], dtype=object)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Profil'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "n1sVhvMmuWuB"
      },
      "outputs": [],
      "source": [
        "dataset['Profil'] = dataset['Profil'].replace({\n",
        "    'Commun_Simple': 'Simple',\n",
        "    'Commun_Dev': 'Dev',\n",
        "    'Commun_Admin': 'Admin'\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UzyDlHQuarv",
        "outputId": "9904c4e7-6ed3-4ab6-d5e9-88ab0003d43c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['Simple', 'Dev', 'Admin', 'Absurde'], dtype=object)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset['Profil'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LwdnbUiRu5yE",
        "outputId": "6fe6ee2d-40f9-4e7c-bdfc-fe8f47247f0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Réponse</th>\n",
              "      <th>Profil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Quelles sont les valeurs clés du Groupe OMF ?</td>\n",
              "      <td>Les valeurs clés incluent le respect, l'exempl...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Comment le Groupe OMF assure-t-il la satisfact...</td>\n",
              "      <td>Nous fournissons des solutions adaptées aux be...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Quels secteurs d'activité bénéficient des serv...</td>\n",
              "      <td>Nos clients proviennent de divers secteurs, to...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Comment puis-je postuler pour une carrière che...</td>\n",
              "      <td>Nous recherchons des talents motivés et passio...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Quelles opportunités de formation le Groupe OM...</td>\n",
              "      <td>Nous offrons des opportunités de développement...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>Que feriez-vous si un message de l'espace arri...</td>\n",
              "      <td>Le traiter comme une opportunité de communicat...</td>\n",
              "      <td>Absurde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>Quel est le plus grand défi dans le domaine de...</td>\n",
              "      <td>Convaincre un toaster de connaître ses limites.</td>\n",
              "      <td>Absurde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>Comment gérer un projet avec des gnomes de jar...</td>\n",
              "      <td>Règle n°1 : ne jamais leur tourner le dos pend...</td>\n",
              "      <td>Absurde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>Quel est l'intérêt d'une réunion avec des nuag...</td>\n",
              "      <td>Développer des stratégies pour une couverture ...</td>\n",
              "      <td>Absurde</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Si les perroquets pouvaient postuler, quel ser...</td>\n",
              "      <td>Une parole en or pour chaque proposition.</td>\n",
              "      <td>Absurde</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>131 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Question  \\\n",
              "10       Quelles sont les valeurs clés du Groupe OMF ?   \n",
              "11   Comment le Groupe OMF assure-t-il la satisfact...   \n",
              "12   Quels secteurs d'activité bénéficient des serv...   \n",
              "13   Comment puis-je postuler pour une carrière che...   \n",
              "14   Quelles opportunités de formation le Groupe OM...   \n",
              "..                                                 ...   \n",
              "136  Que feriez-vous si un message de l'espace arri...   \n",
              "137  Quel est le plus grand défi dans le domaine de...   \n",
              "138  Comment gérer un projet avec des gnomes de jar...   \n",
              "139  Quel est l'intérêt d'une réunion avec des nuag...   \n",
              "140  Si les perroquets pouvaient postuler, quel ser...   \n",
              "\n",
              "                                               Réponse   Profil  \n",
              "10   Les valeurs clés incluent le respect, l'exempl...   Simple  \n",
              "11   Nous fournissons des solutions adaptées aux be...   Simple  \n",
              "12   Nos clients proviennent de divers secteurs, to...   Simple  \n",
              "13   Nous recherchons des talents motivés et passio...   Simple  \n",
              "14   Nous offrons des opportunités de développement...   Simple  \n",
              "..                                                 ...      ...  \n",
              "136  Le traiter comme une opportunité de communicat...  Absurde  \n",
              "137    Convaincre un toaster de connaître ses limites.  Absurde  \n",
              "138  Règle n°1 : ne jamais leur tourner le dos pend...  Absurde  \n",
              "139  Développer des stratégies pour une couverture ...  Absurde  \n",
              "140          Une parole en or pour chaque proposition.  Absurde  \n",
              "\n",
              "[131 rows x 3 columns]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[10:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 679
        },
        "id": "b4tof0UMyGi7",
        "outputId": "9f586c41-c1c5-43a3-9981-81c513ac5d22"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"dupliques[['Question', 'R\\u00e9ponse', 'Profil']]\",\n  \"rows\": 71,\n  \"fields\": [\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Qu'est-ce qui rend Groupe OMF unique ?\",\n          \"Quel r\\u00f4le joue l'innovation chez Groupe OMF ?\",\n          \"Comment Groupe OMF s'engage-t-elle en mati\\u00e8re de QHSE ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"R\\u00e9ponse\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 65,\n        \"samples\": [\n          \"Outils de gestion informatique\",\n          \"Gestion, optimisation, formation, technologie, communication\",\n          \"En suivant des normes strictes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Profil\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Simple\",\n          \"Admin\",\n          \"Dev\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-9ccaab7b-ccb2-4c45-9551-c65407934933\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Réponse</th>\n",
              "      <th>Profil</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>Comment Groupe OMF s'engage-t-elle en matière ...</td>\n",
              "      <td>En suivant des normes strictes</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>Comment Groupe OMF s'engage-t-elle en matière ...</td>\n",
              "      <td>En respectant des engagements QHSE qui garanti...</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>Comment Groupe OMF s'engage-t-elle en matière ...</td>\n",
              "      <td>En adoptant des normes QHSE rigoureuses</td>\n",
              "      <td>Dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>Comment décrit-on l'importance des valeurs che...</td>\n",
              "      <td>Essentielles pour maintenir un bon environneme...</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>Comment décrit-on l'importance des valeurs che...</td>\n",
              "      <td>Essentielles pour la culture d'entreprise</td>\n",
              "      <td>Dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>Quels types de services propose Groupe OMF ?</td>\n",
              "      <td>Gestion, optimisation, formation, technologie,...</td>\n",
              "      <td>Dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>Quels types de services propose Groupe OMF ?</td>\n",
              "      <td>Gestion, optimisation, formation, conseil, tec...</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Quels types de services propose le Groupe OMF ?</td>\n",
              "      <td>Nous proposons des services en gestion, optimi...</td>\n",
              "      <td>Simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Quels types de services propose le Groupe OMF ?</td>\n",
              "      <td>Gestion, optimisation, formation, conseil, com...</td>\n",
              "      <td>Dev</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Quels types de services propose le Groupe OMF ?</td>\n",
              "      <td>Gestion, optimisation, formation, conseil, com...</td>\n",
              "      <td>Admin</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ccaab7b-ccb2-4c45-9551-c65407934933')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9ccaab7b-ccb2-4c45-9551-c65407934933 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9ccaab7b-ccb2-4c45-9551-c65407934933');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-92c1e222-ca14-4ca9-ab4a-583d50229546\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92c1e222-ca14-4ca9-ab4a-583d50229546')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-92c1e222-ca14-4ca9-ab4a-583d50229546 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                              Question  \\\n",
              "70   Comment Groupe OMF s'engage-t-elle en matière ...   \n",
              "72   Comment Groupe OMF s'engage-t-elle en matière ...   \n",
              "71   Comment Groupe OMF s'engage-t-elle en matière ...   \n",
              "111  Comment décrit-on l'importance des valeurs che...   \n",
              "110  Comment décrit-on l'importance des valeurs che...   \n",
              "..                                                 ...   \n",
              "65        Quels types de services propose Groupe OMF ?   \n",
              "66        Quels types de services propose Groupe OMF ?   \n",
              "2      Quels types de services propose le Groupe OMF ?   \n",
              "22     Quels types de services propose le Groupe OMF ?   \n",
              "42     Quels types de services propose le Groupe OMF ?   \n",
              "\n",
              "                                               Réponse  Profil  \n",
              "70                      En suivant des normes strictes  Simple  \n",
              "72   En respectant des engagements QHSE qui garanti...   Admin  \n",
              "71             En adoptant des normes QHSE rigoureuses     Dev  \n",
              "111  Essentielles pour maintenir un bon environneme...   Admin  \n",
              "110          Essentielles pour la culture d'entreprise     Dev  \n",
              "..                                                 ...     ...  \n",
              "65   Gestion, optimisation, formation, technologie,...     Dev  \n",
              "66   Gestion, optimisation, formation, conseil, tec...   Admin  \n",
              "2    Nous proposons des services en gestion, optimi...  Simple  \n",
              "22   Gestion, optimisation, formation, conseil, com...     Dev  \n",
              "42   Gestion, optimisation, formation, conseil, com...   Admin  \n",
              "\n",
              "[71 rows x 3 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Identifier les questions dupliquées (peu importe le rôle)\n",
        "dupliques = dataset[dataset.duplicated(subset=['Question'], keep=False)]\n",
        "\n",
        "# Tri facultatif pour regrouper par question\n",
        "dupliques = dupliques.sort_values(by='Question')\n",
        "\n",
        "# Affichage des colonnes souhaitées\n",
        "dupliques[['Question', 'Réponse', 'Profil']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "IwY737Tvs4as"
      },
      "outputs": [],
      "source": [
        "# dataset.loc[dataset['Profil'].isin(['Commun_Simple', 'Commun_Dev', 'Commun_Admin']), ['Question', 'Réponse']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "OzwQVcsrqMbY"
      },
      "outputs": [],
      "source": [
        "seuil = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "7OSqLQibiHXA"
      },
      "outputs": [],
      "source": [
        "# ask_question('Dev', \"Comment Groupe OMF s'engage-t-elle en matière de QHSE ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "pCWm3YerkUXn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Exemple de seuils à tester (ajuste les valeurs selon ton besoin)\n",
        "liste_seuils = np.arange(0, 1.05, 0.05)  # de 0.05 à 1.0 par pas de 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kWcxRYBkaU3",
        "outputId": "65898da7-6ffb-4a06-a58d-b2e6627e5e77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
              "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "liste_seuils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZtnoVSt-kYoW",
        "outputId": "12899277-d783-4340-dd7b-ad88be2d9e28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reponse_model =  Le Groupe OMF est une entreprise marocaine qui aide les chefs d'entreprise à relever leurs défis quotidiens.  ; reponse_attendue =  Le Groupe OMF est une entreprise marocaine qui aide les chefs d'entreprise à relever leurs défis quotidiens.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous avons plus de 20 ans d'expérience dans notre domaine.  ; reponse_attendue =  Nous avons plus de 20 ans d'expérience dans notre domaine.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous proposons des services en gestion, optimisation, formation, conseil, communication et technologie.  ; reponse_attendue =  Nous proposons des services en gestion, optimisation, formation, conseil, communication et technologie.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Le service de gestion aide à la planification, organisation et contrôle des ressources d'une entreprise.  ; reponse_attendue =  Le service de gestion aide à la planification, organisation et contrôle des ressources d'une entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  L'optimisation vise à améliorer l'utilisation des ressources pour des résultats optimaux.  ; reponse_attendue =  L'optimisation vise à améliorer l'utilisation des ressources pour des résultats optimaux.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  La formation développe les compétences des salariés, renforçant ainsi la performance de l'entreprise.  ; reponse_attendue =  La formation développe les compétences des salariés, renforçant ainsi la performance de l'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous offrons des conseils experts pour prendre des décisions stratégiques et organisationnelles.  ; reponse_attendue =  Nous offrons des conseils experts pour prendre des décisions stratégiques et organisationnelles.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous mettons en place des stratégies pour diffuser efficacement les messages d'entreprise.  ; reponse_attendue =  Nous mettons en place des stratégies pour diffuser efficacement les messages d'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous fournissons des outils et méthodes pour gérer efficacement l'information numérique.  ; reponse_attendue =  Nous fournissons des outils et méthodes pour gérer efficacement l'information numérique.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Notre politique QHSE garantit un service de haute qualité, conforme aux normes de qualité, d'hygiène, de sécurité et d'environnement.  ; reponse_attendue =  Notre politique QHSE garantit un service de haute qualité, conforme aux normes de qualité, d'hygiène, de sécurité et d'environnement.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Les valeurs clés incluent le respect, l'exemplarité, l'innovation et l'esprit d'équipe.  ; reponse_attendue =  Les valeurs clés incluent le respect, l'exemplarité, l'innovation et l'esprit d'équipe.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous fournissons des solutions adaptées aux besoins spécifiques de nos clients et nous nous engageons dans une innovation continue.  ; reponse_attendue =  Nous fournissons des solutions adaptées aux besoins spécifiques de nos clients et nous nous engageons dans une innovation continue.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nos clients proviennent de divers secteurs, tous tirent parti de notre expertise.  ; reponse_attendue =  Nos clients proviennent de divers secteurs, tous tirent parti de notre expertise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous recherchons des talents motivés et passionnés, et notre processus de recrutement est rigoureux.  ; reponse_attendue =  Nous recherchons des talents motivés et passionnés, et notre processus de recrutement est rigoureux.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous offrons des opportunités de développement professionnel avec des formations continues.  ; reponse_attendue =  Nous offrons des opportunités de développement professionnel avec des formations continues.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  L'adresse est : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  ; reponse_attendue =  L'adresse est : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Vous pouvez nous contacter au +212 522 27 35 38.  ; reponse_attendue =  Vous pouvez nous contacter au +212 522 27 35 38.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Pour nous contacter par email, veuillez visiter notre site web et utiliser le formulaire de contact.  ; reponse_attendue =  Pour nous contacter par email, veuillez visiter notre site web et utiliser le formulaire de contact.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Vous pouvez visiter notre site web pour plus d'informations sur nos services et opportunités de carrière.  ; reponse_attendue =  Vous pouvez visiter notre site web pour plus d'informations sur nos services et opportunités de carrière.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Groupe OMF – Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.  ; reponse_attendue =  Groupe OMF – Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Accompagner les chefs d'entreprise dans leurs défis quotidiens avec des solutions personnalisées.  ; reponse_attendue =  Accompagner les chefs d'entreprise dans leurs défis quotidiens avec des solutions personnalisées.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Plus de 20 ans d'expérience.  ; reponse_attendue =  Plus de 20 ans d'expérience.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Gestion, optimisation, formation, conseil, communication, et technologie.  ; reponse_attendue =  Gestion, optimisation, formation, conseil, communication, et technologie.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Il fournit de l'aide à la planification, l'organisation et le contrôle des ressources.  ; reponse_attendue =  Il fournit de l'aide à la planification, l'organisation et le contrôle des ressources.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Amélioration de l'utilisation des ressources pour des résultats optimaux.  ; reponse_attendue =  Amélioration de l'utilisation des ressources pour des résultats optimaux.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Oui, pour développer les compétences des salariés et renforcer la performance.  ; reponse_attendue =  Oui, pour développer les compétences des salariés et renforcer la performance.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Conseil stratégique et organisationnel basé sur l'expertise.  ; reponse_attendue =  Conseil stratégique et organisationnel basé sur l'expertise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En proposant des stratégies pour la diffusion efficace des messages d'entreprise.  ; reponse_attendue =  En proposant des stratégies pour la diffusion efficace des messages d'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Des outils et méthodes pour la gestion de l'information numérique.  ; reponse_attendue =  Des outils et méthodes pour la gestion de l'information numérique.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Un engagement envers la qualité, l'hygiène, la sécurité et l'environnement.  ; reponse_attendue =  Un engagement envers la qualité, l'hygiène, la sécurité et l'environnement.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Respect, exemplarité, innovation, esprit d'équipe.  ; reponse_attendue =  Respect, exemplarité, innovation, esprit d'équipe.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En fournissant des solutions adaptées aux besoins spécifiques des clients.  ; reponse_attendue =  En fournissant des solutions adaptées aux besoins spécifiques des clients.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Divers secteurs, profitant de notre expertise pour atteindre leurs ambitions.  ; reponse_attendue =  Divers secteurs, profitant de notre expertise pour atteindre leurs ambitions.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Des talents motivés et passionnés partageant les valeurs de l'entreprise.  ; reponse_attendue =  Des talents motivés et passionnés partageant les valeurs de l'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Rigorieux, visant à identifier des candidats alignés avec nos valeurs.  ; reponse_attendue =  Rigorieux, visant à identifier des candidats alignés avec nos valeurs.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Oui, grâce à des formations continues et un environnement collaboratif.  ; reponse_attendue =  Oui, grâce à des formations continues et un environnement collaboratif.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  ; reponse_attendue =  Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  +212 522 27 35 38.  ; reponse_attendue =  +212 522 27 35 38.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En utilisant le lien 'Nous Contacter' sur leur site.  ; reponse_attendue =  En utilisant le lien 'Nous Contacter' sur leur site.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Aider les entreprises à prendre des mesures décisives et à obtenir des résultats durables.  ; reponse_attendue =  Aider les entreprises à prendre des mesures décisives et à obtenir des résultats durables.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Accompagner les chefs d'entreprise dans leurs défis quotidiens.  ; reponse_attendue =  Accompagner les chefs d'entreprise dans leurs défis quotidiens.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Plus de 20 ans.  ; reponse_attendue =  Plus de 20 ans.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Gestion, optimisation, formation, conseil, communication et technologie.  ; reponse_attendue =  Gestion, optimisation, formation, conseil, communication et technologie.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En offrant des services d'aide à la planification, l'organisation et le contrôle des ressources.  ; reponse_attendue =  En offrant des services d'aide à la planification, l'organisation et le contrôle des ressources.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Amélioration de l'utilisation des ressources pour obtenir des résultats optimaux.  ; reponse_attendue =  Amélioration de l'utilisation des ressources pour obtenir des résultats optimaux.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Des formations visant à développer les compétences des salariés pour renforcer leur performance.  ; reponse_attendue =  Des formations visant à développer les compétences des salariés pour renforcer leur performance.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Des conseils stratégiques et organisationnels pour aider à la prise de décision.  ; reponse_attendue =  Des conseils stratégiques et organisationnels pour aider à la prise de décision.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En élaborant des stratégies pour assurer la diffusion efficace des messages.  ; reponse_attendue =  En élaborant des stratégies pour assurer la diffusion efficace des messages.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Des outils et méthodes pour la gestion de l'information numérique.  ; reponse_attendue =  Des outils et méthodes pour la gestion de l'information numérique.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Respect, exemplarité, innovation et esprit d'équipe.  ; reponse_attendue =  Respect, exemplarité, innovation et esprit d'équipe.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Grâce à une politique QHSE qui garantit un service de haute qualité.  ; reponse_attendue =  Grâce à une politique QHSE qui garantit un service de haute qualité.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Assurer des services respectueux des normes de qualité, d'hygiène, de sécurité et d'environnement.  ; reponse_attendue =  Assurer des services respectueux des normes de qualité, d'hygiène, de sécurité et d'environnement.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En fournissant des solutions adaptées, mettant l'accent sur la satisfaction client.  ; reponse_attendue =  En fournissant des solutions adaptées, mettant l'accent sur la satisfaction client.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Divers secteurs avec des solutions adaptées à chacun.  ; reponse_attendue =  Divers secteurs avec des solutions adaptées à chacun.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Par une innovation continue et l'adaptation aux besoins des clients.  ; reponse_attendue =  Par une innovation continue et l'adaptation aux besoins des clients.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Des postes pour des talents motivés et passionnés, ainsi que des formations continues.  ; reponse_attendue =  Des postes pour des talents motivés et passionnés, ainsi que des formations continues.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Un processus rigoureux visant à identifier des candidats partageant les valeurs de l'entreprise.  ; reponse_attendue =  Un processus rigoureux visant à identifier des candidats partageant les valeurs de l'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Développement professionnel, environnement collaboratif et possibilités de formation.  ; reponse_attendue =  Développement professionnel, environnement collaboratif et possibilités de formation.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Par téléphone au +212 522 27 35 38 ou par email via leur site web.  ; reponse_attendue =  Par téléphone au +212 522 27 35 38 ou par email via leur site web.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  ; reponse_attendue =  Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.  ; reponse_attendue =  Au service de l'entreprise, nous sommes là pour vous aider à prendre des mesures décisives et à obtenir des résultats durables.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  2003  ; reponse_attendue =  2003  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  2003  ; reponse_attendue =  2003  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  2003  ; reponse_attendue =  2003  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Gestion, optimisation et formation  ; reponse_attendue =  Gestion, optimisation et formation  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Gestion, optimisation, formation, technologie, communication  ; reponse_attendue =  Gestion, optimisation, formation, technologie, communication  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Gestion, optimisation, formation, conseil, technologie, communication  ; reponse_attendue =  Gestion, optimisation, formation, conseil, technologie, communication  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Respect  ; reponse_attendue =  Respect  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Respect  ; reponse_attendue =  Respect  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Respect  ; reponse_attendue =  Respect  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En suivant des normes strictes  ; reponse_attendue =  En suivant des normes strictes  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En adoptant des normes QHSE rigoureuses  ; reponse_attendue =  En adoptant des normes QHSE rigoureuses  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  En respectant des engagements QHSE qui garantissent la qualité  ; reponse_attendue =  En respectant des engagements QHSE qui garantissent la qualité  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  À Casablanca  ; reponse_attendue =  À Casablanca  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  À Casablanca  ; reponse_attendue =  À Casablanca  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Résidence Abdelmoumen, Casablanca 20102  ; reponse_attendue =  Résidence Abdelmoumen, Casablanca 20102  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Divers secteurs  ; reponse_attendue =  Divers secteurs  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Divers secteurs avec des solutions adaptées  ; reponse_attendue =  Divers secteurs avec des solutions adaptées  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Divers secteurs incluant ceux nécessitant une gestion complexe  ; reponse_attendue =  Divers secteurs incluant ceux nécessitant une gestion complexe  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Par téléphone ou par email  ; reponse_attendue =  Par téléphone ou par email  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Par téléphone ou par email pour une réponse rapide  ; reponse_attendue =  Par téléphone ou par email pour une réponse rapide  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Par téléphone, email ou site web pour toutes demandes  ; reponse_attendue =  Par téléphone, email ou site web pour toutes demandes  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Aider les entreprises à résoudre des problèmes  ; reponse_attendue =  Aider les entreprises à résoudre des problèmes  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Aider les entreprises à prendre des mesures décisives  ; reponse_attendue =  Aider les entreprises à prendre des mesures décisives  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Aider les entreprises en leur fournissant des solutions sur mesure  ; reponse_attendue =  Aider les entreprises en leur fournissant des solutions sur mesure  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Collaboration  ; reponse_attendue =  Collaboration  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Collaboration pour atteindre des objectifs communs  ; reponse_attendue =  Collaboration pour atteindre des objectifs communs  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Collaboration et soutien mutuel dans les projets  ; reponse_attendue =  Collaboration et soutien mutuel dans les projets  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Développement des compétences  ; reponse_attendue =  Développement des compétences  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Formations sur des compétences variées  ; reponse_attendue =  Formations sur des compétences variées  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Formations adaptées aux besoins du marché et des entreprises  ; reponse_attendue =  Formations adaptées aux besoins du marché et des entreprises  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Rigoureux  ; reponse_attendue =  Rigoureux  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Rigoureux, pour trouver les meilleurs talents  ; reponse_attendue =  Rigoureux, pour trouver les meilleurs talents  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Rigoureux avec un accent sur les valeurs et la culture d'entreprise  ; reponse_attendue =  Rigoureux avec un accent sur les valeurs et la culture d'entreprise  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Optimisation des ressources  ; reponse_attendue =  Optimisation des ressources  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Optimisation et amélioration des processus  ; reponse_attendue =  Optimisation et amélioration des processus  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Optimisation pour améliorer l'efficacité organisationnelle  ; reponse_attendue =  Optimisation pour améliorer l'efficacité organisationnelle  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Outils de gestion informatique  ; reponse_attendue =  Outils de gestion informatique  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Technologies pour la gestion de l'information  ; reponse_attendue =  Technologies pour la gestion de l'information  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Solutions numériques pour la gestion et l'organisation  ; reponse_attendue =  Solutions numériques pour la gestion et l'organisation  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  S'adapter au marché  ; reponse_attendue =  S'adapter au marché  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Une quête constante pour innover  ; reponse_attendue =  Une quête constante pour innover  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Un élément clé de la stratégie d'entreprise  ; reponse_attendue =  Un élément clé de la stratégie d'entreprise  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Satisfaction client  ; reponse_attendue =  Satisfaction client  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Solutions personnalisées pour chaque client  ; reponse_attendue =  Solutions personnalisées pour chaque client  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Adaptabilité aux besoins spécifiques des clients  ; reponse_attendue =  Adaptabilité aux besoins spécifiques des clients  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  +212 522 27 35 38  ; reponse_attendue =  +212 522 27 35 38  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  +212 522 27 35 38  ; reponse_attendue =  +212 522 27 35 38  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  +212 522 27 35 38 pour contacter notre équipe  ; reponse_attendue =  +212 522 27 35 38 pour contacter notre équipe  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Essentielles  ; reponse_attendue =  Essentielles  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Essentielles pour la culture d'entreprise  ; reponse_attendue =  Essentielles pour la culture d'entreprise  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Essentielles pour maintenir un bon environnement de travail  ; reponse_attendue =  Essentielles pour maintenir un bon environnement de travail  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Respect des normes  ; reponse_attendue =  Respect des normes  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Engagement envers la qualité et la sécurité  ; reponse_attendue =  Engagement envers la qualité et la sécurité  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Engagement à respecter les normes QHSE  ; reponse_attendue =  Engagement à respecter les normes QHSE  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Développement personnel  ; reponse_attendue =  Développement personnel  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Développement professionnel  ; reponse_attendue =  Développement professionnel  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Opportunités de croissance et d'avancement  ; reponse_attendue =  Opportunités de croissance et d'avancement  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Son approche personnalisée  ; reponse_attendue =  Son approche personnalisée  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Une expérience de 20 ans  ; reponse_attendue =  Une expérience de 20 ans  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Une forte dynamique d’innovation et d'adaptation aux besoins du marché  ; reponse_attendue =  Une forte dynamique d’innovation et d'adaptation aux besoins du marché  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "******** Seuil : 0.00 - Précision : 1.0000\n",
            "reponse_model =  Le Groupe OMF est une entreprise marocaine qui aide les chefs d'entreprise à relever leurs défis quotidiens.  ; reponse_attendue =  Le Groupe OMF est une entreprise marocaine qui aide les chefs d'entreprise à relever leurs défis quotidiens.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous avons plus de 20 ans d'expérience dans notre domaine.  ; reponse_attendue =  Nous avons plus de 20 ans d'expérience dans notre domaine.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous proposons des services en gestion, optimisation, formation, conseil, communication et technologie.  ; reponse_attendue =  Nous proposons des services en gestion, optimisation, formation, conseil, communication et technologie.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Le service de gestion aide à la planification, organisation et contrôle des ressources d'une entreprise.  ; reponse_attendue =  Le service de gestion aide à la planification, organisation et contrôle des ressources d'une entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  L'optimisation vise à améliorer l'utilisation des ressources pour des résultats optimaux.  ; reponse_attendue =  L'optimisation vise à améliorer l'utilisation des ressources pour des résultats optimaux.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  La formation développe les compétences des salariés, renforçant ainsi la performance de l'entreprise.  ; reponse_attendue =  La formation développe les compétences des salariés, renforçant ainsi la performance de l'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous offrons des conseils experts pour prendre des décisions stratégiques et organisationnelles.  ; reponse_attendue =  Nous offrons des conseils experts pour prendre des décisions stratégiques et organisationnelles.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous mettons en place des stratégies pour diffuser efficacement les messages d'entreprise.  ; reponse_attendue =  Nous mettons en place des stratégies pour diffuser efficacement les messages d'entreprise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous fournissons des outils et méthodes pour gérer efficacement l'information numérique.  ; reponse_attendue =  Nous fournissons des outils et méthodes pour gérer efficacement l'information numérique.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Notre politique QHSE garantit un service de haute qualité, conforme aux normes de qualité, d'hygiène, de sécurité et d'environnement.  ; reponse_attendue =  Notre politique QHSE garantit un service de haute qualité, conforme aux normes de qualité, d'hygiène, de sécurité et d'environnement.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Les valeurs clés incluent le respect, l'exemplarité, l'innovation et l'esprit d'équipe.  ; reponse_attendue =  Les valeurs clés incluent le respect, l'exemplarité, l'innovation et l'esprit d'équipe.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous fournissons des solutions adaptées aux besoins spécifiques de nos clients et nous nous engageons dans une innovation continue.  ; reponse_attendue =  Nous fournissons des solutions adaptées aux besoins spécifiques de nos clients et nous nous engageons dans une innovation continue.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nos clients proviennent de divers secteurs, tous tirent parti de notre expertise.  ; reponse_attendue =  Nos clients proviennent de divers secteurs, tous tirent parti de notre expertise.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous recherchons des talents motivés et passionnés, et notre processus de recrutement est rigoureux.  ; reponse_attendue =  Nous recherchons des talents motivés et passionnés, et notre processus de recrutement est rigoureux.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Nous offrons des opportunités de développement professionnel avec des formations continues.  ; reponse_attendue =  Nous offrons des opportunités de développement professionnel avec des formations continues.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  L'adresse est : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  ; reponse_attendue =  L'adresse est : Residence Abdelmoumen, Bd Raphael, Casablanca 20102, Maroc.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n",
            "reponse_model =  Vous pouvez nous contacter au +212 522 27 35 38.  ; reponse_attendue =  Vous pouvez nous contacter au +212 522 27 35 38.  \n",
            "\n",
            "reponse_model == reponse_attendue \n",
            "\n",
            "\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-71-2782687630.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mreponse_attendue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Réponse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mreponse_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_question\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'reponse_model = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreponse_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' ; reponse_attendue = '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreponse_attendue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-11-3504231652.py\u001b[0m in \u001b[0;36mask_question\u001b[0;34m(role, question)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrole\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"documents\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/models/Collection.py\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    207\u001b[0m         \"\"\"\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         query_request = self._validate_and_prepare_query_request(\n\u001b[0m\u001b[1;32m    210\u001b[0m             \u001b[0mquery_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mquery_texts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_texts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{str(e)} in {name}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36m_validate_and_prepare_query_request\u001b[0;34m(self, query_embeddings, query_texts, query_images, query_uris, ids, n_results, where, where_document, include)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mvalidate_record_set_for_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mrequest_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed_record_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_records\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0mrequest_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"embeddings\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36m_embed_record_set\u001b[0;34m(self, record_set, embeddable_fields)\u001b[0m\n\u001b[1;32m    549\u001b[0m                     )\n\u001b[1;32m    550\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecord_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[literal-required]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m         raise ValueError(\n\u001b[1;32m    553\u001b[0m             \u001b[0;34m\"Record does not contain any non-None fields that can be embedded.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/models/CollectionCommon.py\u001b[0m in \u001b[0;36m_embed\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mconfig_ef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"embedding_function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig_ef\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconfig_ef\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_embedding_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/types.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEmbeddingFunction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/utils/embedding_functions/__init__.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDocuments\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Delegate to ONNXMiniLM_L6_V2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mONNXMiniLM_L6_V2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/api/types.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEmbeddingFunction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mD\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalidate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# Generate embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;31m# Convert to list of numpy arrays for the expected Embeddings type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, documents, batch_size)\u001b[0m\n\u001b[1;32m    180\u001b[0m             }\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0mmodel_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0mlast_hidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/functools.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, instance, owner)\u001b[0m\n\u001b[1;32m    999\u001b[0m                 \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_NOT_FOUND\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_NOT_FOUND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m                     \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m                         \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/chromadb/utils/embedding_functions/onnx_mini_lm_l6_v2.py\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preferred_providers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CoreMLExecutionProvider\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         return self.ort.InferenceSession(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOWNLOAD_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXTRACTED_FOLDER_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model.onnx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0;31m# Since 1.9 onnyx runtime requires providers to be specified when there are multiple available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_inference_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_enable_fallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/onnxruntime/capi/onnxruntime_inference_collection.py\u001b[0m in \u001b[0;36m_create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;31m# initialize the C++ InferenceSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprovider_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisabled_optimizers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "meilleur_seuil = None\n",
        "meilleure_precision = 0\n",
        "\n",
        "resultats_seuils = []\n",
        "\n",
        "# Boucle sur les seuils\n",
        "for seuil_test in liste_seuils:\n",
        "    seuil = seuil_test  # Met à jour le seuil global dans tes fonctions\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    # Parcours de la dataset pour tester\n",
        "    for _, row in dataset.iterrows():\n",
        "        role = row['Profil']\n",
        "        if role == 'Absurde':\n",
        "          continue\n",
        "        question = row['Question']\n",
        "        reponse_attendue = row['Réponse']\n",
        "\n",
        "        reponse_model = ask_question(role, question)\n",
        "\n",
        "        print('reponse_model = ', reponse_model, ' ; reponse_attendue = ', reponse_attendue, ' \\n')\n",
        "        if reponse_model == reponse_attendue:\n",
        "          print('reponse_model == reponse_attendue \\n\\n')\n",
        "          correct += 1\n",
        "        total += 1\n",
        "\n",
        "    precision = correct / total if total > 0 else 0\n",
        "    resultats_seuils.append( (seuil, precision) )\n",
        "\n",
        "    print(f\"******** Seuil : {seuil:.2f} - Précision : {precision:.4f}\")\n",
        "\n",
        "    # Mise à jour du meilleur seuil\n",
        "    if precision > meilleure_precision:\n",
        "        meilleure_precision = precision\n",
        "        meilleur_seuil = seuil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VV5CweXkobi"
      },
      "outputs": [],
      "source": [
        "print(\"\\n==== Meilleur Résultat ====\")\n",
        "print(f\"Meilleur seuil : {meilleur_seuil:.2f} - Précision : {meilleure_precision:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZwF8BdTwptT"
      },
      "source": [
        "# 6. Data Set de Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVpvI9sxwupy"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Fonction utilitaire pour créer les entrées du dataset\n",
        "def create_dataset(pairs, role, is_ooc=False):\n",
        "    dataset = []\n",
        "    for question, answer in pairs:\n",
        "        dataset.append({\n",
        "            \"question\": question,\n",
        "            \"expected_answer\": (\n",
        "                \"Cette question ne correspond à aucun des rôles définis.\"\n",
        "                if is_ooc else answer\n",
        "            ),\n",
        "            \"role\": role\n",
        "        })\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzBYxZzrw0Kk"
      },
      "outputs": [],
      "source": [
        "# 1. Données simples\n",
        "list_simple = [\n",
        "    (\"Quelle est la capitale de la France ?\", \"Paris\"),\n",
        "    (\"Quel est le plus grand océan du monde ?\", \"Océan Pacifique\"),\n",
        "    (\"Combien de continents y a-t-il sur Terre ?\", \"7\"),\n",
        "    (\"Qui a écrit 'Les Misérables' ?\", \"Victor Hugo\"),\n",
        "    (\"Quelle est la monnaie officielle des États-Unis ?\", \"Dollar américain\"),\n",
        "    (\"Quel est l'animal national de l'Australie ?\", \"Kangourou\"),\n",
        "    (\"Quelle est la langue officielle du Brésil ?\", \"Portugais\"),\n",
        "    (\"Quelle est la hauteur du Mont Everest ?\", \"8 848 mètres\"),\n",
        "    (\"Dans quel pays se trouve le Taj Mahal ?\", \"Inde\"),\n",
        "    (\"Quelle est la couleur du drapeau du Japon ?\", \"Rouge et blanc\")\n",
        "]\n",
        "list_simple_re = [\n",
        "    (\"Quelle est la ville qui est la capitale de la France ?\", \"Paris\"),\n",
        "    (\"Quel est l'océan ayant la plus grande superficie ?\", \"Océan Pacifique\"),\n",
        "    (\"Combien de continents sont présents sur notre planète ?\", \"7\"),\n",
        "    (\"Quel auteur a écrit le livre 'Les Misérables' ?\", \"Victor Hugo\"),\n",
        "    (\"Quelle devise est utilisée aux États-Unis ?\", \"Dollar américain\"),\n",
        "    (\"Quel est l'animal emblématique de l'Australie ?\", \"Kangourou\"),\n",
        "    (\"Quel est le principal langage parlé au Brésil ?\", \"Portugais\"),\n",
        "    (\"Quelle est l'altitude du Mont Everest ?\", \"8 848 mètres\"),\n",
        "    (\"Où peut-on trouver le Taj Mahal ?\", \"Inde\"),\n",
        "    (\"Quelles couleurs composent le drapeau japonais ?\", \"Rouge et blanc\")\n",
        "]\n",
        "\n",
        "# 2. Données dev\n",
        "list_dev = [\n",
        "    (\"Qu'est-ce qu'une API ?\", \"Interface de programmation permettant aux applications de communiquer entre elles.\"),\n",
        "    (\"Quelle est la différence entre un tableau et une liste en Python ?\", \"Un tableau a une taille fixe, alors qu'une liste est dynamique.\"),\n",
        "    (\"Qu'est-ce qu'un framework ?\", \"Un ensemble d'outils et de bibliothèques permettant de développer des applications rapidement.\"),\n",
        "    (\"Quelle est la fonction de Git ?\", \"Git est un système de contrôle de version distribué.\"),\n",
        "    (\"Qu'est-ce qu'une base de données relationnelle ?\", \"Une base de données où les données sont organisées en tables.\"),\n",
        "    (\"À quoi sert un fichier .env ?\", \"Il est utilisé pour stocker des variables d'environnement sensibles.\"),\n",
        "    (\"Qu'est-ce que le versioning de code ?\", \"Le versioning permet de gérer les différentes versions d'un code source.\"),\n",
        "    (\"Quelle est la différence entre une méthode GET et POST en HTTP ?\", \"GET est utilisé pour récupérer des données, POST pour envoyer des données.\"),\n",
        "    (\"Que fait une instruction if en programmation ?\", \"Elle permet d'exécuter du code conditionnel.\"),\n",
        "    (\"Qu'est-ce que le principe DRY en développement ?\", \"DRY signifie 'Don't Repeat Yourself', éviter la duplication du code.\")\n",
        "]\n",
        "\n",
        "list_dev_re = [\n",
        "    (\"Qu'est-ce qu'une API et à quoi sert-elle ?\", \"Une API permet aux applications de communiquer entre elles.\"),\n",
        "    (\"Quelle distinction existe entre un tableau et une liste en Python ?\", \"Un tableau a une taille fixe, tandis qu'une liste peut être redimensionnée.\"),\n",
        "    (\"En quoi consiste un framework en développement ?\", \"Un framework est un ensemble d'outils pour faciliter le développement d'applications.\"),\n",
        "    (\"Comment Git facilite-t-il la gestion de versions ?\", \"Git permet de suivre les changements et de gérer les versions du code source.\"),\n",
        "    (\"Qu'est-ce qu'une base de données relationnelle et comment fonctionne-t-elle ?\", \"Une base de données relationnelle stocke des données sous forme de tables reliées entre elles.\"),\n",
        "    (\"À quoi sert un fichier .env dans un projet ?\", \"Un fichier .env contient des variables d'environnement, souvent utilisées pour stocker des secrets.\"),\n",
        "    (\"Qu'entend-on par versioning dans le développement de logiciels ?\", \"Le versioning permet de gérer différentes versions d'un projet de manière organisée.\"),\n",
        "    (\"Quelle est la différence entre les méthodes HTTP GET et POST ?\", \"GET est utilisé pour récupérer des données, tandis que POST est utilisé pour envoyer des données.\"),\n",
        "    (\"Que permet d'accomplir une instruction 'if' dans un programme ?\", \"L'instruction 'if' permet d'exécuter un bloc de code conditionnellement.\"),\n",
        "    (\"Quel principe est exprimé par l'acronyme DRY en développement logiciel ?\", \"DRY signifie 'Don't Repeat Yourself', il vise à éviter la duplication du code.\")\n",
        "]\n",
        "\n",
        "# 3. Données admin\n",
        "list_admin = [\n",
        "    (\"Comment installer Apache sur un serveur Linux ?\", \"Utiliser la commande 'sudo apt install apache2' sur une machine Ubuntu.\"),\n",
        "    (\"Que faire en cas de 'Disk Full' sur un serveur Linux ?\", \"Libérer de l'espace disque en supprimant des fichiers inutiles.\"),\n",
        "    (\"Comment vérifier les journaux système sur un serveur Linux ?\", \"Utiliser la commande 'journalctl' pour consulter les journaux.\"),\n",
        "    (\"Comment configurer un pare-feu sur Ubuntu ?\", \"Utiliser 'ufw' pour configurer un pare-feu.\"),\n",
        "    (\"Quelle commande permet de redémarrer un service sous Linux ?\", \"Utiliser la commande 'sudo systemctl restart <service>'.\"),\n",
        "    (\"Comment ajouter un utilisateur sur un serveur Linux ?\", \"Utiliser la commande 'sudo adduser <nom_utilisateur>'.\"),\n",
        "    (\"Comment configurer un serveur DNS sur Linux ?\", \"Modifier le fichier '/etc/resolv.conf' pour spécifier les serveurs DNS.\"),\n",
        "    (\"Que fait la commande chmod ?\", \"Elle permet de modifier les permissions d'un fichier ou d'un répertoire.\"),\n",
        "    (\"Comment configurer un serveur Nginx pour une application web ?\", \"Modifier les fichiers de configuration dans '/etc/nginx/sites-available' et activer le site.\"),\n",
        "    (\"Que faire pour sécuriser un serveur Linux contre les attaques DDoS ?\", \"Utiliser des outils comme fail2ban et configurer un pare-feu adapté.\")\n",
        "]\n",
        "\n",
        "list_admin_re = [\n",
        "    (\"Comment procéder pour installer Apache sur un serveur Linux ?\", \"Utilisez la commande 'sudo apt install apache2' sur une machine Ubuntu.\"),\n",
        "    (\"Que faire lorsqu'un serveur Linux affiche un message indiquant que l'espace disque est plein ?\", \"Libérez de l'espace disque en supprimant des fichiers inutiles ou en agrandissant la partition.\"),\n",
        "    (\"Comment accéder et analyser les journaux systèmes sur un serveur Linux ?\", \"Utilisez la commande 'journalctl' pour consulter les journaux système.\"),\n",
        "    (\"Quelle est la méthode pour configurer un pare-feu sur un serveur Ubuntu ?\", \"Utilisez 'ufw' pour activer et configurer le pare-feu sur Ubuntu.\"),\n",
        "    (\"Quelle commande faut-il utiliser pour redémarrer un service sur Linux ?\", \"La commande est 'sudo systemctl restart <service>'.\"),\n",
        "    (\"Quelle procédure faut-il suivre pour ajouter un utilisateur sur un serveur Linux ?\", \"Utilisez la commande 'sudo adduser <nom_utilisateur>' pour ajouter un utilisateur.\"),\n",
        "    (\"Comment configurer un serveur DNS sous Linux ?\", \"Modifiez le fichier '/etc/resolv.conf' pour spécifier les serveurs DNS.\"),\n",
        "    (\"Que permet de faire la commande chmod sur Linux ?\", \"La commande 'chmod' permet de modifier les permissions d'un fichier ou répertoire.\"),\n",
        "    (\"Comment mettre en place un serveur Nginx pour héberger une application web ?\", \"Modifiez les fichiers dans '/etc/nginx/sites-available' et activez le site avec un lien symbolique.\"),\n",
        "    (\"Quelles mesures prendre pour protéger un serveur Linux contre les attaques par déni de service (DDoS) ?\", \"Utilisez des outils comme fail2ban et configurez un pare-feu pour limiter les connexions malveillantes.\")\n",
        "]\n",
        "\n",
        "# 4. Données hors-contexte\n",
        "list_questions_hors = [\n",
        "    (\"Quelle est la durée d'un jour sur Mars ?\", \"24 heures 39 minutes\"),\n",
        "    (\"Qui a inventé l'ampoule électrique ?\", \"Thomas Edison\"),\n",
        "    (\"Qu'est-ce que le Big Bang ?\", \"La théorie qui décrit l'origine de l'univers à partir d'un point très dense et chaud.\"),\n",
        "    (\"Quelle est la plus grande forêt du monde ?\", \"La forêt amazonienne\"),\n",
        "    (\"Qu'est-ce qu'une éclipse solaire ?\", \"Un phénomène où la Lune passe entre la Terre et le Soleil.\"),\n",
        "    (\"Quel est l'animal le plus rapide du monde ?\", \"Le guépard\"),\n",
        "    (\"Qu'est-ce que la gravité ?\", \"La force qui attire les objets vers le centre de la Terre.\"),\n",
        "    (\"En quelle année l'Homme a-t-il marché sur la Lune pour la première fois ?\", \"1969\"),\n",
        "    (\"Quel est le pays le plus peuplé du monde ?\", \"La Chine\"),\n",
        "    (\"Qu'est-ce que l'effet de serre ?\", \"Le phénomène par lequel certains gaz emprisonnent la chaleur dans l'atmosphère terrestre.\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD9ShNVFxMJe"
      },
      "outputs": [],
      "source": [
        "# Création du dataset complet\n",
        "dataset = []\n",
        "dataset += create_dataset(list_simple, \"Simple\")\n",
        "dataset += create_dataset(list_simple_re, \"Simple\")\n",
        "dataset += create_dataset(list_dev, \"Dev\")\n",
        "dataset += create_dataset(list_dev_re, \"Dev\")\n",
        "dataset += create_dataset(list_admin, \"Admin\")\n",
        "dataset += create_dataset(list_admin_re, \"Admin\")\n",
        "dataset += create_dataset(list_questions_hors, \"Simple\", is_ooc=True)\n",
        "dataset += create_dataset(list_questions_hors, \"Dev\", is_ooc=True)\n",
        "dataset += create_dataset(list_questions_hors, \"Admin\", is_ooc=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBzEyJ5hxPXR"
      },
      "outputs": [],
      "source": [
        "# Enregistrer dans un fichier JSON\n",
        "with open(\"eval_dataset.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(dataset, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"✅ Dataset généré avec succès : rag_eval_dataset.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7xEk4XfyfkC"
      },
      "source": [
        "#7. Models : LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "oEOTvp3uyr6u"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(new_session=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ec1CCZBPYFTm",
        "outputId": "6906944a-9698-4450-b247-e20d4b6643db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch<3,>=2.2 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3,>=2.2->bitsandbytes)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.2->bitsandbytes) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n",
            "Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, bitsandbytes\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed bitsandbytes-0.46.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "# !pip install bitsandbytes transformers accelerate\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcPVnl4QYFTd"
      },
      "source": [
        "##7.1 HuggingFaceH4/zephyr-7b-beta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHFuFtKXYFTn"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMsJCBynYFTn"
      },
      "source": [
        "il est préférable de le quantifier pour optimiser les performances et réduire la consommation mémoire, surtout si tu tournes sur un GPU avec peu de VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lLvocfIYFTn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Configuration de quantization 4-bit\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "# Charger Zephyr 7B Beta\n",
        "model_name = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=quant_config,\n",
        "    torch_dtype=torch.float16\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fV9BGLOWYFTn"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "# import torch\n",
        "\n",
        "# # Modèle de traduction multilingue\n",
        "# model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "# model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRDyifn9YFTo"
      },
      "outputs": [],
      "source": [
        "# tokenizer_Llama3.pad_token_id = tokenizer_Llama3.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5wwnTL3YFTo"
      },
      "outputs": [],
      "source": [
        "# Vérifier si le modèle est bien chargé sur GPU\n",
        "import torch\n",
        "\n",
        "# Vérifie si CUDA est disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Le modèle sera chargé sur : {device}\")\n",
        "\n",
        "# Envoie explicitement le modèle sur le GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Vérifie où se trouve une couche du modèle\n",
        "print(next(model.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxUo_JJtR6ll"
      },
      "outputs": [],
      "source": [
        "prompt = \"Translate this sentence from English to French: I love machine learning\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# Génération\n",
        "outputs = model.generate(\n",
        "    **inputs,\n",
        "    max_new_tokens=50,\n",
        "    do_sample=True,\n",
        "    temperature=0.7\n",
        ")\n",
        "\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"✅ Traduction :\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tLHLjVdYFTo"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Charger le modèle sur le GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def query_Model_zephyr(question, reponse):\n",
        "    # Format the input prompt\n",
        "    #formatted_prompt = f\"Question: {question}\\n\\nRespons: {response}\"\n",
        "    formatted_prompt = f\"\"\"\n",
        "                              Voici une question posée par un utilisateur et la réponse récupérée à partir de ChromaDB.\n",
        "\n",
        "                              🔹 **Instructions claires :**\n",
        "                              - **Si la réponse récupérée est valide**, reformule-la en français avec plus de contexte et d'explications. Ajoute des émojis dynamiquement pour illustrer les concepts (ex : 🌍 pour un lieu, 🧠 pour une explication, ✅ pour une réponse correcte). Termine la réponse par ✅.\n",
        "                              - **Si la réponse est exactement \"Cette question ne correspond à aucun des rôles définis.\", alors affiche exactement :**\n",
        "                                **\"Cette question ne correspond à aucun des rôles définis. ❌\"**\n",
        "                              - **Si la réponse est exactement \" Cette question associée à un autre rôle. \", alors affiche exactement :**\n",
        "                                **\"Cette question est associée à un autre rôle. 🔄\"**\n",
        "                              - **Ne génère aucun autre texte en dehors des trois cas définis ci-dessus.**\n",
        "\n",
        "                              **⚠️ Attention :** Tu dois suivre ces règles strictement et ne pas ajouter d'explications supplémentaires si la réponse ne correspond pas aux données disponibles.\n",
        "\n",
        "                              **Longueur maximale de la réponse générée : 500 caractères.**\n",
        "\n",
        "                              Question : {question}\n",
        "                              Réponse récupérée : {reponse}\n",
        "                              💡 Réponse en français :\n",
        "                        \"\"\"\n",
        "\n",
        "\n",
        "    # Tokenization\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Génération de la réponse\n",
        "    outputs = model.generate(**inputs, max_new_tokens=100)\n",
        "\n",
        "    # Décodage du résultat\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EattU2QS5rZo"
      },
      "outputs": [],
      "source": [
        "llm_response = query_Model_zephyr(\"Quelle est la capitale de la France ?\", \"Paris\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_AOxhfLYFTo"
      },
      "outputs": [],
      "source": [
        "def query_zephyr(query:str, role:str):\n",
        "  #print('query : ', query)\n",
        "  #print('role : ', role)\n",
        "  response = ask_question(role, query)\n",
        "  print('\\nresponse ask_question : ', response)\n",
        "\n",
        "  if response == message_question_existante_autre_role:\n",
        "    return response + ' 🔄'\n",
        "  elif response==message_hors_contexte:\n",
        "    return response + ' ❌'\n",
        "  else:\n",
        "    test_answer = query_Model_zephyr(query, response)\n",
        "\n",
        "    # Extraction de la réponse en français après \"💡 Réponse en français :\"\n",
        "    start_index = test_answer.find(\"💡 Réponse en français :\") + len(\"💡 Réponse en français :\")\n",
        "    filtered_response = test_answer[start_index:].strip()\n",
        "\n",
        "    # Enlever \"Correcte !\" à la fin si nécessaire\n",
        "    filtered_response = filtered_response.replace(\"Correct\", \"\").strip()\n",
        "    print('\\nfiltered_response : ', filtered_response)\n",
        "\n",
        "    return filtered_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecTb72BJYFTp"
      },
      "source": [
        "### 6.1.1 Simple Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKRnJDGF46th"
      },
      "outputs": [],
      "source": [
        "query = \"Quelle est la capitale de la France ?\"\n",
        "role = \"Simple\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osKF7j-e5APq"
      },
      "outputs": [],
      "source": [
        "Retrivel_response = ask_question(role, query)\n",
        "Retrivel_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA7ctFlk5QZO"
      },
      "outputs": [],
      "source": [
        "llm_response = query_Model_zephyr(query, Retrivel_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxwhAbnOYFTp"
      },
      "outputs": [],
      "source": [
        "query_zephyr(\"Quelle est la capitale de la France ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGBxAHPLYFTp"
      },
      "source": [
        "### 6.1.2 Dev Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IothS7WwYFTp"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Qu'est-ce qu'une API ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nffCL_9YFTp"
      },
      "source": [
        "### 6.1.3 Admin Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0puzuPUnYFTq"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Comment installer Apache sur un serveur Linux ?\", \"Admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9JfT5NQYFTq"
      },
      "source": [
        "### 6.1.4 D'autre role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnEhKyqsYFTq"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la capitale de la France ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeSMys3yYFTq"
      },
      "source": [
        "### 6.1.5 Hors context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmOMMbKvYFTq"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la durée d'un jour sur Mars ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VZ3fZWsYFTq"
      },
      "source": [
        "### 6.1.6 Test zephyr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zsSzrqxYFTr"
      },
      "source": [
        "L’objectif de ce code est d’évaluer automatiquement la qualité des réponses générées par un modèle de type RAG (comme LLaMA2) en les comparant à des réponses attendues à l’aide de mesures de similarité lexicale et sémantique, afin de calculer une accuracy factuelle globale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9muPQ0PiYFTr"
      },
      "outputs": [],
      "source": [
        "# !pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlrwsqzQYFTr"
      },
      "outputs": [],
      "source": [
        "import re, json, unicodedata\n",
        "from rapidfuzz import fuzz, utils\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zqOHSuSzYFTr"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # 👈 nouveau nom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZSXbwsdYFTr"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    # minuscules, accents retirés, emojis & markdown supprimés\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "    text = re.sub(r\"`[^`]+`\", \" \", text)          # back‑ticks\n",
        "    text = re.sub(r\":[^:\\s]+:\", \" \", text)        # :emoji:\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)          # ponctuation\n",
        "    return \" \".join(text.lower().split())\n",
        "\n",
        "def token_f1(pred, gold):\n",
        "    p_tok, g_tok = pred.split(), gold.split()\n",
        "    common = len(set(p_tok) & set(g_tok))\n",
        "    if common == 0: return 0.0\n",
        "    prec = common / len(p_tok)\n",
        "    rec  = common / len(g_tok)\n",
        "    return 2 * prec * rec / (prec + rec)\n",
        "\n",
        "def score(pred, gold):\n",
        "    p, g = clean(pred), clean(gold)\n",
        "\n",
        "    # 1) containment\n",
        "    if g in p: return 1.0\n",
        "\n",
        "    # 2) token‑F1 rapide\n",
        "    f1 = token_f1(p, g)\n",
        "    if f1 >= 0.8: return f1          # bon seuil pour réponses courtes\n",
        "\n",
        "    # 3) Similarité sémantique\n",
        "    sim = util.cos_sim(\n",
        "        sbert.encode([p])[0],      # utilise sbert, pas model !\n",
        "        sbert.encode([g])[0]\n",
        "    ).item()\n",
        "\n",
        "    return sim                      # 0–1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fr_aHvHYFTr"
      },
      "outputs": [],
      "source": [
        "# ----------- boucle d'évaluation ----------\n",
        "total, passed = 0, 0\n",
        "with open(\"/content/eval_dataset.json\", encoding=\"utf‑8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5XmUb9kYFTs"
      },
      "outputs": [],
      "source": [
        "for row in data:\n",
        "    question   = row[\"question\"]\n",
        "    expected   = row[\"expected_answer\"]\n",
        "\n",
        "    generated  = query_zephyr(question, row[\"role\"])   # ta fonction\n",
        "    s          = score(generated, expected)\n",
        "\n",
        "    total += 1\n",
        "    if s >= 0.8:                   # seuil global\n",
        "        passed += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9IdgTp3YFTs"
      },
      "outputs": [],
      "source": [
        "accuracy = passed / total\n",
        "print(f\"Accuracy factuelle : {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QnnB4qaPbiR"
      },
      "source": [
        "##7.1 deepseek-ai/deepseek-llm-7b-chat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7bSTNzqTPbiS"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsdPbE-5PbiT"
      },
      "source": [
        "il est préférable de le quantifier pour optimiser les performances et réduire la consommation mémoire, surtout si tu tournes sur un GPU avec peu de VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6-gUlSJPbiU"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Configuration pour charger le modèle en 4 bits\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Utiliser float16 pour de meilleures perfs\n",
        "    bnb_4bit_use_double_quant=True,  # Double quantization pour réduire encore plus la mémoire\n",
        "    bnb_4bit_quant_type=\"nf4\"  # nf4 est plus efficace que fp4\n",
        ")\n",
        "\n",
        "# Charger LLaMA-2-7B-Chat avec quantization\n",
        "model_name_DeepSeek = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
        "tokenizer_DeepSeek = AutoTokenizer.from_pretrained(model_name_DeepSeek)\n",
        "model_DeepSeek = AutoModelForCausalLM.from_pretrained(model_name_DeepSeek, quantization_config=quant_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlnSZuN8PbiV"
      },
      "outputs": [],
      "source": [
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "# import torch\n",
        "\n",
        "# model_id = \"deepseek-ai/deepseek-llm-7b-chat\"\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_id, trust_remote_code=True, torch_dtype=torch.float16).to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJFzJ9sLPbiW"
      },
      "outputs": [],
      "source": [
        "# tokenizer_Llama3.pad_token_id = tokenizer_Llama3.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zyyqb9SIPbiW"
      },
      "outputs": [],
      "source": [
        "# Vérifier si le modèle est bien chargé sur GPU\n",
        "import torch\n",
        "\n",
        "# Vérifie si CUDA est disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Le modèle sera chargé sur : {device}\")\n",
        "\n",
        "# Envoie explicitement le modèle sur le GPU\n",
        "model_DeepSeek = model_DeepSeek.to(device)\n",
        "\n",
        "# Vérifie où se trouve une couche du modèle\n",
        "print(next(model_DeepSeek.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II8fucnaPbiX"
      },
      "outputs": [],
      "source": [
        "# Exemple d'input (tâche explicite, ici QA)\n",
        "input_text = \"### Instruction:\\nTraduis cette phrase en français : I love machine learning.\\n### Réponse:\\n\"\n",
        "\n",
        "inputs = tokenizer_DeepSeek(input_text, return_tensors=\"pt\").to(device)\n",
        "outputs = model_DeepSeek.generate(**inputs, max_new_tokens=100)\n",
        "result = tokenizer_DeepSeek.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"✅ Résultat :\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBwFexUiPbiY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Charger le modèle sur le GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def query_Model_DeepSeek(question, reponse):\n",
        "    # Format the input prompt\n",
        "    #formatted_prompt = f\"Question: {question}\\n\\nRespons: {response}\"\n",
        "    formatted_prompt = f\"\"\"\n",
        "                              Voici une question posée par un utilisateur et la réponse récupérée à partir de ChromaDB.\n",
        "\n",
        "                              🔹 **Instructions claires :**\n",
        "                              - **Si la réponse récupérée est valide**, reformule-la en français avec plus de contexte et d'explications. Ajoute des émojis dynamiquement pour illustrer les concepts (ex : 🌍 pour un lieu, 🧠 pour une explication, ✅ pour une réponse correcte). Termine la réponse par ✅.\n",
        "                              - **Si la réponse est exactement \"Cette question ne correspond à aucun des rôles définis.\", alors affiche exactement :**\n",
        "                                **\"Cette question ne correspond à aucun des rôles définis. ❌\"**\n",
        "                              - **Si la réponse est exactement \" Cette question associée à un autre rôle. \", alors affiche exactement :**\n",
        "                                **\"Cette question est associée à un autre rôle. 🔄\"**\n",
        "                              - **Ne génère aucun autre texte en dehors des trois cas définis ci-dessus.**\n",
        "\n",
        "                              **⚠️ Attention :** Tu dois suivre ces règles strictement et ne pas ajouter d'explications supplémentaires si la réponse ne correspond pas aux données disponibles.\n",
        "\n",
        "                              **Longueur maximale de la réponse générée : 500 caractères.**\n",
        "\n",
        "                              Question : {question}\n",
        "                              Réponse récupérée : {reponse}\n",
        "                              💡 Réponse en français :\n",
        "                        \"\"\"\n",
        "\n",
        "\n",
        "    # Tokenization\n",
        "    inputs = tokenizer_DeepSeek(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Génération de la réponse\n",
        "    outputs = model_DeepSeek.generate(**inputs, max_new_tokens=100)\n",
        "\n",
        "    # Décodage du résultat\n",
        "    result = tokenizer_DeepSeek.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Afm-g3i9PbiZ"
      },
      "outputs": [],
      "source": [
        "llm_response = query_Model_DeepSeek(\"Quelle est la capitale de la France ?\", \"Paris\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yv83psP_Pbia"
      },
      "outputs": [],
      "source": [
        "def query_DeepSeek(query:str, role:str):\n",
        "  #print('query : ', query)\n",
        "  #print('role : ', role)\n",
        "  response = ask_question(role, query)\n",
        "  print('\\nresponse ask_question : ', response)\n",
        "\n",
        "  if response == message_question_existante_autre_role:\n",
        "    return response + ' 🔄'\n",
        "  elif response==message_hors_contexte:\n",
        "    return response + ' ❌'\n",
        "  else:\n",
        "    test_answer = query_Model_DeepSeek(query, response)\n",
        "\n",
        "    # Extraction de la réponse en français après \"💡 Réponse en français :\"\n",
        "    start_index = test_answer.find(\"💡 Réponse en français :\") + len(\"💡 Réponse en français :\")\n",
        "    filtered_response = test_answer[start_index:].strip()\n",
        "\n",
        "    # Enlever \"Correcte !\" à la fin si nécessaire\n",
        "    filtered_response = filtered_response.replace(\"Correct\", \"\").strip()\n",
        "    print('\\nfiltered_response : ', filtered_response)\n",
        "\n",
        "    return filtered_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i0oUiRjPbib"
      },
      "source": [
        "### 6.1.1 Simple Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZLkgHJ1Pbic"
      },
      "outputs": [],
      "source": [
        "query = \"Quelle est la capitale de la France ?\"\n",
        "role = \"Simple\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p0UWMOEdPbic"
      },
      "outputs": [],
      "source": [
        "Retrivel_response = ask_question(role, query)\n",
        "Retrivel_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRMWmxyZPbid"
      },
      "outputs": [],
      "source": [
        "llm_response = query_Model_DeepSeek(query, Retrivel_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bia1etTRPbie"
      },
      "outputs": [],
      "source": [
        "query_DeepSeek(\"Quelle est la capitale de la France ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUJv0gVFPbif"
      },
      "source": [
        "### 6.1.2 Dev Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhuR_DbnPbif"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Qu'est-ce qu'une API ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPbJZmFqPbig"
      },
      "source": [
        "### 6.1.3 Admin Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lloKIcvPbih"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Comment installer Apache sur un serveur Linux ?\", \"Admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IEilh2fPbii"
      },
      "source": [
        "### 6.1.4 D'autre role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pjdC0vEdPbij"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la capitale de la France ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "digmosODPbik"
      },
      "source": [
        "### 6.1.5 Hors context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv8whoZ6Pbil"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la durée d'un jour sur Mars ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEAMS5iJPbil"
      },
      "source": [
        "### 6.1.6 Test DeepSeek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WeuYz4TPbim"
      },
      "source": [
        "L’objectif de ce code est d’évaluer automatiquement la qualité des réponses générées par un modèle de type RAG (comme LLaMA2) en les comparant à des réponses attendues à l’aide de mesures de similarité lexicale et sémantique, afin de calculer une accuracy factuelle globale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdvdNdLiPbin"
      },
      "outputs": [],
      "source": [
        "# !pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKmpyUUzPbin"
      },
      "outputs": [],
      "source": [
        "import re, json, unicodedata\n",
        "from rapidfuzz import fuzz, utils\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eLkwnUC4Pbio"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # 👈 nouveau nom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1BDkdSVpPbip"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    # minuscules, accents retirés, emojis & markdown supprimés\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "    text = re.sub(r\"`[^`]+`\", \" \", text)          # back‑ticks\n",
        "    text = re.sub(r\":[^:\\s]+:\", \" \", text)        # :emoji:\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)          # ponctuation\n",
        "    return \" \".join(text.lower().split())\n",
        "\n",
        "def token_f1(pred, gold):\n",
        "    p_tok, g_tok = pred.split(), gold.split()\n",
        "    common = len(set(p_tok) & set(g_tok))\n",
        "    if common == 0: return 0.0\n",
        "    prec = common / len(p_tok)\n",
        "    rec  = common / len(g_tok)\n",
        "    return 2 * prec * rec / (prec + rec)\n",
        "\n",
        "def score(pred, gold):\n",
        "    p, g = clean(pred), clean(gold)\n",
        "\n",
        "    # 1) containment\n",
        "    if g in p: return 1.0\n",
        "\n",
        "    # 2) token‑F1 rapide\n",
        "    f1 = token_f1(p, g)\n",
        "    if f1 >= 0.8: return f1          # bon seuil pour réponses courtes\n",
        "\n",
        "    # 3) Similarité sémantique\n",
        "    sim = util.cos_sim(\n",
        "        sbert.encode([p])[0],      # utilise sbert, pas model !\n",
        "        sbert.encode([g])[0]\n",
        "    ).item()\n",
        "\n",
        "    return sim                      # 0–1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-hxW3N8UPbiq"
      },
      "outputs": [],
      "source": [
        "# ----------- boucle d'évaluation ----------\n",
        "total, passed = 0, 0\n",
        "with open(\"/content/eval_dataset.json\", encoding=\"utf‑8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVCWmRyQPbiq"
      },
      "outputs": [],
      "source": [
        "for row in data:\n",
        "    question   = row[\"question\"]\n",
        "    expected   = row[\"expected_answer\"]\n",
        "\n",
        "    generated  = query_DeepSeek(question, row[\"role\"])   # ta fonction\n",
        "    s          = score(generated, expected)\n",
        "\n",
        "    total += 1\n",
        "    if s >= 0.8:                   # seuil global\n",
        "        passed += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAuLlbnqPbir"
      },
      "outputs": [],
      "source": [
        "accuracy = passed / total\n",
        "print(f\"Accuracy factuelle : {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS3abplVAskU"
      },
      "source": [
        "##7.1 google/flan-t5-small"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iid5sze8AskW"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxlX6viNAskY"
      },
      "source": [
        "il est préférable de le quantifier pour optimiser les performances et réduire la consommation mémoire, surtout si tu tournes sur un GPU avec peu de VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9do6QSCdAskY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Configuration pour charger le modèle en 4 bits\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Utiliser float16 pour de meilleures perfs\n",
        "    bnb_4bit_use_double_quant=True,  # Double quantization pour réduire encore plus la mémoire\n",
        "    bnb_4bit_quant_type=\"nf4\"  # nf4 est plus efficace que fp4\n",
        ")\n",
        "\n",
        "# Charger LLaMA-2-7B-Chat avec quantization\n",
        "model_name_FlanT5 = \"google/flan-t5-small\"\n",
        "tokenizer_FlanT5 = AutoTokenizer.from_pretrained(model_name_FlanT5)\n",
        "model_FlanT5 = AutoModelForCausalLM.from_pretrained(model_name_FlanT5, quantization_config=quant_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8qrKHeZAska"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PVDQvF9SAskb"
      },
      "outputs": [],
      "source": [
        "# tokenizer_Llama3.pad_token_id = tokenizer_Llama3.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv9nejh_Askc"
      },
      "outputs": [],
      "source": [
        "# Vérifier si le modèle est bien chargé sur GPU\n",
        "import torch\n",
        "\n",
        "# Vérifie si CUDA est disponible\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Le modèle sera chargé sur : {device}\")\n",
        "\n",
        "# Envoie explicitement le modèle sur le GPU\n",
        "model = model.to(device)\n",
        "\n",
        "# Vérifie où se trouve une couche du modèle\n",
        "print(next(model.parameters()).device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BXG7wt5DAskd"
      },
      "outputs": [],
      "source": [
        "# Exemple d'input (tâche explicite, ici QA)\n",
        "input_text = \"translate English to French: I love machine learning\"\n",
        "\n",
        "# Tokenization\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# Génération de la réponse\n",
        "outputs = model.generate(**inputs, max_length=50)\n",
        "\n",
        "# Décodage du résultat\n",
        "result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "print(\"✅ Résultat :\", result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hYZY0lnAske"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Charger le modèle sur le GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def query_Model_FlanT5(question, reponse):\n",
        "    # Format the input prompt\n",
        "    #formatted_prompt = f\"Question: {question}\\n\\nRespons: {response}\"\n",
        "    formatted_prompt = f\"\"\"\n",
        "                              Voici une question posée par un utilisateur et la réponse récupérée à partir de ChromaDB.\n",
        "\n",
        "                              🔹 **Instructions claires :**\n",
        "                              - **Si la réponse récupérée est valide**, reformule-la en français avec plus de contexte et d'explications. Ajoute des émojis dynamiquement pour illustrer les concepts (ex : 🌍 pour un lieu, 🧠 pour une explication, ✅ pour une réponse correcte). Termine la réponse par ✅.\n",
        "                              - **Si la réponse est exactement \"Cette question ne correspond à aucun des rôles définis.\", alors affiche exactement :**\n",
        "                                **\"Cette question ne correspond à aucun des rôles définis. ❌\"**\n",
        "                              - **Si la réponse est exactement \" Cette question associée à un autre rôle. \", alors affiche exactement :**\n",
        "                                **\"Cette question est associée à un autre rôle. 🔄\"**\n",
        "                              - **Ne génère aucun autre texte en dehors des trois cas définis ci-dessus.**\n",
        "\n",
        "                              **⚠️ Attention :** Tu dois suivre ces règles strictement et ne pas ajouter d'explications supplémentaires si la réponse ne correspond pas aux données disponibles.\n",
        "\n",
        "                              **Longueur maximale de la réponse générée : 500 caractères.**\n",
        "\n",
        "                              Question : {question}\n",
        "                              Réponse récupérée : {reponse}\n",
        "                              💡 Réponse en français :\n",
        "                        \"\"\"\n",
        "\n",
        "\n",
        "    # Tokenization\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Génération de la réponse\n",
        "    outputs = model.generate(**inputs, max_length=100)\n",
        "\n",
        "    # Décodage du résultat\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PViCofd-Askf"
      },
      "outputs": [],
      "source": [
        "llm_response = query_Model_FlanT5(\"Quelle est la capitale de la France ?\", \"Paris\")\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "199QiP2zAskg"
      },
      "outputs": [],
      "source": [
        "def query_FlanT5(query:str, role:str):\n",
        "  #print('query : ', query)\n",
        "  #print('role : ', role)\n",
        "  response = ask_question(role, query)\n",
        "  print('\\nresponse ask_question : ', response)\n",
        "\n",
        "  if response == message_question_existante_autre_role:\n",
        "    return response + ' 🔄'\n",
        "  elif response==message_hors_contexte:\n",
        "    return response + ' ❌'\n",
        "  else:\n",
        "    test_answer = query_Model_FlanT5(query, response)\n",
        "\n",
        "    # Extraction de la réponse en français après \"💡 Réponse en français :\"\n",
        "    start_index = test_answer.find(\"💡 Réponse en français :\") + len(\"💡 Réponse en français :\")\n",
        "    filtered_response = test_answer[start_index:].strip()\n",
        "\n",
        "    # Enlever \"Correcte !\" à la fin si nécessaire\n",
        "    filtered_response = filtered_response.replace(\"Correct\", \"\").strip()\n",
        "    print('\\nfiltered_response : ', filtered_response)\n",
        "\n",
        "    return filtered_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_HyMcbqAskg"
      },
      "source": [
        "### 6.1.1 Simple Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCuCEPOyAskh"
      },
      "outputs": [],
      "source": [
        "query = \"Quelle est la capitale de la France ?\"\n",
        "role = \"Simple\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-C6nzsqAski"
      },
      "outputs": [],
      "source": [
        "Retrivel_response = ask_question(role, query)\n",
        "Retrivel_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIJTPuj4Aski"
      },
      "outputs": [],
      "source": [
        "llm_response = query_Model_FlanT5(query, Retrivel_response)\n",
        "llm_response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvpjq1DWAskj"
      },
      "outputs": [],
      "source": [
        "query_FlanT5(\"Quelle est la capitale de la France ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdcIjxdIAskk"
      },
      "source": [
        "### 6.1.2 Dev Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pd123YVtAskl"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Qu'est-ce qu'une API ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rt-H8JbqAskl"
      },
      "source": [
        "### 6.1.3 Admin Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eaPZ4LH1Askm"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Comment installer Apache sur un serveur Linux ?\", \"Admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UeZ1gTbAskn"
      },
      "source": [
        "### 6.1.4 D'autre role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zd9IV1MxAskn"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la capitale de la France ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EX10tZwAsko"
      },
      "source": [
        "### 6.1.5 Hors context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVH_BuXJAskp"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la durée d'un jour sur Mars ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iis_CI8HAskp"
      },
      "source": [
        "### 6.1.6 Test  Mistral7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_KZuNAbAskq"
      },
      "source": [
        "L’objectif de ce code est d’évaluer automatiquement la qualité des réponses générées par un modèle de type RAG (comme LLaMA2) en les comparant à des réponses attendues à l’aide de mesures de similarité lexicale et sémantique, afin de calculer une accuracy factuelle globale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYJapZq0Askr"
      },
      "outputs": [],
      "source": [
        "# !pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d-V1nNdTAskr"
      },
      "outputs": [],
      "source": [
        "import re, json, unicodedata\n",
        "from rapidfuzz import fuzz, utils\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5t7fLnkAsks"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # 👈 nouveau nom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhviM08qAskt"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    # minuscules, accents retirés, emojis & markdown supprimés\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "    text = re.sub(r\"`[^`]+`\", \" \", text)          # back‑ticks\n",
        "    text = re.sub(r\":[^:\\s]+:\", \" \", text)        # :emoji:\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)          # ponctuation\n",
        "    return \" \".join(text.lower().split())\n",
        "\n",
        "def token_f1(pred, gold):\n",
        "    p_tok, g_tok = pred.split(), gold.split()\n",
        "    common = len(set(p_tok) & set(g_tok))\n",
        "    if common == 0: return 0.0\n",
        "    prec = common / len(p_tok)\n",
        "    rec  = common / len(g_tok)\n",
        "    return 2 * prec * rec / (prec + rec)\n",
        "\n",
        "def score(pred, gold):\n",
        "    p, g = clean(pred), clean(gold)\n",
        "\n",
        "    # 1) containment\n",
        "    if g in p: return 1.0\n",
        "\n",
        "    # 2) token‑F1 rapide\n",
        "    f1 = token_f1(p, g)\n",
        "    if f1 >= 0.8: return f1          # bon seuil pour réponses courtes\n",
        "\n",
        "    # 3) Similarité sémantique\n",
        "    sim = util.cos_sim(\n",
        "        sbert.encode([p])[0],      # utilise sbert, pas model !\n",
        "        sbert.encode([g])[0]\n",
        "    ).item()\n",
        "\n",
        "    return sim                      # 0–1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imyhDR2hAsku"
      },
      "outputs": [],
      "source": [
        "# ----------- boucle d'évaluation ----------\n",
        "total, passed = 0, 0\n",
        "with open(\"/content/eval_dataset.json\", encoding=\"utf‑8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orTJRKAMAsku"
      },
      "outputs": [],
      "source": [
        "for row in data:\n",
        "    question   = row[\"question\"]\n",
        "    expected   = row[\"expected_answer\"]\n",
        "\n",
        "    generated  = query_Mistral7(question, row[\"role\"])   # ta fonction\n",
        "    s          = score(generated, expected)\n",
        "\n",
        "    total += 1\n",
        "    if s >= 0.8:                   # seuil global\n",
        "        passed += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHk-wo4hAskv"
      },
      "outputs": [],
      "source": [
        "accuracy = passed / total\n",
        "print(f\"Accuracy factuelle : {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9RcU12eAskw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1F9IYa5e5gW"
      },
      "source": [
        "##6.1 Mistral-7B-Instruct-v0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qfa0UG2e5gX"
      },
      "outputs": [],
      "source": [
        "#!pip install bitsandbytes transformers accelerate\n",
        "#!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY86UWHXe5gY"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTb28-wBe5gZ"
      },
      "source": [
        "il est préférable de le quantifier pour optimiser les performances et réduire la consommation mémoire, surtout si tu tournes sur un GPU avec peu de VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1unZUxCMe5ga"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Configuration pour charger le modèle en 4 bits\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Utiliser float16 pour de meilleures perfs\n",
        "    bnb_4bit_use_double_quant=True,  # Double quantization pour réduire encore plus la mémoire\n",
        "    bnb_4bit_quant_type=\"nf4\"  # nf4 est plus efficace que fp4\n",
        ")\n",
        "\n",
        "# Charger LLaMA-2-7B-Chat avec quantization\n",
        "model_name_Mistral7 = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "tokenizer_Mistral7 = AutoTokenizer.from_pretrained(model_name_Mistral7)\n",
        "model_Mistral7 = AutoModelForCausalLM.from_pretrained(model_name_Mistral7, quantization_config=quant_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHBR2Qnde5gb"
      },
      "outputs": [],
      "source": [
        "# # Load model directly\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")\n",
        "# model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcozCrO8e5gb"
      },
      "outputs": [],
      "source": [
        "# tokenizer_Llama3.pad_token_id = tokenizer_Llama3.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DW4lNhyke5gc"
      },
      "outputs": [],
      "source": [
        "# Vérifier si le modèle est bien chargé sur GPU\n",
        "print(model_Mistral7.hf_device_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k9KVZt71e5gc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Charger le modèle sur le GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def query_Model_Mistral7(question, reponse):\n",
        "    # Format the input prompt\n",
        "    #formatted_prompt = f\"Question: {question}\\n\\nRespons: {response}\"\n",
        "    formatted_prompt = f\"\"\"\n",
        "                              Voici une question posée par un utilisateur et la réponse récupérée à partir de ChromaDB.\n",
        "\n",
        "                              🔹 **Instructions claires :**\n",
        "                              - **Si la réponse récupérée est valide**, reformule-la en français avec plus de contexte et d'explications. Ajoute des émojis dynamiquement pour illustrer les concepts (ex : 🌍 pour un lieu, 🧠 pour une explication, ✅ pour une réponse correcte). Termine la réponse par ✅.\n",
        "                              - **Si la réponse est exactement \"Cette question ne correspond à aucun des rôles définis.\", alors affiche exactement :**\n",
        "                                **\"Cette question ne correspond à aucun des rôles définis. ❌\"**\n",
        "                              - **Si la réponse est exactement \" Cette question associée à un autre rôle. \", alors affiche exactement :**\n",
        "                                **\"Cette question est associée à un autre rôle. 🔄\"**\n",
        "                              - **Ne génère aucun autre texte en dehors des trois cas définis ci-dessus.**\n",
        "\n",
        "                              **⚠️ Attention :** Tu dois suivre ces règles strictement et ne pas ajouter d'explications supplémentaires si la réponse ne correspond pas aux données disponibles.\n",
        "\n",
        "                              **Longueur maximale de la réponse générée : 500 caractères.**\n",
        "\n",
        "                              Question : {question}\n",
        "                              Réponse récupérée : {reponse}\n",
        "                              💡 Réponse en français :\n",
        "                        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Tokeniser l'entrée et envoyer sur le GPU\n",
        "    inputs = tokenizer_Mistral7(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Générer la réponse\n",
        "    outputs = model_Mistral7.generate(**inputs, max_length=800)\n",
        "\n",
        "    # Décoder et afficher la réponse\n",
        "    response = tokenizer_Mistral7.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYSZP5gqe5gd"
      },
      "outputs": [],
      "source": [
        "def query_Mistral7(query:str, role:str):\n",
        "  #print('query : ', query)\n",
        "  #print('role : ', role)\n",
        "  response = ask_question(role, query)\n",
        "  print('\\nresponse ask_question : ', response)\n",
        "\n",
        "  if response == message_question_existante_autre_role:\n",
        "    return response + ' 🔄'\n",
        "  elif response==message_hors_contexte:\n",
        "    return response + ' ❌'\n",
        "  else:\n",
        "    test_answer = query_Model_Mistral7(query, response)\n",
        "\n",
        "    # Extraction de la réponse en français après \"💡 Réponse en français :\"\n",
        "    start_index = test_answer.find(\"💡 Réponse en français :\") + len(\"💡 Réponse en français :\")\n",
        "    filtered_response = test_answer[start_index:].strip()\n",
        "\n",
        "    # Enlever \"Correcte !\" à la fin si nécessaire\n",
        "    filtered_response = filtered_response.replace(\"Correct\", \"\").strip()\n",
        "    print('\\nfiltered_response : ', filtered_response)\n",
        "\n",
        "    return filtered_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wji1VtWFe5ge"
      },
      "source": [
        "### 6.1.1 Simple Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48t_6Rqje5ge"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la capitale de la France ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snkh0BhMe5ge"
      },
      "source": [
        "### 6.1.2 Dev Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBPvXb-Qe5gf"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Qu'est-ce qu'une API ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k7k5HbEe5gf"
      },
      "source": [
        "### 6.1.3 Admin Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDw4G-B3e5gf"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Comment installer Apache sur un serveur Linux ?\", \"Admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLj8If6oe5gg"
      },
      "source": [
        "### 6.1.4 D'autre role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctclXqr5e5gg"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la capitale de la France ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1MvT_H_e5gh"
      },
      "source": [
        "### 6.1.5 Hors context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGCsZ6tye5gh"
      },
      "outputs": [],
      "source": [
        "query_Mistral7(\"Quelle est la durée d'un jour sur Mars ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TED4twF9e5gi"
      },
      "source": [
        "### 6.1.6 Test  Mistral7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1AHc2Apje5gi"
      },
      "source": [
        "L’objectif de ce code est d’évaluer automatiquement la qualité des réponses générées par un modèle de type RAG (comme LLaMA2) en les comparant à des réponses attendues à l’aide de mesures de similarité lexicale et sémantique, afin de calculer une accuracy factuelle globale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWa-lEQAe5gi"
      },
      "outputs": [],
      "source": [
        "# !pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzYxd_vWe5gi"
      },
      "outputs": [],
      "source": [
        "import re, json, unicodedata\n",
        "from rapidfuzz import fuzz, utils\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXf65vOae5gj"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # 👈 nouveau nom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJMKPhwEe5gj"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    # minuscules, accents retirés, emojis & markdown supprimés\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "    text = re.sub(r\"`[^`]+`\", \" \", text)          # back‑ticks\n",
        "    text = re.sub(r\":[^:\\s]+:\", \" \", text)        # :emoji:\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)          # ponctuation\n",
        "    return \" \".join(text.lower().split())\n",
        "\n",
        "def token_f1(pred, gold):\n",
        "    p_tok, g_tok = pred.split(), gold.split()\n",
        "    common = len(set(p_tok) & set(g_tok))\n",
        "    if common == 0: return 0.0\n",
        "    prec = common / len(p_tok)\n",
        "    rec  = common / len(g_tok)\n",
        "    return 2 * prec * rec / (prec + rec)\n",
        "\n",
        "def score(pred, gold):\n",
        "    p, g = clean(pred), clean(gold)\n",
        "\n",
        "    # 1) containment\n",
        "    if g in p: return 1.0\n",
        "\n",
        "    # 2) token‑F1 rapide\n",
        "    f1 = token_f1(p, g)\n",
        "    if f1 >= 0.8: return f1          # bon seuil pour réponses courtes\n",
        "\n",
        "    # 3) Similarité sémantique\n",
        "    sim = util.cos_sim(\n",
        "        sbert.encode([p])[0],      # utilise sbert, pas model !\n",
        "        sbert.encode([g])[0]\n",
        "    ).item()\n",
        "\n",
        "    return sim                      # 0–1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81YQLbf_e5gj"
      },
      "outputs": [],
      "source": [
        "# ----------- boucle d'évaluation ----------\n",
        "total, passed = 0, 0\n",
        "with open(\"/content/eval_dataset.json\", encoding=\"utf‑8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZIX5exae5gk"
      },
      "outputs": [],
      "source": [
        "for row in data:\n",
        "    question   = row[\"question\"]\n",
        "    expected   = row[\"expected_answer\"]\n",
        "\n",
        "    generated  = query_Mistral7(question, row[\"role\"])   # ta fonction\n",
        "    s          = score(generated, expected)\n",
        "\n",
        "    total += 1\n",
        "    if s >= 0.8:                   # seuil global\n",
        "        passed += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzHXUPt-e5gk"
      },
      "outputs": [],
      "source": [
        "accuracy = passed / total\n",
        "print(f\"Accuracy factuelle : {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRWlK26we5gk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmpQ7z0-yX-5"
      },
      "source": [
        "##6.2 LLama-3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99nRb_H-kdHS"
      },
      "outputs": [],
      "source": [
        "#!pip install bitsandbytes transformers accelerate\n",
        "#!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exwq1Ib1d0Hx"
      },
      "outputs": [],
      "source": [
        "# from huggingface_hub import login\n",
        "# login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwXLR3npjmDb"
      },
      "source": [
        "il est préférable de le quantifier pour optimiser les performances et réduire la consommation mémoire, surtout si tu tournes sur un GPU avec peu de VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sF9_4xgkd8GR"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Configuration pour charger le modèle en 4 bits\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Utiliser float16 pour de meilleures perfs\n",
        "    bnb_4bit_use_double_quant=True,  # Double quantization pour réduire encore plus la mémoire\n",
        "    bnb_4bit_quant_type=\"nf4\"  # nf4 est plus efficace que fp4\n",
        ")\n",
        "\n",
        "# Charger LLaMA-2-7B-Chat avec quantization\n",
        "model_name_Llama3 = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
        "tokenizer_Llama3 = AutoTokenizer.from_pretrained(model_name_Llama3)\n",
        "model_Llama3 = AutoModelForCausalLM.from_pretrained(model_name_Llama3, quantization_config=quant_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCHLrC53WgGA"
      },
      "outputs": [],
      "source": [
        "# # Load model directly\n",
        "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# tokenizer_Llama3 = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")\n",
        "# model_Llama3 = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3.1-8B-Instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQCbAd1kNn4X"
      },
      "outputs": [],
      "source": [
        "tokenizer_Llama3.pad_token_id = tokenizer_Llama3.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TcKySz6gkOeG"
      },
      "outputs": [],
      "source": [
        "# Vérifier si le modèle est bien chargé sur GPU\n",
        "print(model_Llama3.hf_device_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mbp9Lnrsgeze"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Charger le modèle sur le GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def query_Model_llama3(question, reponse):\n",
        "    # Format the input prompt\n",
        "    #formatted_prompt = f\"Question: {question}\\n\\nRespons: {response}\"\n",
        "    formatted_prompt = f\"\"\"\n",
        "                              Voici une question posée par un utilisateur et la réponse récupérée à partir de ChromaDB.\n",
        "\n",
        "                              🔹 **Instructions claires :**\n",
        "                              - **Si la réponse récupérée est valide**, reformule-la en français avec plus de contexte et d'explications. Ajoute des émojis dynamiquement pour illustrer les concepts (ex : 🌍 pour un lieu, 🧠 pour une explication, ✅ pour une réponse correcte). Termine la réponse par ✅.\n",
        "                              - **Si la réponse est exactement \"Cette question ne correspond à aucun des rôles définis.\", alors affiche exactement :**\n",
        "                                **\"Cette question ne correspond à aucun des rôles définis. ❌\"**\n",
        "                              - **Si la réponse est exactement \" Cette question associée à un autre rôle. \", alors affiche exactement :**\n",
        "                                **\"Cette question est associée à un autre rôle. 🔄\"**\n",
        "                              - **Ne génère aucun autre texte en dehors des trois cas définis ci-dessus.**\n",
        "\n",
        "                              **⚠️ Attention :** Tu dois suivre ces règles strictement et ne pas ajouter d'explications supplémentaires si la réponse ne correspond pas aux données disponibles.\n",
        "\n",
        "                              **Longueur maximale de la réponse générée : 500 caractères.**\n",
        "\n",
        "                              Question : {question}\n",
        "                              Réponse récupérée : {reponse}\n",
        "                              💡 Réponse en français :\n",
        "                        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Tokeniser l'entrée et envoyer sur le GPU\n",
        "    inputs = tokenizer_Llama3(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Générer la réponse\n",
        "    outputs = model_Llama3.generate(**inputs, max_length=800)\n",
        "\n",
        "    # Décoder et afficher la réponse\n",
        "    response = tokenizer_Llama3.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOawsGUmY2sD"
      },
      "outputs": [],
      "source": [
        "def query_Llama3(query:str, role:str):\n",
        "  #print('query : ', query)\n",
        "  #print('role : ', role)\n",
        "  response = ask_question(role, query)\n",
        "  print('\\nresponse ask_question : ', response)\n",
        "\n",
        "  if response == message_question_existante_autre_role:\n",
        "    return response + ' 🔄'\n",
        "  elif response==message_hors_contexte:\n",
        "    return response + ' ❌'\n",
        "  else:\n",
        "    test_answer = query_Model_llama3(query, response)\n",
        "\n",
        "    # Extraction de la réponse en français après \"💡 Réponse en français :\"\n",
        "    start_index = test_answer.find(\"💡 Réponse en français :\") + len(\"💡 Réponse en français :\")\n",
        "    filtered_response = test_answer[start_index:].strip()\n",
        "\n",
        "    # Enlever \"Correcte !\" à la fin si nécessaire\n",
        "    filtered_response = filtered_response.replace(\"Correct\", \"\").strip()\n",
        "    print('\\nfiltered_response : ', filtered_response)\n",
        "\n",
        "    return filtered_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL7tf5-lZoF5"
      },
      "source": [
        "### 6.1.1 Simple Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmt-b7kUZfqL"
      },
      "outputs": [],
      "source": [
        "query_Llama3(\"Quelle est la capitale de la France ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lbhJDzjZrBW"
      },
      "source": [
        "### 6.1.2 Dev Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEKBciyvZs_X"
      },
      "outputs": [],
      "source": [
        "query_Llama3(\"Qu'est-ce qu'une API ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfSOcWQSZtic"
      },
      "source": [
        "### 6.1.3 Admin Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ok6Lk46TZvle"
      },
      "outputs": [],
      "source": [
        "query_Llama3(\"Comment installer Apache sur un serveur Linux ?\", \"Admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFsXFc1dZwpv"
      },
      "source": [
        "### 6.1.4 D'autre role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-vqjKAK9Z0ks"
      },
      "outputs": [],
      "source": [
        "query_Llama3(\"Quelle est la capitale de la France ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md-oDvGgZ1Df"
      },
      "source": [
        "### 6.1.5 Hors context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bQI5QNSZ5rN"
      },
      "outputs": [],
      "source": [
        "query_Llama3(\"Quelle est la durée d'un jour sur Mars ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g73Bj5Zw8je4"
      },
      "source": [
        "### 6.1.6 Test  Llama3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5t57EIMDizh"
      },
      "source": [
        "L’objectif de ce code est d’évaluer automatiquement la qualité des réponses générées par un modèle de type RAG (comme LLaMA2) en les comparant à des réponses attendues à l’aide de mesures de similarité lexicale et sémantique, afin de calculer une accuracy factuelle globale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "10L9ni9n802k"
      },
      "outputs": [],
      "source": [
        "# !pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzcC8DlE7_yG"
      },
      "outputs": [],
      "source": [
        "import re, json, unicodedata\n",
        "from rapidfuzz import fuzz, utils\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pu0h7N1D_UKr"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # 👈 nouveau nom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3IoQjxO8r-J"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    # minuscules, accents retirés, emojis & markdown supprimés\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "    text = re.sub(r\"`[^`]+`\", \" \", text)          # back‑ticks\n",
        "    text = re.sub(r\":[^:\\s]+:\", \" \", text)        # :emoji:\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)          # ponctuation\n",
        "    return \" \".join(text.lower().split())\n",
        "\n",
        "def token_f1(pred, gold):\n",
        "    p_tok, g_tok = pred.split(), gold.split()\n",
        "    common = len(set(p_tok) & set(g_tok))\n",
        "    if common == 0: return 0.0\n",
        "    prec = common / len(p_tok)\n",
        "    rec  = common / len(g_tok)\n",
        "    return 2 * prec * rec / (prec + rec)\n",
        "\n",
        "def score(pred, gold):\n",
        "    p, g = clean(pred), clean(gold)\n",
        "\n",
        "    # 1) containment\n",
        "    if g in p: return 1.0\n",
        "\n",
        "    # 2) token‑F1 rapide\n",
        "    f1 = token_f1(p, g)\n",
        "    if f1 >= 0.8: return f1          # bon seuil pour réponses courtes\n",
        "\n",
        "    # 3) Similarité sémantique\n",
        "    sim = util.cos_sim(\n",
        "        sbert.encode([p])[0],      # utilise sbert, pas model !\n",
        "        sbert.encode([g])[0]\n",
        "    ).item()\n",
        "\n",
        "    return sim                      # 0–1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jSHfMmEN8vHX"
      },
      "outputs": [],
      "source": [
        "# ----------- boucle d'évaluation ----------\n",
        "total, passed = 0, 0\n",
        "with open(\"/content/eval_dataset.json\", encoding=\"utf‑8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNSh7Ych8wzz"
      },
      "outputs": [],
      "source": [
        "for row in data:\n",
        "    question   = row[\"question\"]\n",
        "    expected   = row[\"expected_answer\"]\n",
        "\n",
        "    generated  = query_Llama3(question, row[\"role\"])   # ta fonction\n",
        "    s          = score(generated, expected)\n",
        "\n",
        "    total += 1\n",
        "    if s >= 0.8:                   # seuil global\n",
        "        passed += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtXb9sYV8ySC"
      },
      "outputs": [],
      "source": [
        "accuracy = passed / total\n",
        "print(f\"Accuracy factuelle : {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c1-f4HsCWYB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6GvD2eNEC2C"
      },
      "source": [
        "##6.3 LLama-2-7b-chat via API HugginFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AOzEHaDVEC2E"
      },
      "outputs": [],
      "source": [
        "# !pip install bitsandbytes transformers accelerate\n",
        "# !pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "024ee4323c7d4ab3b2d9ec30709b3b43",
            "7242943b95f94968ab21fda184d5b0b6",
            "12bc4024cf67404c83f16d07817fb7a3",
            "291dfee45c974252ba71511670a4344f",
            "d86364755f384ada916d6dd9475dc11b",
            "fad1556885094d028f3d1e673bfe5204",
            "1f97a1b244b848d49880167aca06b1a4",
            "175565677bb44654a6fd33a79cf4d35b",
            "5e2d254239b947fb8b319a1d208b4138",
            "f3fb5560664c4d05bdae26774030b358",
            "d3092eb867a540e594ca693520d76b20",
            "55ff2a65f74248b4bd88d7037a25c271",
            "145e994f32ad4e3aa3fd1d64fc6d41f5",
            "7bc0b16446da4711b8adea96ced78a11",
            "5b54090b9ca742258fd9dd26ced0ebf6",
            "14877e2fff23444791378ba12c9ea010",
            "429ad65607cc43e2bc713de6d603cfa8",
            "8c41761237dc4df9b26541f0148e8f5e",
            "225452271ace49b58483eef479e1e145",
            "0837e2feae63406faa39cc483f594062"
          ]
        },
        "id": "xtOYrwZyEC2G",
        "outputId": "9e22db80-94b5-44b7-e903-d1b7a1c1ff5b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "024ee4323c7d4ab3b2d9ec30709b3b43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL6ipIIsEC2H"
      },
      "source": [
        "il est préférable de le quantifier pour optimiser les performances et réduire la consommation mémoire, surtout si tu tournes sur un GPU avec peu de VRAM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369,
          "referenced_widgets": [
            "a57f9e3f8701469ca2ca1ec473412fc0",
            "1ed7c375119a446ab54cf1363db6e6a9",
            "18195fff73e24e3aafe950c84681ad95",
            "7b6aed589b1945728f94be81e41fcd74",
            "95c622c9ce2b4ad0a4277b7621acdad6",
            "06283f68b2814441a5e0f111807fa196",
            "58bd0c102d2944d18da0f010759ee839",
            "6f3a1e8813474a10b364d660c6b683aa",
            "d60673661ccd471ea08312097f2aa979",
            "d46c63fdb2ae41649c061aa164eb837f",
            "57a76abf6d164e768b1986d7cd997417",
            "ca73cf59016a467190ad7189d451f2a3",
            "1b664fc163d94b6291b1e7a38a8e399d",
            "7e6f056249f34af5a34d1e20d15287a8",
            "77d9e76f9f524abe8ff71363a59da622",
            "1aaf388d033745faba6b5b18f3ea5bef",
            "9f9fe8516271439489118f4bca090bb8",
            "09c6aca9fa0e4908984786a5c1c5eab5",
            "c1376c2cd35e46f7a86f7e7dc7af8d54",
            "9082ccae3e5b42599a8d6172ff0b83dc",
            "9a30dcf1a3fc4192959971e5a5398e0c",
            "d597d02f63b14c2cbd4aa6650b6a9dcf",
            "2d8e7c72932b46d3a34120e2f52916cc",
            "114158fe54364398b62ddf430bf7ddce",
            "47e12dcfebd046deaae6ae36be78b53a",
            "e29f1e0c7bc64fb4ba7b6576654b3cee",
            "369104c5e1b744e0b56e8b628c40cd38",
            "2fc2c6f746de432189315ab4c12b44e2",
            "0d61703a21044ec2881729ca43081d3e",
            "a661c1baab4b4f698540942c679aa49c",
            "6e54d479f9a7476cbbc12c9be46d72c2",
            "b5c8afc058504f598260e77c4a1ce6ac",
            "16bde49b3490434e902c071293c9bab3",
            "a93b94469a4e49dfa88fc0352a6f0499",
            "e6e355b7f14f486ea732ab8e7d2a80cc",
            "ddf8742eca314747ad366e46be0f6e3c",
            "3ca3d01a554a4c8b99f8d1fd120fb584",
            "46a806963dad4c45bf1c99eb7eb9e32d",
            "62fce3350df84dc5a18d9386339c3291",
            "19a4474fd52b434d8404e4f2b380dcad",
            "079e6574859546338076f89a4fe6075b",
            "e4efe60e2fa242ceb2bc48180666720f",
            "ae2d38b0cd8c48bd85310c6514130e88",
            "73e72585a4fa45058859c8040981c8d6",
            "b1f3e4091bf84837bccae5786799c3b4",
            "e77364a6e0544d98904c4d84b1ac6726",
            "15fbf490b7c943f08f2c25533bc7e2cd",
            "aa0a60f7f6e14a9b9cd510aa25441856",
            "99ebb464932043e1bef13a21d48d1b08",
            "23cddf47c4e2485a853d4b516a0bede9",
            "81bad82e32864a1fa3e12671834c1062",
            "f6edba4b36424c5da5959543398c7b75",
            "7d0870f2e0a04588a910eef5c891473b",
            "a541e9b6966a42bea33fb790718ec1d8",
            "31889945b8be4e8f9d58043382903df1",
            "46653dcf299c4c6c951c93c8e50ecaa4",
            "e05a251750d8437ba1acbcab5e23ef39",
            "d68d5e48b3c340bda94a67eb98adfb22",
            "153891927ebe4dec8097ab25b98b6313",
            "be8cdbc2f5a94979bef82b675d0d84fa",
            "416ac86da3f743718320b747b9414540",
            "011eae76884e41bb85585bbb65d9981b",
            "74a224e0cae94f1aaf68b10f9490d8a3",
            "623e8daa974f446986ab6744db6d5142",
            "039936c5745546789de4e591d51bf484",
            "cde83deb1ba54429baf4e653598c8313",
            "fe8a1cc138cc446c9d0d796f43dd2224",
            "e661bc40befd49ccacdd6f4cdfd56a2e",
            "4d322b8d05ba4d09a3033dc023ba331d",
            "9d9304b4652b410cbd17d3c2e42ed9a5",
            "00426c959a4148c9bd27e5358c5e4084",
            "fe648a2b24fb4452ad3f5e5b26a814cb",
            "302f86ab9e5844549bc82f3d52d65a94",
            "696acf4b662c46078b7fd5cec07741fd",
            "7651d85944cb4e78bd63b2942cdbe316",
            "fed67998df5b4e04b7e2aeba529fd0df",
            "eff8014a560d4253b163e130a6e684e8",
            "78997186215f4928839a4df29fa35a3a",
            "4eb8a7c2143f491581ce06bc6413446f",
            "0b3a733e17c74634bf58ee0118b42a97",
            "28b7cc8e837e42b691931ec4b52d1b8f",
            "acd581791d1248ab9861df460f132494",
            "75b366f82cbb44e2b7ac4a83832573d6",
            "1365bfeab4bd459f9697405deeb18768",
            "851ffd7a778d4a99aa567e9b7933be0c",
            "086513fd908f45d19b7c5d5b59860b69",
            "2679810151764f2aabc9aa57fbb30869",
            "f4a6b7890295403cb8bc9f410d5baffb",
            "b65a48579be14d3e89882f93ddc71642",
            "ab979d50cee94eb9b57753b4208df9af",
            "cdc7596bfa2f4166b77bc54e5b039bc5",
            "890318819b6141cdbb4ac78352593400",
            "1b1cff7b6164436491e0354776d74cc7",
            "9649e579ded145448ce75d5f5c307ff5",
            "223656c197bf452eb9e0c2c898ffc255",
            "6cf0e9681a994bfb95021bbf825fdac1",
            "b6ed4f7779484c9abf014e81a4d03cc3",
            "ebc7ce8079a14646aab1cb27237fa0a1",
            "5a8982f283554e1cac26d8d60f2f18ac",
            "82235f3dc2214c39a16b3ec46d03e93b",
            "3276ceb252434aa2833fae9ba8f3de5b",
            "8a16fdca5ade415ea9b5bfe2021bdf45",
            "06bb7bac77944c41b26cd782fd95700a",
            "76b8f57e42c94f1589818c9eb9bb65ac",
            "4bc220d74ed5429a9fa3982e158a3e4b",
            "85fb5ff723374674bd6b68528ed7f9a1",
            "9119d05b9b4147d3bd90f9a0e86687ab",
            "4f0b07f5ffa5405fab992871517da356",
            "985d74ce2e57455093b3f3c382064455",
            "731f2d353c9c49d9ab6affcb12602c6e",
            "8098ded1dd12436fabe05dcc8e8900c5",
            "9baae9d83179433591a1ddf49dbb8263",
            "dd55a2af25434ad1ac5405e20c579322",
            "14eb3bb4b2b9466d9f087160cbc4c17f",
            "65ed0524511145319a594c98d373fb86",
            "143307a62bb643ad9b156938cc1185f7",
            "50046b73da9743858df2f53c93a4fc02",
            "6189f72ecac24e61a52bd58cf9b6a732",
            "2179b802bc334a5fabe42014f17cc913",
            "851311cb45384f18b7b4322d5a9727b3",
            "ac95bbb109ee4f89af9af6726d04402c"
          ]
        },
        "id": "S06a8O2AEC2H",
        "outputId": "b1c4ef40-25ba-4819-8fe4-f6ccaa7e24ae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a57f9e3f8701469ca2ca1ec473412fc0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca73cf59016a467190ad7189d451f2a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d8e7c72932b46d3a34120e2f52916cc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a93b94469a4e49dfa88fc0352a6f0499",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1f3e4091bf84837bccae5786799c3b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "46653dcf299c4c6c951c93c8e50ecaa4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe8a1cc138cc446c9d0d796f43dd2224",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "78997186215f4928839a4df29fa35a3a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b65a48579be14d3e89882f93ddc71642",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82235f3dc2214c39a16b3ec46d03e93b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8098ded1dd12436fabe05dcc8e8900c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# Configuration pour charger le modèle en 4 bits\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,  # Utiliser float16 pour de meilleures perfs\n",
        "    bnb_4bit_use_double_quant=True,  # Double quantization pour réduire encore plus la mémoire\n",
        "    bnb_4bit_quant_type=\"nf4\"  # nf4 est plus efficace que fp4\n",
        ")\n",
        "\n",
        "# Charger LLaMA-2-7B-Chat avec quantization\n",
        "model_name_Llama2 = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "tokenizer_Llama2 = AutoTokenizer.from_pretrained(model_name_Llama2)\n",
        "model_Llama2 = AutoModelForCausalLM.from_pretrained(model_name_Llama2, quantization_config=quant_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Zcnn-2EC2I",
        "outputId": "9a42b0a9-4e8a-48e0-b17a-68c197462115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'': 0}\n"
          ]
        }
      ],
      "source": [
        "# Vérifier si le modèle est bien chargé sur GPU\n",
        "print(model_Llama2.hf_device_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ViP-vabhEC2J"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Charger le modèle sur le GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "def query_Model_llama2(question, reponse):\n",
        "    # Format the input prompt\n",
        "    #formatted_prompt = f\"Question: {question}\\n\\nRespons: {response}\"\n",
        "    formatted_prompt = f\"\"\"\n",
        "                              Voici une question posée par un utilisateur et la réponse récupérée à partir de ChromaDB.\n",
        "\n",
        "                              🔹 **Instructions claires :**\n",
        "                              - **Si la réponse récupérée est valide**, reformule-la en français avec plus de contexte et d'explications. Ajoute des émojis dynamiquement pour illustrer les concepts (ex : 🌍 pour un lieu, 🧠 pour une explication, ✅ pour une réponse correcte). Termine la réponse par ✅.\n",
        "                              - **Si la réponse est exactement \"Cette question ne correspond à aucun des rôles définis.\", alors affiche exactement :**\n",
        "                                **\"Cette question ne correspond à aucun des rôles définis. ❌\"**\n",
        "                              - **Si la réponse est exactement \" Cette question associée à un autre rôle. \", alors affiche exactement :**\n",
        "                                **\"Cette question est associée à un autre rôle. 🔄\"**\n",
        "                              - **Ne génère aucun autre texte en dehors des trois cas définis ci-dessus.**\n",
        "\n",
        "                              **⚠️ Attention :** Tu dois suivre ces règles strictement et ne pas ajouter d'explications supplémentaires si la réponse ne correspond pas aux données disponibles.\n",
        "\n",
        "                              **Longueur maximale de la réponse générée : 500 caractères.**\n",
        "\n",
        "                              Question : {question}\n",
        "                              Réponse récupérée : {reponse}\n",
        "                              💡 Réponse en français :\n",
        "                        \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Tokeniser l'entrée et envoyer sur le GPU\n",
        "    inputs = tokenizer_Llama2(formatted_prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "    # Générer la réponse\n",
        "    outputs = model_Llama2.generate(**inputs, max_length=800)\n",
        "\n",
        "    # Décoder et afficher la réponse\n",
        "    response = tokenizer_Llama2.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "BhqVZI5vEC2K"
      },
      "outputs": [],
      "source": [
        "def query_Llama2(query:str, role:str):\n",
        "  #print('query : ', query)\n",
        "  #print('role : ', role)\n",
        "  response = ask_question(role, query)\n",
        "  print('\\nresponse ask_question : ', response)\n",
        "\n",
        "  if response == message_question_existante_autre_role:\n",
        "    return response + ' 🔄'\n",
        "  elif response==message_hors_contexte:\n",
        "    return response + ' ❌'\n",
        "  else:\n",
        "    test_answer = query_Model_llama2(query, response)\n",
        "\n",
        "    # Extraction de la réponse en français après \"💡 Réponse en français :\"\n",
        "    start_index = test_answer.find(\"💡 Réponse en français :\") + len(\"💡 Réponse en français :\")\n",
        "    filtered_response = test_answer[start_index:].strip()\n",
        "\n",
        "    # Enlever \"Correcte !\" à la fin si nécessaire\n",
        "    filtered_response = filtered_response.replace(\"Correct\", \"\").strip()\n",
        "    # print('\\nfiltered_response : ', filtered_response)\n",
        "\n",
        "    return filtered_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haWOSOyeEC2L"
      },
      "source": [
        "### 6.1.1 Simple Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "yxMOTtd0EC2M",
        "outputId": "2640b0ca-9df5-45f8-8305-093183ce50e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "response ask_question :  Le Groupe OMF est une entreprise marocaine qui aide les chefs d'entreprise à relever leurs défis quotidiens.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Le Groupe OMF est une entreprise marocaine spécialisée dans la fourniture de services de gestion d'entreprise. Ils offrent des conseils et des outils pour aider les chefs d'entreprise à relever leurs défis quotidiens et à améliorer leur gestion de l'entreprise. 🤝\\n                         ✅\""
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_Llama2(\"Qui est le Groupe OMF ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNVuqgnTEC2N"
      },
      "source": [
        "### 6.1.2 Dev Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "E5_oKYlxEC2N",
        "outputId": "ebca157d-e2db-48c5-d04b-7dcb6b56d405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "response ask_question :  Amélioration de l'utilisation des ressources pour des résultats optimaux.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"L'optimisation au sein du Groupe OMF (Optimization and Maintenance Framework) est l'amélioration de l'utilisation des ressources pour obtenir les résultats optimaux. Cela implique de mettre en place des stratégies et des techniques pour maximiser l'efficacité des ressources et minimiser les coûts. L'objectif est de garantir une bonne performance, une sécurité accrue et une maintenance efficace des systèmes et des applications. ✅\""
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_Llama2(\"Qu'entend-on par optimisation au sein du Groupe OMF ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHadT62AEC2O"
      },
      "source": [
        "### 6.1.3 Admin Utilisateur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "ZllxO5YoEC2P",
        "outputId": "c8efcd85-abd5-4aa7-f26b-6dced0ca8a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "response ask_question :  Gestion, optimisation, formation, conseil, communication et technologie.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Le Groupe OMF propose différents types de services pour aider les professionnels du marketing et de la communication à améliorer leur performance. Il offre des services de gestion, d'optimisation, de formation, de conseil, de communication et de technologie pour aider les entreprises à atteindre leurs objectifs commerciaux. 💻\""
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_Llama2(\"Quels types de services propose le Groupe OMF ?\", \"Admin\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0VPNCcL7EC2Q"
      },
      "source": [
        "### 6.1.4 D'autre role"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "KYwc6_8aEC2Q",
        "outputId": "7960d0aa-5da8-434d-97de-b3ff3f5bda27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "response ask_question :  Cette question associée à un autre rôle.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Cette question associée à un autre rôle. 🔄'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_Llama2(\"Qui est le Groupe OMF ?\", \"Dev\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLz02ivPEC2R"
      },
      "source": [
        "### 6.1.5 Hors context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "tdjLGtj4EC2S",
        "outputId": "6b791638-6ea2-4aba-c0c5-0f3413deb092"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "response ask_question :  Cette question ne correspond à aucun des rôles définis.\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Cette question ne correspond à aucun des rôles définis. ❌'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_Llama2(\"Quelle est la durée d'un jour sur Mars ?\", \"Simple\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDXw9qLNEC2T"
      },
      "source": [
        "### 6.1.6 Test  llama2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qthq61YPEC2U"
      },
      "source": [
        "L’objectif de ce code est d’évaluer automatiquement la qualité des réponses générées par un modèle de type RAG (comme LLaMA2) en les comparant à des réponses attendues à l’aide de mesures de similarité lexicale et sémantique, afin de calculer une accuracy factuelle globale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mo54Dx5dEC2U"
      },
      "outputs": [],
      "source": [
        "!pip install rapidfuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmFLKZpWEC2V"
      },
      "outputs": [],
      "source": [
        "import re, json, unicodedata\n",
        "from rapidfuzz import fuzz, utils\n",
        "from sentence_transformers import SentenceTransformer, util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4uK2-EEEC2W"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "sbert = SentenceTransformer(\"paraphrase-multilingual-MiniLM-L12-v2\")  # 👈 nouveau nom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSMahf6SEC2X"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    # minuscules, accents retirés, emojis & markdown supprimés\n",
        "    text = unicodedata.normalize(\"NFKD\", text).encode(\"ascii\", \"ignore\").decode()\n",
        "    text = re.sub(r\"`[^`]+`\", \" \", text)          # back‑ticks\n",
        "    text = re.sub(r\":[^:\\s]+:\", \" \", text)        # :emoji:\n",
        "    text = re.sub(r\"[^\\w\\s]\", \" \", text)          # ponctuation\n",
        "    return \" \".join(text.lower().split())\n",
        "\n",
        "def token_f1(pred, gold):\n",
        "    p_tok, g_tok = pred.split(), gold.split()\n",
        "    common = len(set(p_tok) & set(g_tok))\n",
        "    if common == 0: return 0.0\n",
        "    prec = common / len(p_tok)\n",
        "    rec  = common / len(g_tok)\n",
        "    return 2 * prec * rec / (prec + rec)\n",
        "\n",
        "def score(pred, gold):\n",
        "    p, g = clean(pred), clean(gold)\n",
        "\n",
        "    # 1) containment\n",
        "    if g in p: return 1.0\n",
        "\n",
        "    # 2) token‑F1 rapide\n",
        "    f1 = token_f1(p, g)\n",
        "    if f1 >= 0.8: return f1          # bon seuil pour réponses courtes\n",
        "\n",
        "    # 3) Similarité sémantique\n",
        "    sim = util.cos_sim(\n",
        "        sbert.encode([p])[0],      # utilise sbert, pas model !\n",
        "        sbert.encode([g])[0]\n",
        "    ).item()\n",
        "\n",
        "    return sim                      # 0–1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aVfaJVkEC2Y"
      },
      "outputs": [],
      "source": [
        "# ----------- boucle d'évaluation ----------\n",
        "total, passed = 0, 0\n",
        "with open(\"/content/eval_dataset.json\", encoding=\"utf‑8\") as f:\n",
        "    data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naaDyikBEC2Z"
      },
      "outputs": [],
      "source": [
        "for row in data:\n",
        "    question   = row[\"question\"]\n",
        "    expected   = row[\"expected_answer\"]\n",
        "\n",
        "    generated  = query_Llama2(question, row[\"role\"])   # ta fonction\n",
        "    s          = score(generated, expected)\n",
        "\n",
        "    total += 1\n",
        "    if s >= 0.8:                   # seuil global\n",
        "        passed += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_QDj9nDEC2a"
      },
      "outputs": [],
      "source": [
        "accuracy = passed / total\n",
        "print(f\"Accuracy factuelle : {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjLgpq0u_25B"
      },
      "source": [
        "# Selection Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VoS5T1PEC2b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Noms des modèles et leurs scores d'accuracy factuelle\n",
        "models = [\"FLAN-T5 Base/Large\", \"Mistral-7B\", \"LLaMA 3\", \"LLaMA 2\", \"GPT2\", \"DeepSeek\"]\n",
        "accuracies = [32, 61.11, 67.78, 72.48, 33.33, 68.89]  # en pourcentages\n",
        "\n",
        "# Couleurs personnalisées : par défaut gris, sauf LLaMA 2 en vert\n",
        "colors = ['gray'] * len(models)\n",
        "llama2_index = models.index(\"LLaMA 2\")\n",
        "colors[llama2_index] = 'green'\n",
        "\n",
        "# Création du graphique\n",
        "plt.figure(figsize=(12, 6))\n",
        "bars = plt.bar(models, accuracies, color=colors)\n",
        "\n",
        "# Ajout des valeurs au-dessus des barres\n",
        "for bar in bars:\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, height + 1,\n",
        "             f'{height:.2f}%', ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "# Détails esthétiques\n",
        "plt.title(\"Comparaison de l'Accuracy Factuale entre différents modèles LLM\", fontsize=14)\n",
        "plt.ylabel(\"Accuracy Factuale (%)\", fontsize=12)\n",
        "plt.ylim(0, 80)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
        "\n",
        "# Annotation de justification pour LLaMA 2\n",
        "plt.text(llama2_index, accuracies[llama2_index] + 4,\n",
        "         \"✅ Meilleur compromis : LLaMA 2\", fontsize=12, color='green', ha='center')\n",
        "\n",
        "# Affichage\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CkhQFnZ_63p"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUaENx-n3MIt"
      },
      "source": [
        "# Gradio Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "xYTYXtkm3N59"
      },
      "outputs": [],
      "source": [
        "#!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "hxrqfnWF3Owp"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Création de l'interface Gradio\n",
        "interface = gr.Interface(\n",
        "    fn=query_Llama2,  # Appelle la fonction query(question, role)\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Question\"),  # Champ pour la question\n",
        "        gr.Dropdown([\"Simple\", \"Dev\", \"Admin\"], label=\"Rôle\")  # Sélection du rôle\n",
        "    ],\n",
        "    outputs=\"text\",\n",
        "    title=\"RAG Chatbot : Réponses adaptées selon le rôle\",\n",
        "    description=\"Pose une question et sélectionne un rôle (Simple, Dev ou Admin) pour obtenir une réponse personnalisée générée par LLaMa avec ChromaDB.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "SYHWZgCD3P0P",
        "outputId": "b97abf25-7876-4272-9ebb-16a10dc05870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4d60be1b92f2d0d1f0.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://4d60be1b92f2d0d1f0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interface.launch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGrpSz7t3Rk7"
      },
      "outputs": [],
      "source": [
        "interface.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "d8TQtMFiNNyw",
        "pnh5f8-IXd7w",
        "_slW1788Xmh9",
        "KSnjKwmRXvAD",
        "CNraZT_58jj5",
        "n9tge6r7U42F",
        "03ah0eF1W2fF",
        "7Nb_D5eAYFii",
        "jhcO3JA3ay6q",
        "8t4TAHPIWOlp",
        "U9rA6YWhWWCO",
        "Nqf-7LRGWaTN",
        "pwaOPcNtWjOC",
        "IpEZWR82XBxS",
        "-CqY_BcEiDaV",
        "UZwF8BdTwptT",
        "PcPVnl4QYFTd",
        "FGBxAHPLYFTp",
        "8nffCL_9YFTp",
        "o9JfT5NQYFTq",
        "yeSMys3yYFTq",
        "4QnnB4qaPbiR",
        "pS3abplVAskU",
        "y1F9IYa5e5gW",
        "KmpQ7z0-yX-5",
        "mjLgpq0u_25B"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "00426c959a4148c9bd27e5358c5e4084": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "011eae76884e41bb85585bbb65d9981b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "024ee4323c7d4ab3b2d9ec30709b3b43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_1f97a1b244b848d49880167aca06b1a4"
          }
        },
        "039936c5745546789de4e591d51bf484": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06283f68b2814441a5e0f111807fa196": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06bb7bac77944c41b26cd782fd95700a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_985d74ce2e57455093b3f3c382064455",
            "placeholder": "​",
            "style": "IPY_MODEL_731f2d353c9c49d9ab6affcb12602c6e",
            "value": " 2/2 [01:08&lt;00:00, 31.47s/it]"
          }
        },
        "079e6574859546338076f89a4fe6075b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0837e2feae63406faa39cc483f594062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "086513fd908f45d19b7c5d5b59860b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09c6aca9fa0e4908984786a5c1c5eab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b3a733e17c74634bf58ee0118b42a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851ffd7a778d4a99aa567e9b7933be0c",
            "max": 9976576152,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_086513fd908f45d19b7c5d5b59860b69",
            "value": 9976576152
          }
        },
        "0d61703a21044ec2881729ca43081d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "114158fe54364398b62ddf430bf7ddce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fc2c6f746de432189315ab4c12b44e2",
            "placeholder": "​",
            "style": "IPY_MODEL_0d61703a21044ec2881729ca43081d3e",
            "value": "tokenizer.json: 100%"
          }
        },
        "12bc4024cf67404c83f16d07817fb7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f3fb5560664c4d05bdae26774030b358",
            "placeholder": "​",
            "style": "IPY_MODEL_d3092eb867a540e594ca693520d76b20",
            "value": ""
          }
        },
        "1365bfeab4bd459f9697405deeb18768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "143307a62bb643ad9b156938cc1185f7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145e994f32ad4e3aa3fd1d64fc6d41f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14877e2fff23444791378ba12c9ea010": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14eb3bb4b2b9466d9f087160cbc4c17f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_851311cb45384f18b7b4322d5a9727b3",
            "placeholder": "​",
            "style": "IPY_MODEL_ac95bbb109ee4f89af9af6726d04402c",
            "value": " 188/188 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "153891927ebe4dec8097ab25b98b6313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_039936c5745546789de4e591d51bf484",
            "placeholder": "​",
            "style": "IPY_MODEL_cde83deb1ba54429baf4e653598c8313",
            "value": " 26.8k/26.8k [00:00&lt;00:00, 1.47MB/s]"
          }
        },
        "15fbf490b7c943f08f2c25533bc7e2cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6edba4b36424c5da5959543398c7b75",
            "max": 614,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d0870f2e0a04588a910eef5c891473b",
            "value": 614
          }
        },
        "16bde49b3490434e902c071293c9bab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "175565677bb44654a6fd33a79cf4d35b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18195fff73e24e3aafe950c84681ad95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f3a1e8813474a10b364d660c6b683aa",
            "max": 1618,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d60673661ccd471ea08312097f2aa979",
            "value": 1618
          }
        },
        "19a4474fd52b434d8404e4f2b380dcad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1aaf388d033745faba6b5b18f3ea5bef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b1cff7b6164436491e0354776d74cc7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b664fc163d94b6291b1e7a38a8e399d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f9fe8516271439489118f4bca090bb8",
            "placeholder": "​",
            "style": "IPY_MODEL_09c6aca9fa0e4908984786a5c1c5eab5",
            "value": "tokenizer.model: 100%"
          }
        },
        "1ed7c375119a446ab54cf1363db6e6a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06283f68b2814441a5e0f111807fa196",
            "placeholder": "​",
            "style": "IPY_MODEL_58bd0c102d2944d18da0f010759ee839",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1f97a1b244b848d49880167aca06b1a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "2179b802bc334a5fabe42014f17cc913": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "223656c197bf452eb9e0c2c898ffc255": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "225452271ace49b58483eef479e1e145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23cddf47c4e2485a853d4b516a0bede9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2679810151764f2aabc9aa57fbb30869": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b7cc8e837e42b691931ec4b52d1b8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2679810151764f2aabc9aa57fbb30869",
            "placeholder": "​",
            "style": "IPY_MODEL_f4a6b7890295403cb8bc9f410d5baffb",
            "value": " 9.98G/9.98G [14:04&lt;00:00, 25.5MB/s]"
          }
        },
        "291dfee45c974252ba71511670a4344f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "CheckboxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_55ff2a65f74248b4bd88d7037a25c271",
            "style": "IPY_MODEL_145e994f32ad4e3aa3fd1d64fc6d41f5",
            "value": true
          }
        },
        "2d8e7c72932b46d3a34120e2f52916cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_114158fe54364398b62ddf430bf7ddce",
              "IPY_MODEL_47e12dcfebd046deaae6ae36be78b53a",
              "IPY_MODEL_e29f1e0c7bc64fb4ba7b6576654b3cee"
            ],
            "layout": "IPY_MODEL_369104c5e1b744e0b56e8b628c40cd38"
          }
        },
        "2fc2c6f746de432189315ab4c12b44e2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "302f86ab9e5844549bc82f3d52d65a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "31889945b8be4e8f9d58043382903df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3276ceb252434aa2833fae9ba8f3de5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bc220d74ed5429a9fa3982e158a3e4b",
            "placeholder": "​",
            "style": "IPY_MODEL_85fb5ff723374674bd6b68528ed7f9a1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "369104c5e1b744e0b56e8b628c40cd38": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ca3d01a554a4c8b99f8d1fd120fb584": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae2d38b0cd8c48bd85310c6514130e88",
            "placeholder": "​",
            "style": "IPY_MODEL_73e72585a4fa45058859c8040981c8d6",
            "value": " 414/414 [00:00&lt;00:00, 24.7kB/s]"
          }
        },
        "416ac86da3f743718320b747b9414540": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "429ad65607cc43e2bc713de6d603cfa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46653dcf299c4c6c951c93c8e50ecaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e05a251750d8437ba1acbcab5e23ef39",
              "IPY_MODEL_d68d5e48b3c340bda94a67eb98adfb22",
              "IPY_MODEL_153891927ebe4dec8097ab25b98b6313"
            ],
            "layout": "IPY_MODEL_be8cdbc2f5a94979bef82b675d0d84fa"
          }
        },
        "46a806963dad4c45bf1c99eb7eb9e32d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47e12dcfebd046deaae6ae36be78b53a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a661c1baab4b4f698540942c679aa49c",
            "max": 1842767,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e54d479f9a7476cbbc12c9be46d72c2",
            "value": 1842767
          }
        },
        "4bc220d74ed5429a9fa3982e158a3e4b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d322b8d05ba4d09a3033dc023ba331d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_696acf4b662c46078b7fd5cec07741fd",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7651d85944cb4e78bd63b2942cdbe316",
            "value": 2
          }
        },
        "4eb8a7c2143f491581ce06bc6413446f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b366f82cbb44e2b7ac4a83832573d6",
            "placeholder": "​",
            "style": "IPY_MODEL_1365bfeab4bd459f9697405deeb18768",
            "value": "model-00001-of-00002.safetensors: 100%"
          }
        },
        "4f0b07f5ffa5405fab992871517da356": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "50046b73da9743858df2f53c93a4fc02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55ff2a65f74248b4bd88d7037a25c271": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "57a76abf6d164e768b1986d7cd997417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58bd0c102d2944d18da0f010759ee839": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a8982f283554e1cac26d8d60f2f18ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b54090b9ca742258fd9dd26ced0ebf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5e2d254239b947fb8b319a1d208b4138": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6189f72ecac24e61a52bd58cf9b6a732": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "623e8daa974f446986ab6744db6d5142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "62fce3350df84dc5a18d9386339c3291": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65ed0524511145319a594c98d373fb86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "696acf4b662c46078b7fd5cec07741fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cf0e9681a994bfb95021bbf825fdac1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e54d479f9a7476cbbc12c9be46d72c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f3a1e8813474a10b364d660c6b683aa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7242943b95f94968ab21fda184d5b0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_175565677bb44654a6fd33a79cf4d35b",
            "placeholder": "​",
            "style": "IPY_MODEL_5e2d254239b947fb8b319a1d208b4138",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "731f2d353c9c49d9ab6affcb12602c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73e72585a4fa45058859c8040981c8d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74a224e0cae94f1aaf68b10f9490d8a3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75b366f82cbb44e2b7ac4a83832573d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7651d85944cb4e78bd63b2942cdbe316": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "76b8f57e42c94f1589818c9eb9bb65ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77d9e76f9f524abe8ff71363a59da622": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a30dcf1a3fc4192959971e5a5398e0c",
            "placeholder": "​",
            "style": "IPY_MODEL_d597d02f63b14c2cbd4aa6650b6a9dcf",
            "value": " 500k/500k [00:00&lt;00:00, 940kB/s]"
          }
        },
        "78997186215f4928839a4df29fa35a3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4eb8a7c2143f491581ce06bc6413446f",
              "IPY_MODEL_0b3a733e17c74634bf58ee0118b42a97",
              "IPY_MODEL_28b7cc8e837e42b691931ec4b52d1b8f"
            ],
            "layout": "IPY_MODEL_acd581791d1248ab9861df460f132494"
          }
        },
        "7b6aed589b1945728f94be81e41fcd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d46c63fdb2ae41649c061aa164eb837f",
            "placeholder": "​",
            "style": "IPY_MODEL_57a76abf6d164e768b1986d7cd997417",
            "value": " 1.62k/1.62k [00:00&lt;00:00, 149kB/s]"
          }
        },
        "7bc0b16446da4711b8adea96ced78a11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0870f2e0a04588a910eef5c891473b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e6f056249f34af5a34d1e20d15287a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1376c2cd35e46f7a86f7e7dc7af8d54",
            "max": 499723,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9082ccae3e5b42599a8d6172ff0b83dc",
            "value": 499723
          }
        },
        "8098ded1dd12436fabe05dcc8e8900c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9baae9d83179433591a1ddf49dbb8263",
              "IPY_MODEL_dd55a2af25434ad1ac5405e20c579322",
              "IPY_MODEL_14eb3bb4b2b9466d9f087160cbc4c17f"
            ],
            "layout": "IPY_MODEL_65ed0524511145319a594c98d373fb86"
          }
        },
        "81bad82e32864a1fa3e12671834c1062": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82235f3dc2214c39a16b3ec46d03e93b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3276ceb252434aa2833fae9ba8f3de5b",
              "IPY_MODEL_8a16fdca5ade415ea9b5bfe2021bdf45",
              "IPY_MODEL_06bb7bac77944c41b26cd782fd95700a"
            ],
            "layout": "IPY_MODEL_76b8f57e42c94f1589818c9eb9bb65ac"
          }
        },
        "851311cb45384f18b7b4322d5a9727b3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "851ffd7a778d4a99aa567e9b7933be0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85fb5ff723374674bd6b68528ed7f9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "890318819b6141cdbb4ac78352593400": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ebc7ce8079a14646aab1cb27237fa0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8982f283554e1cac26d8d60f2f18ac",
            "value": " 3.50G/3.50G [11:57&lt;00:00, 1.91MB/s]"
          }
        },
        "8a16fdca5ade415ea9b5bfe2021bdf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9119d05b9b4147d3bd90f9a0e86687ab",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f0b07f5ffa5405fab992871517da356",
            "value": 2
          }
        },
        "8c41761237dc4df9b26541f0148e8f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_225452271ace49b58483eef479e1e145",
            "placeholder": "​",
            "style": "IPY_MODEL_0837e2feae63406faa39cc483f594062",
            "value": "Connecting..."
          }
        },
        "9082ccae3e5b42599a8d6172ff0b83dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9119d05b9b4147d3bd90f9a0e86687ab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95c622c9ce2b4ad0a4277b7621acdad6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9649e579ded145448ce75d5f5c307ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "985d74ce2e57455093b3f3c382064455": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99ebb464932043e1bef13a21d48d1b08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a30dcf1a3fc4192959971e5a5398e0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9baae9d83179433591a1ddf49dbb8263": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_143307a62bb643ad9b156938cc1185f7",
            "placeholder": "​",
            "style": "IPY_MODEL_50046b73da9743858df2f53c93a4fc02",
            "value": "generation_config.json: 100%"
          }
        },
        "9d9304b4652b410cbd17d3c2e42ed9a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fed67998df5b4e04b7e2aeba529fd0df",
            "placeholder": "​",
            "style": "IPY_MODEL_eff8014a560d4253b163e130a6e684e8",
            "value": " 2/2 [14:05&lt;00:00, 845.20s/it]"
          }
        },
        "9f9fe8516271439489118f4bca090bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a541e9b6966a42bea33fb790718ec1d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a57f9e3f8701469ca2ca1ec473412fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ed7c375119a446ab54cf1363db6e6a9",
              "IPY_MODEL_18195fff73e24e3aafe950c84681ad95",
              "IPY_MODEL_7b6aed589b1945728f94be81e41fcd74"
            ],
            "layout": "IPY_MODEL_95c622c9ce2b4ad0a4277b7621acdad6"
          }
        },
        "a661c1baab4b4f698540942c679aa49c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93b94469a4e49dfa88fc0352a6f0499": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6e355b7f14f486ea732ab8e7d2a80cc",
              "IPY_MODEL_ddf8742eca314747ad366e46be0f6e3c",
              "IPY_MODEL_3ca3d01a554a4c8b99f8d1fd120fb584"
            ],
            "layout": "IPY_MODEL_46a806963dad4c45bf1c99eb7eb9e32d"
          }
        },
        "aa0a60f7f6e14a9b9cd510aa25441856": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a541e9b6966a42bea33fb790718ec1d8",
            "placeholder": "​",
            "style": "IPY_MODEL_31889945b8be4e8f9d58043382903df1",
            "value": " 614/614 [00:00&lt;00:00, 45.1kB/s]"
          }
        },
        "ab979d50cee94eb9b57753b4208df9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9649e579ded145448ce75d5f5c307ff5",
            "placeholder": "​",
            "style": "IPY_MODEL_223656c197bf452eb9e0c2c898ffc255",
            "value": "model-00002-of-00002.safetensors: 100%"
          }
        },
        "ac95bbb109ee4f89af9af6726d04402c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "acd581791d1248ab9861df460f132494": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae2d38b0cd8c48bd85310c6514130e88": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1f3e4091bf84837bccae5786799c3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e77364a6e0544d98904c4d84b1ac6726",
              "IPY_MODEL_15fbf490b7c943f08f2c25533bc7e2cd",
              "IPY_MODEL_aa0a60f7f6e14a9b9cd510aa25441856"
            ],
            "layout": "IPY_MODEL_99ebb464932043e1bef13a21d48d1b08"
          }
        },
        "b5c8afc058504f598260e77c4a1ce6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b65a48579be14d3e89882f93ddc71642": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab979d50cee94eb9b57753b4208df9af",
              "IPY_MODEL_cdc7596bfa2f4166b77bc54e5b039bc5",
              "IPY_MODEL_890318819b6141cdbb4ac78352593400"
            ],
            "layout": "IPY_MODEL_1b1cff7b6164436491e0354776d74cc7"
          }
        },
        "b6ed4f7779484c9abf014e81a4d03cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be8cdbc2f5a94979bef82b675d0d84fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1376c2cd35e46f7a86f7e7dc7af8d54": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca73cf59016a467190ad7189d451f2a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b664fc163d94b6291b1e7a38a8e399d",
              "IPY_MODEL_7e6f056249f34af5a34d1e20d15287a8",
              "IPY_MODEL_77d9e76f9f524abe8ff71363a59da622"
            ],
            "layout": "IPY_MODEL_1aaf388d033745faba6b5b18f3ea5bef"
          }
        },
        "cdc7596bfa2f4166b77bc54e5b039bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cf0e9681a994bfb95021bbf825fdac1",
            "max": 3500296424,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6ed4f7779484c9abf014e81a4d03cc3",
            "value": 3500296424
          }
        },
        "cde83deb1ba54429baf4e653598c8313": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3092eb867a540e594ca693520d76b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d46c63fdb2ae41649c061aa164eb837f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d597d02f63b14c2cbd4aa6650b6a9dcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d60673661ccd471ea08312097f2aa979": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d68d5e48b3c340bda94a67eb98adfb22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74a224e0cae94f1aaf68b10f9490d8a3",
            "max": 26788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_623e8daa974f446986ab6744db6d5142",
            "value": 26788
          }
        },
        "d86364755f384ada916d6dd9475dc11b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7bc0b16446da4711b8adea96ced78a11",
            "style": "IPY_MODEL_5b54090b9ca742258fd9dd26ced0ebf6",
            "tooltip": ""
          }
        },
        "dd55a2af25434ad1ac5405e20c579322": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6189f72ecac24e61a52bd58cf9b6a732",
            "max": 188,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2179b802bc334a5fabe42014f17cc913",
            "value": 188
          }
        },
        "ddf8742eca314747ad366e46be0f6e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_079e6574859546338076f89a4fe6075b",
            "max": 414,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4efe60e2fa242ceb2bc48180666720f",
            "value": 414
          }
        },
        "e05a251750d8437ba1acbcab5e23ef39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_416ac86da3f743718320b747b9414540",
            "placeholder": "​",
            "style": "IPY_MODEL_011eae76884e41bb85585bbb65d9981b",
            "value": "model.safetensors.index.json: 100%"
          }
        },
        "e29f1e0c7bc64fb4ba7b6576654b3cee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c8afc058504f598260e77c4a1ce6ac",
            "placeholder": "​",
            "style": "IPY_MODEL_16bde49b3490434e902c071293c9bab3",
            "value": " 1.84M/1.84M [00:00&lt;00:00, 22.6MB/s]"
          }
        },
        "e4efe60e2fa242ceb2bc48180666720f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e661bc40befd49ccacdd6f4cdfd56a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe648a2b24fb4452ad3f5e5b26a814cb",
            "placeholder": "​",
            "style": "IPY_MODEL_302f86ab9e5844549bc82f3d52d65a94",
            "value": "Fetching 2 files: 100%"
          }
        },
        "e6e355b7f14f486ea732ab8e7d2a80cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_62fce3350df84dc5a18d9386339c3291",
            "placeholder": "​",
            "style": "IPY_MODEL_19a4474fd52b434d8404e4f2b380dcad",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "e77364a6e0544d98904c4d84b1ac6726": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23cddf47c4e2485a853d4b516a0bede9",
            "placeholder": "​",
            "style": "IPY_MODEL_81bad82e32864a1fa3e12671834c1062",
            "value": "config.json: 100%"
          }
        },
        "ebc7ce8079a14646aab1cb27237fa0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eff8014a560d4253b163e130a6e684e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3fb5560664c4d05bdae26774030b358": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4a6b7890295403cb8bc9f410d5baffb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6edba4b36424c5da5959543398c7b75": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad1556885094d028f3d1e673bfe5204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14877e2fff23444791378ba12c9ea010",
            "placeholder": "​",
            "style": "IPY_MODEL_429ad65607cc43e2bc713de6d603cfa8",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "fe648a2b24fb4452ad3f5e5b26a814cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe8a1cc138cc446c9d0d796f43dd2224": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e661bc40befd49ccacdd6f4cdfd56a2e",
              "IPY_MODEL_4d322b8d05ba4d09a3033dc023ba331d",
              "IPY_MODEL_9d9304b4652b410cbd17d3c2e42ed9a5"
            ],
            "layout": "IPY_MODEL_00426c959a4148c9bd27e5358c5e4084"
          }
        },
        "fed67998df5b4e04b7e2aeba529fd0df": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
